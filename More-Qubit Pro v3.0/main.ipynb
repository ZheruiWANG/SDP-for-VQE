{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "source": [
    "**Find the ground state energy of a certain Hamiltonian with SDP:**\n",
    "1. We can somehow prepare the groud state $\\rho_g$ of a Hamiltonian $H$\n",
    "2. We do quantum tomography on this prepared state $\\rho_g$ and get an approximation $\\hat{\\rho}$\n",
    "3. By using SDP, we get a physically valid quantum state $\\hat{\\rho}_{SDP}$ which minimizes $\\text{Tr}(\\rho H)$ for $\\rho \\in \\tilde{\\rho}$\n",
    "4. The ground state energy we find is then $\\text{Tr}(H\\hat{\\rho}_{SDP})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import math\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from qutip import *\n",
    "from qiskit import *\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.quantum_info import Statevector, DensityMatrix, Operator, Pauli, partial_trace, state_fidelity, random_density_matrix\n",
    "from qiskit.visualization import plot_histogram, plot_state_city, plot_bloch_multivector, plot_state_paulivec, plot_state_hinton, plot_state_qsphere\n",
    "from qiskit.tools.monitor import job_monitor\n",
    "import os\n",
    "#os.environ[\"OMP_NUM_THREADS\"] = \"10\"\n",
    "\n",
    "# Generate measurement dataset\n",
    "def meas(qubits_meas_basis, state, num_meas, N):\n",
    "    ''' Given a Pauli basis (0-Z, 1-X, 2-Y), do measurement and return its outcome\n",
    "    Args:\n",
    "        qubits_meas_basis: A list representing measuring basis, e.g.: [0,0,0] is 'ZZZ'\n",
    "        state: A quantum state from Qiskit\n",
    "        num_meas: number of measurements performed in this basis\n",
    "    Yeilds:\n",
    "        outcome: A list of strings, of which each element is an instance of measurement\n",
    "    E.g.:\n",
    "        INPUT: [0,0,0], state, N=3, num_meas=2\n",
    "        OUTPUT: [000, 000] (in order of qubit 012)\n",
    "    '''\n",
    "    outcome = []\n",
    "    circ_meas = QuantumCircuit(N)\n",
    "\n",
    "    if num_meas>0:\n",
    "        for i in range(N):\n",
    "            if qubits_meas_basis[i] == '1':\n",
    "                circ_meas.ry(-math.pi / 2, i)\n",
    "            elif qubits_meas_basis[i] == '2':\n",
    "                circ_meas.rx(math.pi / 2, i)\n",
    "\n",
    "        U_meas = Operator(circ_meas)\n",
    "        state_temp = state.evolve(U_meas)\n",
    "        for j in range(num_meas):\n",
    "            str_tmp = state_temp.measure()[0]\n",
    "            outcome.append(str_tmp[::-1])  # Take the reverse\n",
    "\n",
    "    # Note: in qiskit, qubit number counts from the left,\n",
    "    # e.g.: '00101' means we measure qubit0 a '1'.\n",
    "    return outcome\n",
    "def number_to_Pauli(pauli_num_str, N):\n",
    "    ''' Given a number string, return the corresponding Pauli string\n",
    "        0-Z, 1-X, 2-Y\n",
    "    E.g.:\n",
    "        INPUT: '01200' (in order of qubit 01234)\n",
    "        OUTPUT: 'ZZYXZ' (in order of qubit 01234)\n",
    "    '''\n",
    "    pauli_num_list = list(pauli_num_str)\n",
    "    pauli_basis_list = list(pauli_num_str)\n",
    "    for i in range(N):\n",
    "        if pauli_num_list[i] == '1':\n",
    "            pauli_basis_list[i] = 'X'\n",
    "        elif pauli_num_list[i] == '2':\n",
    "            pauli_basis_list[i] = 'Y'\n",
    "        else:\n",
    "            pauli_basis_list[i] = 'Z'\n",
    "    return ''.join(pauli_basis_list)\n",
    "def random_distribute(N_meas, N):\n",
    "    '''N_meas is the total number of measurements for all basis\n",
    "    '''\n",
    "    quotient = N_meas//3**N\n",
    "    remainder = N_meas%3**N\n",
    "    num_of_meas_list = quotient*np.ones(3**N)\n",
    "    \n",
    "    tmp = list(range(0,3**N))\n",
    "    lucky_dog = random.sample(tmp, int(remainder))\n",
    "\n",
    "    for i in range(remainder):\n",
    "        num_of_meas_list[lucky_dog[i]] = num_of_meas_list[lucky_dog[i]]+1\n",
    "\n",
    "    return num_of_meas_list\n",
    "def generate_meas_dataset(state, N_meas, N):\n",
    "    '''Generate measurement dataset for a N-qubit quantum state\n",
    "    Args:\n",
    "        state: A quantum state from Qiskit\n",
    "        N_meas: total number of measurements for all basis\n",
    "        N: number of qubits of the state\n",
    "    Yeilds:\n",
    "        Dict_meas_outcome\n",
    "    '''\n",
    "    Dict_meas_outcome = dict()\n",
    "    num_meas_list = random_distribute(N_meas, N) # A list of integers, of which each element represent the number of measurement for one basis\n",
    "    for i in range(3 ** N):\n",
    "        qubits_meas_basis = tenToAny(i, N, 3)\n",
    "        meas_outcome_string = meas(qubits_meas_basis, state, int(num_meas_list[i]), N)\n",
    "        Dict_meas_outcome[number_to_Pauli(''.join(qubits_meas_basis), N)] = meas_outcome_string\n",
    "    return Dict_meas_outcome\n",
    "def tenToAny(origin, N, n):\n",
    "    # 10进制转换为n进制list\n",
    "    list = []\n",
    "    while True:\n",
    "        s = origin // n\n",
    "        tmp = origin % n\n",
    "        list.append(tmp)\n",
    "        if s == 0:\n",
    "            break\n",
    "        origin = s\n",
    "    list.reverse()\n",
    "    list = [str(each) for each in list]\n",
    "    while len(list) < N:\n",
    "        list.insert(0, '0')\n",
    "    return list\n",
    "def generate_PauliStrList(N):\n",
    "    ''' Given the number of qubits N, return its corresponding Pauli vector.\n",
    "    E.g.:\n",
    "        INPUT: N=2\n",
    "        OUTPUT: ['II','IX',...'ZZ']\n",
    "    '''\n",
    "    Pauli_str_list = []\n",
    "    for i in range(4 ** N):\n",
    "        pauli_num_list = tenToAny(i, N, 4)\n",
    "        pauli_basis_list = pauli_num_list\n",
    "        for j in range(N):\n",
    "            if pauli_num_list[j] == '0':\n",
    "                pauli_basis_list[j] = 'I'\n",
    "            elif pauli_num_list[j] == '1':\n",
    "                pauli_basis_list[j] = 'X'\n",
    "            elif pauli_num_list[j] == '2':\n",
    "                pauli_basis_list[j] = 'Y'\n",
    "            else:\n",
    "                pauli_basis_list[j] = 'Z'\n",
    "        Pauli_str_list.append(''.join(pauli_basis_list))\n",
    "\n",
    "    return Pauli_str_list\n",
    "def generate_sub_PauliStrList(PauliStrList, index):\n",
    "    # Stupid version\n",
    "    ''' Given a index (list) of qubits, retrun the Pauli vectors of this sub system.\n",
    "    E.g.:\n",
    "        INPUT: PauliStrList=['III',...'ZZZ'], index=[0,2]\n",
    "        OUTPUT: ['III','IIX','IIY','IIZ','XII','XIX',...'ZIZ']\n",
    "    '''\n",
    "    output = list()\n",
    "    no_meas = list(set(list(range(N))) - set(index))\n",
    "    for i in PauliStrList:\n",
    "        trigger = bool(1)\n",
    "        for j in no_meas:\n",
    "            trigger = bool(trigger and i[int(j)] == 'I')\n",
    "        if trigger: output.append(i)\n",
    "\n",
    "    return output\n",
    "def generate_sub_PauliStrList(N, index_list):\n",
    "    # Less-complexity version\n",
    "    base_string = 'I' * N\n",
    "    output_strings = []\n",
    "\n",
    "    for combination in itertools.product('IXYZ', repeat=len(index_list)):\n",
    "        if all(c == 'I' for c in combination):\n",
    "            continue\n",
    "\n",
    "        temp_string = list(base_string)\n",
    "        for index, char in zip(index_list, combination):\n",
    "            temp_string[index] = char\n",
    "\n",
    "        output_strings.append(''.join(temp_string))\n",
    "\n",
    "    return output_strings\n",
    "def parity_check(meas_string):\n",
    "    ''' Given a measurement outcome binary string array,\n",
    "        return 0 if #1 in the string is even, otherwise return 1 for each element\n",
    "    E.g.:\n",
    "        INPUT: ['0001', '0101', '0000']\n",
    "        OUTPUT: [-1, 1, 1]\n",
    "    '''\n",
    "    num_of_meas = len(meas_string)\n",
    "    meas_parity = np.zeros(num_of_meas)\n",
    "    for i in range(num_of_meas):\n",
    "        temp = bin(int(meas_string[i], 2)).count(\"1\")\n",
    "        if temp % 2 == 0:\n",
    "            meas_parity[i] = 1\n",
    "        else:\n",
    "            meas_parity[i] = -1\n",
    "    return meas_parity\n",
    "def exp_var_calculator(measurement_dataset, pauli_basis_str):\n",
    "    ''' Given a Pauli basis (on partial qubits, e.g.: XIXZY, IIIXX, ZIIII, etc.) and dataset,\n",
    "        return its applicable measurement outcome expectation value and variance.\n",
    "    '''\n",
    "    #measurement_dataset = {key: value for key, value in measurement_dataset.items() if value} # For reducing the complexity\n",
    "    output = list([])\n",
    "    for key in measurement_dataset:\n",
    "        if pauli_basis_str.count('I') == sum(char1 != char2 for char1, char2 in zip(pauli_basis_str, key)):\n",
    "            output = measurement_dataset[key] + output\n",
    "\n",
    "    while pauli_basis_str.find('I') != -1:\n",
    "        index_I = pauli_basis_str.find('I')\n",
    "        pauli_basis_str = pauli_basis_str[:index_I] + pauli_basis_str[(index_I + 1):]\n",
    "        for j in range(len(output)):\n",
    "            words = output[j]\n",
    "            output[j] = words[:index_I] + words[(index_I + 1):]\n",
    "\n",
    "    meas_outcome = parity_check(output)\n",
    "    N_meas_sub = len(output)\n",
    "    \n",
    "    if N_meas_sub == 0:\n",
    "        expectation_value = 0\n",
    "        variance = 0\n",
    "    else: \n",
    "        expectation_value = np.average(meas_outcome)\n",
    "        variance = np.var(meas_outcome)\n",
    "\n",
    "    return expectation_value, variance\n",
    "def num_meas_sub_calculator(measurement_dataset, pauli_basis_str):\n",
    "    ''' Given a Pauli basis (on partial qubits, e.g.: XIXZY, IIIXX, ZIIII, etc.) and dataset,\n",
    "        return the number of measurements performed in this basis\n",
    "    '''\n",
    "    output = list([])\n",
    "    for key in measurement_dataset:\n",
    "        if pauli_basis_str.count('I') == sum(char1 != char2 for char1, char2 in zip(pauli_basis_str, key)):\n",
    "            output = measurement_dataset[key] + output\n",
    "\n",
    "    while pauli_basis_str.find('I') != -1:\n",
    "        index_I = pauli_basis_str.find('I')\n",
    "        pauli_basis_str = pauli_basis_str[:index_I] + pauli_basis_str[(index_I + 1):]\n",
    "        for j in range(len(output)):\n",
    "            words = output[j]\n",
    "            output[j] = words[:index_I] + words[(index_I + 1):]\n",
    "\n",
    "    return len(output)\n",
    "def pauliToMatrix(pauli_str):\n",
    "    '''Given a Pauli string basis (str),\n",
    "       output its corresponding matrix representation (Qobj data).\n",
    "    '''\n",
    "    pauli_basis_list = list()\n",
    "    for basis in pauli_str:\n",
    "        if basis == 'I':\n",
    "            pauli_basis_list.append(qeye(2))\n",
    "        elif basis == 'X':\n",
    "            pauli_basis_list.append(sigmax())\n",
    "        elif basis == 'Y':\n",
    "            pauli_basis_list.append(sigmay())\n",
    "        else:\n",
    "            pauli_basis_list.append(sigmaz())\n",
    "    return tensor(pauli_basis_list)\n",
    "def q_tomography_dm(qubit_index, measurement_dataset, N):\n",
    "    ''' Do quantum tomography for certain qubits according to the index,\n",
    "        output the constructed density matrix.\n",
    "    '''\n",
    "    density_matrix = 0\n",
    "    for basis in generate_sub_PauliStrList(N, qubit_index):\n",
    "        expectation, variance = exp_var_calculator(measurement_dataset, basis)\n",
    "        sub_basis = ''.join([basis[i] for i in qubit_index])\n",
    "        density_matrix += expectation * pauliToMatrix(sub_basis)\n",
    "    density_matrix += tensor([qeye(2)] * len(qubit_index))\n",
    "    return 1 / (2 ** len(qubit_index)) * density_matrix\n",
    "def q_tomography_vec(qubit_index, measurement_dataset):\n",
    "    ''' Do quantum tomography for certain qubits according to the index,\n",
    "        output a list of expectation value.\n",
    "    '''\n",
    "    bloch_vec = []\n",
    "    for basis in generate_sub_PauliStrList(N, qubit_index):\n",
    "        expectation, variance = exp_var_calculator(measurement_dataset, basis)\n",
    "        bloch_vec.append(expectation)\n",
    "    return bloch_vec\n",
    "def Wald_interval(qubit_index, confidence_level, measurement_dataset, N):\n",
    "    ''' Given a qubit index (e.g. [0,1,2], in order of 01234...),\n",
    "        return the corresponding Wald_interval for each expectation value\n",
    "    '''\n",
    "    error_rate = 1 - confidence_level\n",
    "    z = norm.ppf(1 - error_rate / 2)  # Quantile of the input confidence level for binomial distribution\n",
    "    mean_vec = np.array(q_tomography_vec(qubit_index, measurement_dataset))\n",
    "    p_vec = 0.5 * (1 + mean_vec)\n",
    "\n",
    "    basis_list = generate_sub_PauliStrList(N, qubit_index)\n",
    "    sigma = []\n",
    "    for i in range(len(basis_list)):\n",
    "        num_meas_sub = num_meas_sub_calculator(measurement_dataset, basis_list[i])\n",
    "        sigma.append(2 * z * ((p_vec[i] * (1 - p_vec[i]) / num_meas_sub) ** 0.5))\n",
    "\n",
    "    return sigma\n",
    "def Wald_interval_bisection(coef, qubit_index, confidence_level, measurement_dataset, N):\n",
    "    ''' Given a qubit index (in order of 01234...),\n",
    "        return the corresponding Wald_interval for each expectation value.\n",
    "        But here \"bisection\" means we add an additional coefficient,\n",
    "        so that we can use bisection method to find the solution of the SDP within a certain domain defined by a threshold\n",
    "    '''\n",
    "    error_rate = 1 - confidence_level\n",
    "    z = norm.ppf(1 - error_rate / 2)  # Quantile of the input confidence level for binomial distribution\n",
    "    mean_vec = np.array(q_tomography_vec(qubit_index, measurement_dataset))\n",
    "    p_vec = 0.5 * (1 + mean_vec)\n",
    "\n",
    "    basis_list = generate_sub_PauliStrList(N, qubit_index)\n",
    "    sigma = []\n",
    "    for i in range(len(basis_list)):\n",
    "        num_meas_sub = num_meas_sub_calculator(measurement_dataset, basis_list[i])\n",
    "        sigma.append(2 * coef * z * ((p_vec[i] * (1 - p_vec[i]) / num_meas_sub) ** 0.5))\n",
    "    sigma = np.nan_to_num(sigma, nan=1)\n",
    "    return sigma\n",
    "def Wilson_interval_bisection(coef, qubit_index, confidence_level, measurement_dataset, N):\n",
    "    ''' Given a qubit index (in order of 01234...),\n",
    "        return the corresponding Wilson_interval for each expectation value.\n",
    "        But here \"bisection\" means we add an additional coefficient,\n",
    "        so that we can use bisection method to find the solution of the SDP within a certain domain defined by a threshold\n",
    "    '''\n",
    "    error_rate = 1 - confidence_level\n",
    "    z = norm.ppf(1 - error_rate / 2)  # Quantile of the input confidence level for binomial distribution\n",
    "\n",
    "    mean_vec = np.array(q_tomography_vec(qubit_index, measurement_dataset))\n",
    "    p_vec = 0.5 * (1 + mean_vec)\n",
    "\n",
    "    basis_list = generate_sub_PauliStrList(N, qubit_index)\n",
    "    sigma = []\n",
    "    for i in range(len(basis_list)):\n",
    "        num_meas_sub = num_meas_sub_calculator(measurement_dataset, basis_list[i])\n",
    "        sigma.append(2*coef*z/(1+z*z/num_meas_sub)*math.sqrt((p_vec[i]*(1-p_vec[i]) + z*z/(4*num_meas_sub)) / num_meas_sub))\n",
    "    sigma = np.nan_to_num(sigma, nan=1)\n",
    "    return sigma\n",
    "def Bloch_vec(qiskit_state, qubit_index):\n",
    "    ''' Given a qiskit quantum state and the qubit index,\n",
    "        return the Bloch vector of the reduced state according to the index\n",
    "    '''\n",
    "    output = []\n",
    "    for basis in generate_sub_PauliStrList(N, qubit_index):\n",
    "        basis = basis[::-1]\n",
    "        output.append(qiskit_state.expectation_value(oper=Pauli(basis), qargs=None))\n",
    "    return output\n",
    "def qubit_swap(N, state_43210):\n",
    "    circSWAP = QuantumCircuit(N)\n",
    "    for i in range(int(N / 2)):\n",
    "        circSWAP.swap(i, N - 1 - i)\n",
    "    U_SWAP = Operator(circSWAP)\n",
    "    state_01234 = state_43210.evolve(U_SWAP)\n",
    "    return state_01234\n",
    "def generate_random_dm(purity, N):\n",
    "    '''Generate a random density matrix with a certain purity\n",
    "    '''\n",
    "    qiskit_state = DensityMatrix(random_statevector(2 ** N))\n",
    "    PauliStrList = generate_PauliStrList(N)[1:]\n",
    "\n",
    "    Bloch_vector = []\n",
    "    for basis in PauliStrList:\n",
    "        Bloch_vector.append(qiskit_state.expectation_value(oper=Pauli(basis), qargs=None))\n",
    "    Bloch_vector_noisy = math.sqrt(((2 ** N) * purity - 1) / (2 ** N - 1)) * np.array(Bloch_vector)\n",
    "\n",
    "    density_matrix = tensor([qeye(2)] * N)\n",
    "    for i in range(4 ** N - 1):\n",
    "        density_matrix += Bloch_vector_noisy[i] * pauliToMatrix(PauliStrList[i])\n",
    "    return 1 / (2 ** N) * np.array(density_matrix)\n",
    "\n",
    "# Hamiltonian and plot\n",
    "def Hamiltonian_matrix(H):\n",
    "    '''Given a list of Pauli string for each subsystem,\n",
    "       output a list of their matrix representation.\n",
    "    '''\n",
    "    Hamiltonian_matrix = 0\n",
    "    for i in range(len(H)):\n",
    "        Hamiltonian_matrix = Hamiltonian_matrix + (pauliToMatrix(H[i]))\n",
    "    return Hamiltonian_matrix\n",
    "def Hamiltonian_global(H_local_list, N, M, K):\n",
    "    '''Given the Hamiltonian of local subsystem (list of Pauli strings)\n",
    "       return the Hamiltonian of global system (list of Pauli strings)\n",
    "    '''\n",
    "    H_global = []\n",
    "    for i in range(K):\n",
    "        for h in H_local_list:\n",
    "            H_global.append(i * 'I' + h + (N - M - i) * 'I')\n",
    "    return H_global\n",
    "def ground_state(H_matrix):\n",
    "    '''Given a matrix representation of a Hamiltonian,\n",
    "       find the ground state energy, i.e. the minimum eigenvalue of the matrix,\n",
    "       and the ground state density matrix\n",
    "    '''\n",
    "    H_matrix = np.array(H_matrix)\n",
    "    eigenvalue, eigenvector = np.linalg.eigh(H_matrix)\n",
    "\n",
    "    tmp = np.argsort(eigenvalue)\n",
    "    ground_state_energy = eigenvalue[tmp[0]]\n",
    "    ground_state_vec = np.array(eigenvector[:, tmp[0]])\n",
    "\n",
    "    ground_state_dm = np.outer(ground_state_vec, np.conj(ground_state_vec))\n",
    "\n",
    "    return ground_state_energy, ground_state_dm\n",
    "def N_meas_list_func(start, end, num):\n",
    "    '''Generate a list of number of measurement for the loop\n",
    "    '''\n",
    "    a = pow(end / start, 1 / (num - 1))\n",
    "    N_meas_list = [start]\n",
    "    for i in range(num - 1):\n",
    "        N_meas_list.append(math.floor(a * N_meas_list[-1]))\n",
    "\n",
    "    return N_meas_list\n",
    "def gs_energy_estimate(measurement_dataset, confidence_level, H_global_list):\n",
    "    '''Given the Pauli decomposition of the Hamiltonian of interest and measurement dataset\n",
    "       return the expectaion value of the Hamiltonian (with confidence interval)\n",
    "    '''\n",
    "    E_min = 0\n",
    "    E_max = 0\n",
    "    error_rate = 1 - confidence_level\n",
    "    z = norm.ppf(1 - error_rate / 2)  # Quantile of the input confidence level for binomial distribution\n",
    "    \n",
    "    for pauli_basis_str in H_global_list:\n",
    "        exp, var = exp_var_calculator(measurement_dataset, pauli_basis_str)\n",
    "        num_meas_sub = num_meas_sub_calculator(measurement_dataset, pauli_basis_str)\n",
    "        p_value = 0.5 * (1 + exp)\n",
    "        sigma = z * ((p_value * (1 - p_value) / num_meas_sub) ** 0.5)\n",
    "        E_min = E_min + exp - 2*sigma\n",
    "        E_max = E_max + exp + 2*sigma\n",
    "\n",
    "    return E_min, E_max\n",
    "def gs_energy_estimate(measurement_dataset, confidence_level, H_global_list):\n",
    "    '''Given the Pauli decomposition of the Hamiltonian of interest and measurement dataset\n",
    "       return the expectaion value of the Hamiltonian (with confidence interval)\n",
    "       This version is more rigorous.\n",
    "    '''\n",
    "    E_sum = 0\n",
    "    var_sum = 0\n",
    "    error_rate = 1 - confidence_level\n",
    "    z = norm.ppf(1 - error_rate / 2)  # Quantile of the input confidence level for binomial distribution\n",
    "    \n",
    "    for pauli_basis_str in H_global_list:\n",
    "        exp, var = exp_var_calculator(measurement_dataset, pauli_basis_str)\n",
    "        num_meas_sub = num_meas_sub_calculator(measurement_dataset, pauli_basis_str)\n",
    "        E_sum = E_sum + exp\n",
    "        var_sum = var_sum + var/num_meas_sub\n",
    "\n",
    "    E_min = E_sum - 2.58*var_sum**0.5\n",
    "    E_max = E_sum + 2.58*var_sum**0.5\n",
    "\n",
    "    return E_min, E_max\n",
    "def lower_bound_with_SDP(H, N, M, K, P):\n",
    "    '''Solve the SDP minimization problem with constraints C0 and C0+C1\n",
    "    '''\n",
    "\n",
    "    K_3body = N-G+1 # Number of 3-body subsystems\n",
    "    P_3body = 4**G-1 # Number of Pauli basis for 3-body subsystems\n",
    "    ep = cp.Variable((K, P))\n",
    "    ep_C1 = cp.Variable((N-G+1, 4**G-1))\n",
    "\n",
    "    # Define SDP variables\n",
    "    dm_tilde = []\n",
    "    for k in range(K):\n",
    "        dm_tilde.append( np.array(tensor([qeye(2)] * M)) / 2 **M )\n",
    "    for k in range(K):\n",
    "        for p in range(P):\n",
    "            dm_tilde[k] = dm_tilde[k] + cp.multiply(ep[k, p], np.array(pauliToMatrix(PauliStrList_part[p])))\n",
    "    dm_tilde_C1 = []\n",
    "    for k in range(K_3body):\n",
    "        dm_tilde_C1.append( np.array(tensor([qeye(2)] * G)) / 2 ** G )\n",
    "    for k in range(K_3body): \n",
    "        for p in range(P_3body):\n",
    "            dm_tilde_C1[k] = dm_tilde_C1[k] + cp.multiply(ep_C1[k, p], np.array(pauliToMatrix(PauliStrList_Gbody[p])))\n",
    "\n",
    "            \n",
    "\n",
    "    constraints_C0 = []\n",
    "    for i in range(K):  # non-negative eigenvalues\n",
    "        constraints_C0 += [dm_tilde[i] >> 1e-8]\n",
    "    for i in range(K - 1):  # physically compatitble\n",
    "        constraints_C0 += [cp.partial_trace(dm_tilde[i], dims=[2] * M, axis=0) ==\n",
    "                        cp.partial_trace(dm_tilde[i + 1], dims=[2] * M, axis=M - 1)]\n",
    "\n",
    "    constraints_C1 = []\n",
    "    for i in range(K_3body): \n",
    "        constraints_C1 += [dm_tilde_C1[i] >> 1e-8]  # non-negative eigenvalues\n",
    "\n",
    "    for i in range(K_3body):\n",
    "        constraints_C1 += [cp.partial_trace(dm_tilde_C1[i], dims=[4,2], axis=1) == dm_tilde[i]]\n",
    "        constraints_C1 += [cp.partial_trace(dm_tilde_C1[i], dims=[2,4], axis=0) == dm_tilde[i+1]]\n",
    "\n",
    "\n",
    "    # Solve SDP with conditions C1+C0\n",
    "    H_exp01 = 0\n",
    "    for i in range(K):\n",
    "        H_exp01 = H_exp01 + H @ dm_tilde[i]\n",
    "    prob_C01 = cp.Problem(\n",
    "        cp.Minimize(\n",
    "            cp.real(\n",
    "                cp.trace(\n",
    "                    H_exp01\n",
    "                )\n",
    "            )\n",
    "        ), constraints_C0 + constraints_C1\n",
    "    )\n",
    "    energy_C01 = prob_C01.solve(solver=cp.SCS, verbose=False)\n",
    "\n",
    "    return energy_C01\n",
    "\n",
    "# SDP problem variables and constraints\n",
    "def SDP_variables_C0(ep, measurement_dataset, N, M, K, P):\n",
    "    '''Define SDP variables'''\n",
    "    dm = []\n",
    "    for k in range(K):  # K: number of subsystems\n",
    "        index = list(range(k, k + M, 1))  # [k, k+1, ...]\n",
    "        dm.append(np.array(q_tomography_dm(index, measurement_dataset, N)))\n",
    "    dm_hat = dm\n",
    "    dm_tilde = dm\n",
    "    for k in range(K):\n",
    "        for p in range(P):\n",
    "            dm_tilde[k] = dm_tilde[k] + cp.multiply(ep[k, p], np.array(pauliToMatrix(PauliStrList_part[p])))\n",
    "    return dm_tilde, dm_hat\n",
    "def constraints_C0(ep, coef, dm_tilde, measurement_dataset, N, M, K, P):\n",
    "    '''Define the constraints of the SDP for bisection method:\n",
    "       1. non-negative eigenvalues\n",
    "       2. physically compatitble\n",
    "    '''\n",
    "    constraints = []\n",
    "    for i in range(K):  # non-negative eigenvalues\n",
    "        constraints += [dm_tilde[i] >> 1e-8]\n",
    "    for i in range(K - 1):  # physically compatitble\n",
    "        constraints += [cp.partial_trace(dm_tilde[i], dims=[2] * M, axis=0) ==\n",
    "                        cp.partial_trace(dm_tilde[i+1], dims=[2] * M, axis=M - 1)]\n",
    "\n",
    "    sigma = np.zeros((K, P))\n",
    "    for i in range(K):\n",
    "        index = list(range(i, i + M, 1))  # [i, i+1, ...]\n",
    "        sigma[i] = Wilson_interval_bisection(coef, index, 0.95, measurement_dataset, N)\n",
    "    constraints += [ep >= -sigma, ep <= sigma]\n",
    "\n",
    "    return constraints\n",
    "def constraints_interval(ep, coef, dm_tilde, measurement_dataset, N, M, K, P):\n",
    "    '''Define the constraints of the SDP for bisection method:\n",
    "       1. non-negative eigenvalues\n",
    "    '''\n",
    "    constraints = []\n",
    "    sigma = np.zeros((K, P))\n",
    "    for i in range(K):\n",
    "        index = list(range(i, i + M, 1))  # [i, i+1, ...]\n",
    "        sigma[i] = Wilson_interval_bisection(coef, index, 0.95, measurement_dataset, N)\n",
    "    constraints += [ep >= -sigma, ep <= sigma]\n",
    "\n",
    "    return constraints\n",
    "def SDP_variables_verify(ep_verify, measurement_dataset, N):\n",
    "    '''Define the varibles of global verification problem\n",
    "    '''\n",
    "    dm_tilde_full = np.array(tensor([qeye(2)] * N)) / 2 ** N\n",
    "    for i in range(4 ** N - 1):\n",
    "        dm_tilde_full = dm_tilde_full + cp.multiply(ep_verify[i], np.array(pauliToMatrix(PauliStrList[i])))\n",
    "    return dm_tilde_full\n",
    "def constraints_verify(ep_verify, coef, dm_tilde, dm_tilde_full, measurement_dataset, N, M, K):\n",
    "    '''Define the constraints of global verification problem:\n",
    "       1. non-negative eigenvalues\n",
    "       2. there exists a global state whose reduced states are the corresponding subsystems' states\n",
    "    '''\n",
    "    constraints_verify = []\n",
    "    constraints_verify += [dm_tilde_full >> 1e-8]  # non-negative eigenvalues\n",
    "\n",
    "    # global verification\n",
    "    constraints_verify += [cp.partial_trace(dm_tilde_full, dims=[2 ** M, 2 ** (N - M)], axis=1) == dm_tilde[0]]\n",
    "    constraints_verify += [cp.partial_trace(dm_tilde_full, dims=[2 ** (N - M), 2 ** M], axis=0) == dm_tilde[-1]]\n",
    "    # constraints_verify += [cp.partial_trace(cp.partial_trace(dm_tilde_full, dims=[2,4,2], axis=0), dims=[4,2], axis=1) == dm_tilde[1]]\n",
    "\n",
    "    if K >= 3:\n",
    "        for i in range(K - 2):\n",
    "            constraints_verify += [cp.partial_trace(\n",
    "                cp.partial_trace(dm_tilde_full, dims=[2 ** (i + 1), 2 ** M, 2 ** (N - M - i - 1)], axis=2),\n",
    "                dims=[2 ** (i + 1), 2 ** M], axis=0) == dm_tilde[i + 1]]\n",
    "\n",
    "    constraints_verify += [ep_verify >= -1, ep_verify <= 1]\n",
    "\n",
    "    return constraints_verify\n",
    "def SDP_variables_C1(ep_C1, measurement_dataset, N, G):\n",
    "    '''Define SDP variables for C1\n",
    "    '''\n",
    "    K_3body = N-G+1 # Number of 3-body subsystems\n",
    "    P_3body = 4**G-1 # Number of Pauli basis for 3-body subsystems\n",
    "    \n",
    "    dm_tilde_C1 = []\n",
    "    for k in range(K_3body):\n",
    "        dm_tilde_C1.append( np.array(tensor([qeye(2)] * G)) / 2 ** G )\n",
    "\n",
    "    for k in range(K_3body): \n",
    "        for p in range(P_3body):\n",
    "            dm_tilde_C1[k] = dm_tilde_C1[k] + cp.multiply(ep_C1[k, p], np.array(pauliToMatrix(PauliStrList_Gbody[p])))\n",
    "    \n",
    "    return dm_tilde_C1\n",
    "def constraints_C1(ep_C1, coef, dm_tilde, dm_tilde_C1, measurement_dataset, N, M, G):\n",
    "    '''Define the constraints of 3-body SDP problem (C1):\n",
    "       1. non-negative eigenvalues\n",
    "       2. there exists a 3-body global state whose reduced states are the corresponding subsystems' states\n",
    "    '''\n",
    "    K_3body = N-G+1 # Number of 3-body subsystems\n",
    "    P_3body = 4**G-1 # Number of Pauli basis for 3-body subsystems\n",
    "\n",
    "    constraints_C1 = []\n",
    "    for i in range(K_3body): \n",
    "        constraints_C1 += [dm_tilde_C1[i] >> 1e-8]  # non-negative eigenvalues\n",
    "\n",
    "    for i in range(K_3body):\n",
    "        constraints_C1 += [cp.partial_trace(dm_tilde_C1[i], dims=[4,2], axis=1) == dm_tilde[i]]\n",
    "        constraints_C1 += [cp.partial_trace(dm_tilde_C1[i], dims=[2,4], axis=0) == dm_tilde[i+1]]\n",
    "\n",
    "    return constraints_C1\n",
    "def SDP_variables_C2(ep_C2, measurement_dataset, N, G):\n",
    "    '''Define SDP variables for C2:\n",
    "    '''\n",
    "    K_3body = N-G+1 # Number of 3-body subsystems\n",
    "    P_3body = 4**G-1 # Number of Pauli basis for 3-body subsystems\n",
    "\n",
    "    dm = []\n",
    "    for k in range(K_3body):  # K: number of subsystems\n",
    "        index = list(range(k, k+G, 1))  # [k, k+1, ...]\n",
    "        dm.append(np.array(q_tomography_dm(index, measurement_dataset, N)))\n",
    "    dm_hat_C2 = dm\n",
    "    dm_tilde_C2 = dm\n",
    "    for k in range(K_3body):\n",
    "        for p in range(P_3body):\n",
    "            dm_tilde_C2[k] = dm_tilde_C2[k] + cp.multiply(ep_C2[k, p], np.array(pauliToMatrix(PauliStrList_Gbody[p])))\n",
    "\n",
    "    return dm_tilde_C2\n",
    "def constraints_C2(ep_C2, coef, dm_tilde, dm_tilde_C2, measurement_dataset, N, M, G):\n",
    "    '''Define the constraints of the SDP for bisection method:\n",
    "       1. there exists a 3-body global state whose reduced states are the corresponding subsystems' states\n",
    "       2. in the confidence interval\n",
    "    '''\n",
    "    K_3body = N-G+1 # Number of 3-body subsystems\n",
    "    P_3body = 4**G-1 # Number of Pauli basis for 3-body subsystems\n",
    "\n",
    "    constraints_C2 = []\n",
    "    for i in range(K_3body):\n",
    "        constraints_C2 += [cp.partial_trace(dm_tilde_C2[i], dims=[4,2], axis=1) == dm_tilde[i]]\n",
    "        constraints_C2 += [cp.partial_trace(dm_tilde_C2[i], dims=[2,4], axis=0) == dm_tilde[i+1]]\n",
    "\n",
    "    sigma = np.zeros((K_3body, P_3body))\n",
    "    for i in range(K_3body):\n",
    "        index = list(range(i, i+G, 1))  # [i, i+1, ...]\n",
    "        sigma[i] = Wilson_interval_bisection(coef, index, 0.95, measurement_dataset, N)\n",
    "    constraints_C2 += [ep_C2 >= -sigma, ep_C2 <= sigma]\n",
    "\n",
    "    return constraints_C2\n",
    "def constraints_CWM(ep, coef, dm_tilde, dm_tilde_C1, measurement_dataset, N, M, G):\n",
    "    '''Define the constraints of weak monotonicity (CWM):\n",
    "       1. Weak monotonicity: For any state rho_ABC on systems ABC, we have: S(A|B) + S(A|C) >= 0\n",
    "       2. Here we only consider WM for each 3-body global state\n",
    "       \n",
    "       Comments: \n",
    "       Unlike the classical conditional entropy, the conditional quantum entropy can be negative.\n",
    "    '''\n",
    "    K_3body = N-G+1 # Number of 3-body subsystems\n",
    "    P_3body = 4**G-1 # Number of Pauli basis for 3-body subsystems\n",
    "\n",
    "    # constraints_WM = []\n",
    "    # for i in range(K_3body):\n",
    "    #     constraints_WM += [( cp.von_neumann_entr(cp.partial_trace(dm_tilde_C1[i], dims=[2]*G, axis=G-1))+\n",
    "    #                        cp.von_neumann_entr(cp.partial_trace(dm_tilde_C1[i], dims=[2]*G, axis=0)) ) \n",
    "    #                        >= \n",
    "    #                        ( cp.von_neumann_entr(cp.partial_trace(\n",
    "    #                             cp.partial_trace(dm_tilde_C1[i], dims=[2]*G, axis=0), dims=[2]*(G-1), axis=0\n",
    "    #                        )) + \n",
    "    #                        cp.von_neumann_entr(cp.partial_trace(\n",
    "    #                             cp.partial_trace(dm_tilde_C1[i], dims=[2]*G, axis=G-1), dims=[2]*(G-1), axis=G-2\n",
    "    #                        )) )\n",
    "    #                        ]\n",
    "\n",
    "    constraints_WM = []\n",
    "    for i in range(K): # non-negative eigenvalues\n",
    "        constraints_WM += [dm_tilde[i] >> 1e-8]  \n",
    "    for i in range(K_3body):\n",
    "        constraints_WM += [cp.von_neumann_entr(dm_tilde[i])+cp.von_neumann_entr(dm_tilde[i+1]) >= \n",
    "                        cp.von_neumann_entr(cp.partial_trace(dm_tilde[i], dims=[2] * M, axis=M-1))+\n",
    "                        cp.von_neumann_entr(cp.partial_trace(dm_tilde[i+1], dims=[2] * M, axis=0))]\n",
    "\n",
    "    return constraints_WM\n",
    "\n",
    "# Solve the SDP problems\n",
    "def SDP_solver_min(coef, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P):\n",
    "    '''Solve the SDP minimization problem with constraints C0 and C0+C1\n",
    "    '''\n",
    "    \n",
    "    dm_tilde_copy0 = dm_tilde\n",
    "    dm_tilde_copy1 = dm_tilde\n",
    "    dm_tilde_copy01 = dm_tilde\n",
    "    dm_tilde_copyWM = dm_tilde\n",
    "\n",
    "    # Solve SDP with conditions C0\n",
    "    constraints0 = constraints_C0(ep, coef, dm_tilde_copy0, measurement_dataset, N, M, K, P)\n",
    "    H_exp0 = 0\n",
    "    for i in range(K):\n",
    "        H_exp0 = H_exp0 + H @ dm_tilde_copy0[i]\n",
    "    prob_C0 = cp.Problem(\n",
    "        cp.Minimize(\n",
    "            cp.real(\n",
    "                cp.trace(\n",
    "                    H_exp0\n",
    "                )\n",
    "            )\n",
    "        ), constraints0\n",
    "    )\n",
    "    energy_C0 = prob_C0.solve(solver=cp.SCS, verbose=False)\n",
    "    if prob_C0.status != cp.OPTIMAL:\n",
    "        energy_C0 = float('inf') \n",
    "\n",
    "    \n",
    "    # Solve SDP with conditions C1\n",
    "    constraints1 = constraints_C1(ep_C1, coef, dm_tilde_copy1, dm_tilde_C1, measurement_dataset, N, M, G)\n",
    "    H_exp1 = 0\n",
    "    for i in range(K):\n",
    "        H_exp1 = H_exp1 + H @ dm_tilde_copy1[i]\n",
    "    prob_C1 = cp.Problem(\n",
    "        cp.Minimize(\n",
    "            cp.real(\n",
    "                cp.trace(\n",
    "                    H_exp1\n",
    "                )\n",
    "            )\n",
    "        ), constraints1\n",
    "    )\n",
    "    energy_C1 = prob_C1.solve(solver=cp.SCS, verbose=False)\n",
    "    if prob_C1.status != cp.OPTIMAL:\n",
    "        energy_C1 = float('inf')\n",
    "\n",
    "\n",
    "    # Solve SDP with conditions C1+C0\n",
    "    constraints_0 = constraints_C0(ep, coef, dm_tilde_copy01, measurement_dataset, N, M, K, P)\n",
    "    constraints_1 = constraints_C1(ep_C1, coef, dm_tilde_copy01, dm_tilde_C1, measurement_dataset, N, M, G)\n",
    "    H_exp01 = 0\n",
    "    for i in range(K):\n",
    "        H_exp01 = H_exp01 + H @ dm_tilde_copy01[i]\n",
    "    prob_C01 = cp.Problem(\n",
    "        cp.Minimize(\n",
    "            cp.real(\n",
    "                cp.trace(\n",
    "                    H_exp01\n",
    "                )\n",
    "            )\n",
    "        ), constraints_0 + constraints_1\n",
    "    )\n",
    "    energy_C01 = prob_C01.solve(solver=cp.SCS, verbose=False)\n",
    "    if prob_C01.status != cp.OPTIMAL:\n",
    "        energy_C01 = float('inf') \n",
    "\n",
    "\n",
    "    # Solve SDP with conditions C1+C0+WM\n",
    "    constraints_0 = constraints_C0(ep, coef, dm_tilde_copyWM, measurement_dataset, N, M, K, P)\n",
    "    constraints_1 = constraints_C1(ep_C1, coef, dm_tilde_copyWM, dm_tilde_C1, measurement_dataset, N, M, G)\n",
    "    constraints_WM = constraints_CWM(ep, coef, dm_tilde_copyWM, dm_tilde_C1, measurement_dataset, N, M, G)\n",
    "    H_exp_WM = 0\n",
    "    for i in range(K):\n",
    "        H_exp_WM = H_exp_WM + H @ dm_tilde_copyWM[i]\n",
    "    prob_WM = cp.Problem(\n",
    "        cp.Minimize(\n",
    "            cp.real(\n",
    "                cp.trace(\n",
    "                    H_exp_WM\n",
    "                )\n",
    "            )\n",
    "        ), constraints_0 + constraints_1 + constraints_WM\n",
    "    )\n",
    "    energy_WM = prob_WM.solve(solver=cp.MOSEK, verbose=False)\n",
    "    if prob_WM.status != cp.OPTIMAL:\n",
    "        energy_WM = float('inf') \n",
    "\n",
    "    return energy_C0, energy_C1, energy_C01, energy_WM\n",
    "def SDP_solver_max(coef, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P):\n",
    "    '''Solve the SDP maximization problem with constraints C0 and C0+C1\n",
    "    '''\n",
    "    \n",
    "    dm_tilde_copy0 = dm_tilde\n",
    "    dm_tilde_copy1 = dm_tilde\n",
    "    dm_tilde_copy01 = dm_tilde\n",
    "\n",
    "    # Solve SDP with conditions C0\n",
    "    constraints0 = constraints_C0(ep, coef, dm_tilde_copy0, measurement_dataset, N, M, K, P)\n",
    "    H_exp0 = 0\n",
    "    for i in range(K):\n",
    "        H_exp0 = H_exp0 + H @ dm_tilde_copy0[i]\n",
    "    prob_C0 = cp.Problem(\n",
    "        cp.Maximize(\n",
    "            cp.real(\n",
    "                cp.trace(\n",
    "                    H_exp0\n",
    "                )\n",
    "            )\n",
    "        ), constraints0\n",
    "    )\n",
    "    energy_C0 = prob_C0.solve(solver=cp.SCS, verbose=False)\n",
    "    if prob_C0.status != cp.OPTIMAL:\n",
    "        energy_C0 = float('inf') \n",
    "\n",
    "    \n",
    "    # Solve SDP with conditions C1\n",
    "    constraints1 = constraints_C1(ep_C1, coef, dm_tilde_copy1, dm_tilde_C1, measurement_dataset, N, M, G)\n",
    "    H_exp1 = 0\n",
    "    for i in range(K):\n",
    "        H_exp1 = H_exp1 + H @ dm_tilde_copy1[i]\n",
    "    prob_C1 = cp.Problem(\n",
    "        cp.Maximize(\n",
    "            cp.real(\n",
    "                cp.trace(\n",
    "                    H_exp1\n",
    "                )\n",
    "            )\n",
    "        ), constraints1\n",
    "    )\n",
    "    energy_C1 = prob_C1.solve(solver=cp.SCS, verbose=False)\n",
    "    if prob_C1.status != cp.OPTIMAL:\n",
    "        energy_C1 = float('inf')\n",
    "\n",
    "\n",
    "    # Solve SDP with conditions C1+C0\n",
    "    constraints_0 = constraints_C0(ep, coef, dm_tilde_copy01, measurement_dataset, N, M, K, P)\n",
    "    constraints_1 = constraints_C1(ep_C1, coef, dm_tilde_copy01, dm_tilde_C1, measurement_dataset, N, M, G)\n",
    "    H_exp01 = 0\n",
    "    for i in range(K):\n",
    "        H_exp01 = H_exp01 + H @ dm_tilde_copy01[i]\n",
    "    prob_C01 = cp.Problem(\n",
    "        cp.Maximize(\n",
    "            cp.real(\n",
    "                cp.trace(\n",
    "                    H_exp01\n",
    "                )\n",
    "            )\n",
    "        ), constraints_0 + constraints_1\n",
    "    )\n",
    "    energy_C01 = prob_C01.solve(solver=cp.SCS, verbose=False)\n",
    "    if prob_C01.status != cp.OPTIMAL:\n",
    "        energy_C01 = float('inf') \n",
    "\n",
    "    return energy_C0, energy_C1, energy_C01\n",
    "def biSection_search_min(higher_bound, threshold, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P):\n",
    "    '''Use bi-search method to find the minimum value of the relaxation such that there exists at least one solution in the search space,\n",
    "       with an accuracy of 'threshold'\n",
    "    '''\n",
    "\n",
    "    low = 0\n",
    "    high = higher_bound\n",
    "    max_iter = 6\n",
    "   \n",
    "    energy_C0, energy_C1, energy_C01 = SDP_solver_min(high, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P)\n",
    "    coef = high\n",
    "    \n",
    "    # If no solution exists within the initial higher bounds, increase the higher bound.\n",
    "    while (math.isinf(energy_C0) or math.isinf(energy_C1) or math.isinf(energy_C01)) and max_iter > 0:\n",
    "        low = high\n",
    "        high = 2*high\n",
    "        max_iter = max_iter-1\n",
    "        energy_C0, energy_C1, energy_C01 = SDP_solver_min(high, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P)\n",
    "\n",
    "    # If still no solution after expanding the bounds, return an error message.\n",
    "    if max_iter == 0:\n",
    "        return \"No solution found within the search bounds and maximum iterations.\"\n",
    "    \n",
    "    # Perform the binary search within the updated bounds.\n",
    "    while abs(high - low) >= threshold:\n",
    "        coef = low + abs(high - low) / 2\n",
    "        energy_C0_result, energy_C1_result, energy_C01_result = SDP_solver_min(coef, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P)\n",
    "        if (math.isinf(energy_C0_result) or math.isinf(energy_C1) or math.isinf(energy_C01_result)):\n",
    "            low = coef\n",
    "        else:\n",
    "            high = coef\n",
    "            energy_C0 = energy_C0_result\n",
    "            energy_C1 = energy_C1_result\n",
    "            energy_C01 = energy_C01_result\n",
    "\n",
    "    # # Perform the binary search within the updated bounds.\n",
    "    # while abs(high - low) > threshold or (math.isinf(energy_C0) or math.isinf(energy_C01)):\n",
    "    #     coef = low + abs(high - low) / 2\n",
    "    #     energy_C0, energy_C01 = SDP_solver_min(coef, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P)\n",
    "    #     if (math.isinf(energy_C0) or math.isinf(energy_C01)):\n",
    "    #         low = coef\n",
    "    #     else:\n",
    "    #         high = coef\n",
    "\n",
    "    return energy_C0, energy_C1, energy_C01, coef\n",
    "def biSection_search_max(higher_bound, threshold, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P):\n",
    "    '''Use bi-search method to find the minimum value of the relaxation such that there exists at least one solution in the search space,\n",
    "       with an accuracy of 'threshold'\n",
    "    '''\n",
    "\n",
    "    low = 0\n",
    "    high = higher_bound\n",
    "    max_iter = 6\n",
    "   \n",
    "    energy_C0, energy_C1, energy_C01 = SDP_solver_max(high, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P)\n",
    "    coef = high\n",
    "    \n",
    "    # If no solution exists within the initial higher bounds, increase the higher bound.\n",
    "    while (math.isinf(energy_C0) or math.isinf(energy_C1) or math.isinf(energy_C01)) and max_iter > 0:\n",
    "        low = high\n",
    "        high = 2*high\n",
    "        max_iter = max_iter-1\n",
    "        energy_C0, energy_C1, energy_C01 = SDP_solver_max(high, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P)\n",
    "\n",
    "    # If still no solution after expanding the bounds, return an error message.\n",
    "    if max_iter == 0:\n",
    "        return \"No solution found within the search bounds and maximum iterations.\"\n",
    "    \n",
    "    # Perform the binary search within the updated bounds.\n",
    "    while abs(high - low) >= threshold:\n",
    "        coef = low + abs(high - low) / 2\n",
    "        energy_C0_result, energy_C1_result, energy_C01_result = SDP_solver_max(coef, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P)\n",
    "        if (math.isinf(energy_C0_result) or math.isinf(energy_C1) or math.isinf(energy_C01_result)):\n",
    "            low = coef\n",
    "        else:\n",
    "            high = coef\n",
    "            energy_C0 = energy_C0_result\n",
    "            energy_C1 = energy_C1_result\n",
    "            energy_C01 = energy_C01_result\n",
    "\n",
    "    # # Perform the binary search within the updated bounds.\n",
    "    # while abs(high - low) > threshold or (math.isinf(energy_C0) or math.isinf(energy_C01)):\n",
    "    #     coef = low + abs(high - low) / 2\n",
    "    #     energy_C0, energy_C01 = SDP_solver_min(coef, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P)\n",
    "    #     if (math.isinf(energy_C0) or math.isinf(energy_C01)):\n",
    "    #         low = coef\n",
    "    #     else:\n",
    "    #         high = coef\n",
    "\n",
    "    return energy_C0, energy_C1, energy_C01, coef\n",
    "def biSection_gs(coef_gs, threshold, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P):\n",
    "    '''Use bi-search method to find the approximation of ground state energy\n",
    "    '''\n",
    "\n",
    "    low = 0\n",
    "    max_iter = 6\n",
    "    high = coef_gs\n",
    "   \n",
    "    energy_C0, energy_C01 = SDP_solver_min(high, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P)\n",
    "    coef = high\n",
    "    \n",
    "    # If no solution exists within the initial higher bounds, increase the higher bound.\n",
    "    while (math.isinf(energy_C0) or math.isinf(energy_C01)) and max_iter > 0:\n",
    "        low = high\n",
    "        high = 2*high\n",
    "        max_iter = max_iter-1\n",
    "        energy_C0, energy_C01 = SDP_solver_min(high, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P)\n",
    "    energy_C0_gs = energy_C0 # Store the SDP solutions when the value of relaxation equals the higher bound (to approch the ground energy)\n",
    "    energy_C01_gs = energy_C01 # Store the SDP solutions when the value of relaxation equals the higher bound (to approch the ground energy)\n",
    "\n",
    "    # If still no solution after expanding the bounds, return an error message.\n",
    "    if max_iter == 0:\n",
    "        return \"No solution found within the search bounds and maximum iterations.\"\n",
    "\n",
    "    return energy_C0_gs, energy_C01_gs, coef\n",
    "\n",
    "# Main functions\n",
    "def jordi_min(repetition, N_meas_list, higher_bound, threshold, N, M, K, P):\n",
    "    '''Solve the SDP minimization and maximization problem with the two different constraints for a list of number of measurement\n",
    "    '''\n",
    "\n",
    "    E_min = []\n",
    "    E_max = []\n",
    "\n",
    "    E_min_C0 = []\n",
    "    E_min_C1 = []\n",
    "    E_min_C01 = []\n",
    "    coef_min = []\n",
    "\n",
    "    for N_meas in N_meas_list:\n",
    "        path = f'meas_dataset/N={N}/N{N}_Meas{N_meas}.npy'\n",
    "        data = np.load(path, allow_pickle=True)\n",
    "        measurement_dataset = data[repetition]\n",
    "        measurement_dataset = {key: value for key, value in measurement_dataset.items() if value} # For reducing the complexity\n",
    "        N_meas_sub = N_meas * (3 ** (N - M))\n",
    "\n",
    "        ep = cp.Variable((K, P))\n",
    "        ep_C1 = cp.Variable((N-G+1, 4**G-1))\n",
    "        dm_tilde, dm_hat = SDP_variables_C0(ep, measurement_dataset, N, M, K, P)\n",
    "        dm_tilde_C1 = SDP_variables_C1(ep_C1, measurement_dataset, N, G)\n",
    "\n",
    "        # Energy with SDP - minimum\n",
    "        E_min_C0_value, E_min_C1_value, E_min_C01_value, coef_min_value = biSection_search_min(higher_bound, threshold, \n",
    "                                                                               ep, ep_C1, dm_tilde, dm_tilde_C1, \n",
    "                                                                               H_local, measurement_dataset, \n",
    "                                                                               N, M, K, P\n",
    "                                                                               )\n",
    "        E_min_C0.append(E_min_C0_value)\n",
    "        E_min_C1.append(E_min_C1_value)\n",
    "        E_min_C01.append(E_min_C01_value)\n",
    "        coef_min.append(coef_min_value)\n",
    "        \n",
    "        # Average energy calculated from measurements\n",
    "        E_min_and_max = gs_energy_estimate(measurement_dataset, 0.99, H_global_list)\n",
    "        E_min.append(E_min_and_max[0])\n",
    "        E_max.append(E_min_and_max[1])\n",
    "\n",
    "        print(\"Case N_meas =\", N_meas, \"finished\")\n",
    "\n",
    "    return E_min_C0, E_min_C1, E_min_C01, coef_min, E_min, E_max\n",
    "def jordi_max(repetition, N_meas_list, higher_bound, threshold, N, M, K, P):\n",
    "    '''Solve the SDP minimization and maximization problem with the two different constraints for a list of number of measurement\n",
    "    '''\n",
    "\n",
    "    E_max_C0 = []\n",
    "    E_max_C1 = []\n",
    "    E_max_C01 = []\n",
    "    coef_max = []\n",
    "\n",
    "    for N_meas in N_meas_list:\n",
    "        path = f'meas_dataset/N={N}/N{N}_Meas{N_meas}.npy'\n",
    "        data = np.load(path, allow_pickle=True)\n",
    "        measurement_dataset = data[repetition]\n",
    "        measurement_dataset = {key: value for key, value in measurement_dataset.items() if value} # For reducing the complexity\n",
    "        N_meas_sub = N_meas * (3 ** (N - M))\n",
    "\n",
    "        ep = cp.Variable((K, P))\n",
    "        ep_C1 = cp.Variable((N-G+1, 4**G-1))\n",
    "        dm_tilde, dm_hat = SDP_variables_C0(ep, measurement_dataset, N, M, K, P)\n",
    "        dm_tilde_C1 = SDP_variables_C1(ep_C1, measurement_dataset, N, G)\n",
    "        \n",
    "        # Energy with SDP - maximum\n",
    "        E_max_C0_value, E_max_C1_value, E_max_C01_value, coef_max_value = biSection_search_max(higher_bound, threshold, \n",
    "                                                                               ep, ep_C1, dm_tilde, dm_tilde_C1, \n",
    "                                                                               H_local, measurement_dataset, \n",
    "                                                                               N, M, K, P\n",
    "                                                                               )\n",
    "        E_max_C0.append(E_max_C0_value)\n",
    "        E_max_C1.append(E_max_C1_value)\n",
    "        E_max_C01.append(E_max_C01_value)\n",
    "        coef_max.append(coef_max_value)\n",
    "\n",
    "        print(\"Case N_meas =\", N_meas, \"finished\")\n",
    "\n",
    "    return E_max_C0, E_max_C1, E_max_C01, coef_max\n",
    "def get_SDP_dataset_min(num_of_shot, N_meas_list, higher_bound, threshold, N, M, K, P):\n",
    "    '''Get the dataset of the solution of the SDP problems\n",
    "    '''\n",
    "\n",
    "    data = {}\n",
    "    data['E_min_C0'] = []\n",
    "    data['E_min_C1'] = []\n",
    "    data['E_min_C01'] = []\n",
    "    data['coef_min'] = []\n",
    "\n",
    "    data['E_min'] = []\n",
    "    data['E_max'] = []\n",
    "    \n",
    "    for repetition in range(num_of_shot):\n",
    "        E_min_C0, E_min_C1, E_min_C01, coef_min, E_min, E_max = jordi_min(\n",
    "            repetition, \n",
    "            N_meas_list, higher_bound, threshold, \n",
    "            N, M, K, P\n",
    "        )\n",
    "        data['E_min_C0'].append(E_min_C0)\n",
    "        data['E_min_C1'].append(E_min_C1)\n",
    "        data['E_min_C01'].append(E_min_C01)\n",
    "        data['coef_min'].append(coef_min)\n",
    "        data['E_min'].append(E_min)\n",
    "        data['E_max'].append(E_max)\n",
    "    return data\n",
    "def get_SDP_dataset_max(num_of_shot, N_meas_list, higher_bound, threshold, N, M, K, P):\n",
    "    '''Get the dataset of the solution of the SDP problems\n",
    "    '''\n",
    "\n",
    "    data = {}\n",
    "    data['E_max_C0'] = []\n",
    "    data['E_max_C1'] = []\n",
    "    data['E_max_C01'] = []\n",
    "    data['coef_max'] = []\n",
    "\n",
    "    for repetition in range(num_of_shot):\n",
    "        E_max_C0, E_max_C1, E_max_C01, coef_max = jordi_max(\n",
    "            repetition, \n",
    "            N_meas_list, higher_bound, threshold, \n",
    "            N, M, K, P\n",
    "        )\n",
    "        data['E_max_C0'].append(E_max_C0)\n",
    "        data['E_max_C1'].append(E_max_C1)\n",
    "        data['E_max_C01'].append(E_max_C01)\n",
    "        data['coef_max'].append(coef_max)\n",
    "    return data\n",
    "def process_SDP_dataset(data, num_of_shot, num_data_point):\n",
    "    '''Given the dataset of SDP problem results,\n",
    "       return the mean value and standard deviation\n",
    "    '''\n",
    "    E_mean = {}\n",
    "    E_std = {}\n",
    "\n",
    "    for key in data:\n",
    "        tmp = np.array(data[key])\n",
    "        E_mean[key] = np.mean(tmp, axis=0)\n",
    "        E_std[key] = np.std(tmp, axis=0) / num_of_shot ** 0.5\n",
    "\n",
    "    return E_mean, E_std\n",
    "\n",
    "# Moniter the time complexity with fixed G as N increases\n",
    "import time\n",
    "def time_cost_min_C01(H, measurement_dataset, N, M, K, P):\n",
    "    '''Solve the SDP using bi-section method\n",
    "    '''\n",
    "    ep = cp.Variable((K, P))\n",
    "    ep_C1 = cp.Variable((N-G+1, 4**G-1))\n",
    "    ep_C2 = cp.Variable((N-G+1, 4**G-1))\n",
    "    coef = 1\n",
    "\n",
    "    # Solve SDP with conditions C1+C0\n",
    "    dm_tilde01, dm_hat01 = SDP_variables_C0(ep, measurement_dataset, N, M, K, P)\n",
    "    dm_tilde_C1 = SDP_variables_C1(ep_C1, measurement_dataset, N, G)\n",
    "    constraints0 = constraints_C0(ep, coef, dm_tilde01, measurement_dataset, N, M, K, P)\n",
    "    constraints1 = constraints_C1(ep_C1, coef, dm_tilde01, dm_tilde_C1, measurement_dataset, N, M, G)\n",
    "    \n",
    "    H_exp01 = 0\n",
    "    for i in range(K):\n",
    "        H_exp01 = H_exp01 + H @ dm_tilde01[i]\n",
    "    prob_C1 = cp.Problem(\n",
    "        cp.Minimize(\n",
    "            cp.real(\n",
    "                cp.trace(\n",
    "                    H_exp01\n",
    "                )\n",
    "            )\n",
    "        ), constraints0 + constraints1\n",
    "    )\n",
    "    energy_C1 = prob_C1.solve(solver=cp.SCS, verbose=False)\n",
    "\n",
    "    return energy_C1, coef\n",
    "def time_cost_max_C01(H, measurement_dataset, N, M, K, P):\n",
    "    '''Solve the SDP using bi-section method\n",
    "    '''\n",
    "    ep = cp.Variable((K, P))\n",
    "    ep_C1 = cp.Variable((N-G+1, 4**G-1))\n",
    "    ep_C2 = cp.Variable((N-G+1, 4**G-1))\n",
    "    coef = 1\n",
    "\n",
    "    # Solve SDP with conditions C1+C0\n",
    "    dm_tilde01, dm_hat01 = SDP_variables_C0(ep, measurement_dataset, N, M, K, P)\n",
    "    dm_tilde_C1 = SDP_variables_C1(ep_C1, measurement_dataset, N, G)\n",
    "    constraints0 = constraints_C0(ep, coef, dm_tilde01, measurement_dataset, N, M, K, P)\n",
    "    constraints1 = constraints_C1(ep_C1, coef, dm_tilde01, dm_tilde_C1, measurement_dataset, N, M, G)\n",
    "    \n",
    "    H_exp01 = 0\n",
    "    for i in range(K):\n",
    "        H_exp01 = H_exp01 + H @ dm_tilde01[i]\n",
    "    prob_C1 = cp.Problem(\n",
    "        cp.Maximize(\n",
    "            cp.real(\n",
    "                cp.trace(\n",
    "                    H_exp01\n",
    "                )\n",
    "            )\n",
    "        ), constraints0 + constraints1\n",
    "    )\n",
    "    energy_C1 = prob_C1.solve(solver=cp.SCS, verbose=False)\n",
    "\n",
    "    return energy_C1, coef\n",
    "def time_cost_min_C0(H, measurement_dataset, N, M, K, P):\n",
    "    '''Solve the SDP using bi-section method\n",
    "    '''\n",
    "    ep = cp.Variable((K, P))\n",
    "    coef = 1\n",
    "\n",
    "    # Solve SDP with conditions C0\n",
    "    dm_tilde0, dm_hat0 = SDP_variables_C0(ep, measurement_dataset, N, M, K, P)\n",
    "    constraints0 = constraints_C0(ep, coef, dm_tilde0, measurement_dataset, N, M, K, P)\n",
    "    \n",
    "    H_exp0 = 0\n",
    "    for i in range(K):\n",
    "        H_exp0 = H_exp0 + H @ dm_tilde0[i]\n",
    "    prob_C0 = cp.Problem(\n",
    "        cp.Minimize(\n",
    "            cp.real(\n",
    "                cp.trace(\n",
    "                    H_exp0\n",
    "                )\n",
    "            )\n",
    "        ), constraints0\n",
    "    )\n",
    "    energy_C0 = prob_C0.solve(solver=cp.SCS, verbose=False)\n",
    "\n",
    "    return energy_C0, coef\n",
    "def time_cost_max_C0(H, measurement_dataset, N, M, K, P):\n",
    "    '''Solve the SDP using bi-section method\n",
    "    '''\n",
    "    ep = cp.Variable((K, P))\n",
    "    coef = 1\n",
    "\n",
    "    # Solve SDP with conditions C0\n",
    "    dm_tilde0, dm_hat0 = SDP_variables_C0(ep, measurement_dataset, N, M, K, P)\n",
    "    constraints0 = constraints_C0(ep, coef, dm_tilde0, measurement_dataset, N, M, K, P)\n",
    "    \n",
    "    H_exp0 = 0\n",
    "    for i in range(K):\n",
    "        H_exp0 = H_exp0 + H @ dm_tilde0[i]\n",
    "    prob_C0 = cp.Problem(\n",
    "        cp.Maximize(\n",
    "            cp.real(\n",
    "                cp.trace(\n",
    "                    H_exp0\n",
    "                )\n",
    "            )\n",
    "        ), constraints0\n",
    "    )\n",
    "    energy_C0 = prob_C0.solve(solver=cp.SCS, verbose=False)\n",
    "\n",
    "    return energy_C0, coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import math\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from qutip import *\n",
    "from qiskit import *\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.quantum_info import Statevector, DensityMatrix, Operator, Pauli, partial_trace, state_fidelity, random_density_matrix\n",
    "from qiskit.visualization import plot_histogram, plot_state_city, plot_bloch_multivector, plot_state_paulivec, plot_state_hinton, plot_state_qsphere\n",
    "from qiskit.tools.monitor import job_monitor\n",
    "import os\n",
    "\n",
    "from SDPforVQE import generate_PauliStrList, Hamiltonian_global, Hamiltonian_matrix, ground_state, lower_bound_with_SDP, N_meas_list_func\n",
    "from SDPforVQE import get_SDP_dataset_min, get_SDP_dataset_max, process_SDP_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Case N_meas = 100 finished\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/wangzherui/Documents/GitHub/SDP-for-VQE/More-Qubit Pro v3.0/main.ipynb 单元格 4\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangzherui/Documents/GitHub/SDP-for-VQE/More-Qubit%20Pro%20v3.0/main.ipynb#W2sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m higher_bound \u001b[39m=\u001b[39m \u001b[39m0.1\u001b[39m \u001b[39m# Starting trial value for the bi-search method\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangzherui/Documents/GitHub/SDP-for-VQE/More-Qubit%20Pro%20v3.0/main.ipynb#W2sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m threshold \u001b[39m=\u001b[39m \u001b[39m0.001\u001b[39m \u001b[39m# Accuracy of the minimum relaxation value \u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/wangzherui/Documents/GitHub/SDP-for-VQE/More-Qubit%20Pro%20v3.0/main.ipynb#W2sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m data_min \u001b[39m=\u001b[39m get_SDP_dataset_min(num_of_shot\u001b[39m=\u001b[39;49mnum_of_shot,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangzherui/Documents/GitHub/SDP-for-VQE/More-Qubit%20Pro%20v3.0/main.ipynb#W2sZmlsZQ%3D%3D?line=32'>33</a>\u001b[0m                        N_meas_list\u001b[39m=\u001b[39;49mN_meas_list,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangzherui/Documents/GitHub/SDP-for-VQE/More-Qubit%20Pro%20v3.0/main.ipynb#W2sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m                        higher_bound\u001b[39m=\u001b[39;49mhigher_bound,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangzherui/Documents/GitHub/SDP-for-VQE/More-Qubit%20Pro%20v3.0/main.ipynb#W2sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m                        threshold\u001b[39m=\u001b[39;49mthreshold,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangzherui/Documents/GitHub/SDP-for-VQE/More-Qubit%20Pro%20v3.0/main.ipynb#W2sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m                        N\u001b[39m=\u001b[39;49mN,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangzherui/Documents/GitHub/SDP-for-VQE/More-Qubit%20Pro%20v3.0/main.ipynb#W2sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m                        M\u001b[39m=\u001b[39;49mM,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangzherui/Documents/GitHub/SDP-for-VQE/More-Qubit%20Pro%20v3.0/main.ipynb#W2sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m                        G\u001b[39m=\u001b[39;49mG,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangzherui/Documents/GitHub/SDP-for-VQE/More-Qubit%20Pro%20v3.0/main.ipynb#W2sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m                        K\u001b[39m=\u001b[39;49mK,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangzherui/Documents/GitHub/SDP-for-VQE/More-Qubit%20Pro%20v3.0/main.ipynb#W2sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m                        P\u001b[39m=\u001b[39;49mP,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangzherui/Documents/GitHub/SDP-for-VQE/More-Qubit%20Pro%20v3.0/main.ipynb#W2sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m                        model_type\u001b[39m=\u001b[39;49mmodel_type,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangzherui/Documents/GitHub/SDP-for-VQE/More-Qubit%20Pro%20v3.0/main.ipynb#W2sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m                        PauliStrList_part\u001b[39m=\u001b[39;49mPauliStrList_part,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangzherui/Documents/GitHub/SDP-for-VQE/More-Qubit%20Pro%20v3.0/main.ipynb#W2sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m                        PauliStrList_Gbody\u001b[39m=\u001b[39;49mPauliStrList_Gbody,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangzherui/Documents/GitHub/SDP-for-VQE/More-Qubit%20Pro%20v3.0/main.ipynb#W2sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m                        H_local_matrix\u001b[39m=\u001b[39;49mH_local_matrix, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangzherui/Documents/GitHub/SDP-for-VQE/More-Qubit%20Pro%20v3.0/main.ipynb#W2sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m                        H_global_list\u001b[39m=\u001b[39;49mH_global_list)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangzherui/Documents/GitHub/SDP-for-VQE/More-Qubit%20Pro%20v3.0/main.ipynb#W2sZmlsZQ%3D%3D?line=45'>46</a>\u001b[0m data_max \u001b[39m=\u001b[39m get_SDP_dataset_max(num_of_shot\u001b[39m=\u001b[39mnum_of_shot,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangzherui/Documents/GitHub/SDP-for-VQE/More-Qubit%20Pro%20v3.0/main.ipynb#W2sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m                        N_meas_list\u001b[39m=\u001b[39mN_meas_list,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangzherui/Documents/GitHub/SDP-for-VQE/More-Qubit%20Pro%20v3.0/main.ipynb#W2sZmlsZQ%3D%3D?line=47'>48</a>\u001b[0m                        higher_bound\u001b[39m=\u001b[39mhigher_bound,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangzherui/Documents/GitHub/SDP-for-VQE/More-Qubit%20Pro%20v3.0/main.ipynb#W2sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m                        H_local_matrix\u001b[39m=\u001b[39mH_local_matrix, \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangzherui/Documents/GitHub/SDP-for-VQE/More-Qubit%20Pro%20v3.0/main.ipynb#W2sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m                        H_global_list\u001b[39m=\u001b[39mH_global_list)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/wangzherui/Documents/GitHub/SDP-for-VQE/More-Qubit%20Pro%20v3.0/main.ipynb#W2sZmlsZQ%3D%3D?line=60'>61</a>\u001b[0m E_mean_min, E_std_min \u001b[39m=\u001b[39m process_SDP_dataset(data_min, num_of_shot, num_data_point)\n",
      "File \u001b[0;32m~/Documents/GitHub/SDP-for-VQE/More-Qubit Pro v3.0/SDPforVQE.py:1236\u001b[0m, in \u001b[0;36mget_SDP_dataset_min\u001b[0;34m(num_of_shot, N_meas_list, higher_bound, threshold, N, M, G, K, P, model_type, PauliStrList_part, PauliStrList_Gbody, H_local_matrix, H_global_list)\u001b[0m\n\u001b[1;32m   1233\u001b[0m data[\u001b[39m'\u001b[39m\u001b[39mE_max\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m []\n\u001b[1;32m   1235\u001b[0m \u001b[39mfor\u001b[39;00m repetition \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_of_shot):\n\u001b[0;32m-> 1236\u001b[0m     E_min_C0, E_min_C1, E_min_C01, coef_min, E_min, E_max \u001b[39m=\u001b[39m jordi_min(\n\u001b[1;32m   1237\u001b[0m         repetition, \n\u001b[1;32m   1238\u001b[0m         N_meas_list, higher_bound, threshold, \n\u001b[1;32m   1239\u001b[0m         N, M, G, K, P,\n\u001b[1;32m   1240\u001b[0m         model_type,\n\u001b[1;32m   1241\u001b[0m         PauliStrList_part, PauliStrList_Gbody,\n\u001b[1;32m   1242\u001b[0m         H_local_matrix, H_global_list\n\u001b[1;32m   1243\u001b[0m     )\n\u001b[1;32m   1244\u001b[0m     data[\u001b[39m'\u001b[39m\u001b[39mE_min_C0\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(E_min_C0)\n\u001b[1;32m   1245\u001b[0m     data[\u001b[39m'\u001b[39m\u001b[39mE_min_C1\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mappend(E_min_C1)\n",
      "File \u001b[0;32m~/Documents/GitHub/SDP-for-VQE/More-Qubit Pro v3.0/SDPforVQE.py:1146\u001b[0m, in \u001b[0;36mjordi_min\u001b[0;34m(repetition, N_meas_list, higher_bound, threshold, N, M, G, K, P, model_type, PauliStrList_part, PauliStrList_Gbody, H_local_matrix, H_global_list)\u001b[0m\n\u001b[1;32m   1143\u001b[0m dm_tilde_C1 \u001b[39m=\u001b[39m SDP_variables_C1(ep_C1, measurement_dataset, N, G, K, PauliStrList_Gbody, model_type)\n\u001b[1;32m   1145\u001b[0m \u001b[39m# Energy with SDP - minimum\u001b[39;00m\n\u001b[0;32m-> 1146\u001b[0m E_min_C0_value, E_min_C1_value, E_min_C01_value, coef_min_value \u001b[39m=\u001b[39m biSection_search_min(higher_bound, threshold, \n\u001b[1;32m   1147\u001b[0m                                                                        ep, ep_C1, dm_tilde, dm_tilde_C1, \n\u001b[1;32m   1148\u001b[0m                                                                        H_local_matrix, measurement_dataset, \n\u001b[1;32m   1149\u001b[0m                                                                        N, M, G, K, P,\n\u001b[1;32m   1150\u001b[0m                                                                        model_type\n\u001b[1;32m   1151\u001b[0m                                                                        )\n\u001b[1;32m   1152\u001b[0m E_min_C0\u001b[39m.\u001b[39mappend(E_min_C0_value)\n\u001b[1;32m   1153\u001b[0m E_min_C1\u001b[39m.\u001b[39mappend(E_min_C1_value)\n",
      "File \u001b[0;32m~/Documents/GitHub/SDP-for-VQE/More-Qubit Pro v3.0/SDPforVQE.py:1002\u001b[0m, in \u001b[0;36mbiSection_search_min\u001b[0;34m(higher_bound, threshold, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, G, K, P, model_type)\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mabs\u001b[39m(high \u001b[39m-\u001b[39m low) \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m threshold:\n\u001b[1;32m   1001\u001b[0m     coef \u001b[39m=\u001b[39m low \u001b[39m+\u001b[39m \u001b[39mabs\u001b[39m(high \u001b[39m-\u001b[39m low) \u001b[39m/\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m-> 1002\u001b[0m     energy_C0_result, energy_C1_result, energy_C01_result \u001b[39m=\u001b[39m SDP_solver_min(coef, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, G, K, P, model_type)\n\u001b[1;32m   1003\u001b[0m     \u001b[39mif\u001b[39;00m (math\u001b[39m.\u001b[39misinf(energy_C0_result) \u001b[39mor\u001b[39;00m math\u001b[39m.\u001b[39misinf(energy_C1) \u001b[39mor\u001b[39;00m math\u001b[39m.\u001b[39misinf(energy_C01_result)):\n\u001b[1;32m   1004\u001b[0m         low \u001b[39m=\u001b[39m coef\n",
      "File \u001b[0;32m~/Documents/GitHub/SDP-for-VQE/More-Qubit Pro v3.0/SDPforVQE.py:850\u001b[0m, in \u001b[0;36mSDP_solver_min\u001b[0;34m(coef, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, G, K, P, model_type)\u001b[0m\n\u001b[1;32m    840\u001b[0m     H_exp1 \u001b[39m=\u001b[39m H_exp1 \u001b[39m+\u001b[39m H \u001b[39m@\u001b[39m dm_tilde_copy1[i]\n\u001b[1;32m    841\u001b[0m prob_C1 \u001b[39m=\u001b[39m cp\u001b[39m.\u001b[39mProblem(\n\u001b[1;32m    842\u001b[0m     cp\u001b[39m.\u001b[39mMinimize(\n\u001b[1;32m    843\u001b[0m         cp\u001b[39m.\u001b[39mreal(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    848\u001b[0m     ), constraints1\n\u001b[1;32m    849\u001b[0m )\n\u001b[0;32m--> 850\u001b[0m energy_C1 \u001b[39m=\u001b[39m prob_C1\u001b[39m.\u001b[39;49msolve(solver\u001b[39m=\u001b[39;49mcp\u001b[39m.\u001b[39;49mSCS, verbose\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m    851\u001b[0m \u001b[39mif\u001b[39;00m prob_C1\u001b[39m.\u001b[39mstatus \u001b[39m!=\u001b[39m cp\u001b[39m.\u001b[39mOPTIMAL:\n\u001b[1;32m    852\u001b[0m     energy_C1 \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39m(\u001b[39m'\u001b[39m\u001b[39minf\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/QuantumC/lib/python3.8/site-packages/cvxpy/problems/problem.py:495\u001b[0m, in \u001b[0;36mProblem.solve\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    494\u001b[0m     solve_func \u001b[39m=\u001b[39m Problem\u001b[39m.\u001b[39m_solve\n\u001b[0;32m--> 495\u001b[0m \u001b[39mreturn\u001b[39;00m solve_func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/QuantumC/lib/python3.8/site-packages/cvxpy/problems/problem.py:1056\u001b[0m, in \u001b[0;36mProblem._solve\u001b[0;34m(self, solver, warm_start, verbose, gp, qcp, requires_grad, enforce_dpp, ignore_dpp, canon_backend, **kwargs)\u001b[0m\n\u001b[1;32m   1053\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39munpack(chain\u001b[39m.\u001b[39mretrieve(soln))\n\u001b[1;32m   1054\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvalue\n\u001b[0;32m-> 1056\u001b[0m data, solving_chain, inverse_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_problem_data(\n\u001b[1;32m   1057\u001b[0m     solver, gp, enforce_dpp, ignore_dpp, verbose, canon_backend, kwargs\n\u001b[1;32m   1058\u001b[0m )\n\u001b[1;32m   1060\u001b[0m \u001b[39mif\u001b[39;00m verbose:\n\u001b[1;32m   1061\u001b[0m     \u001b[39mprint\u001b[39m(_NUM_SOLVER_STR)\n",
      "File \u001b[0;32m~/anaconda3/envs/QuantumC/lib/python3.8/site-packages/cvxpy/problems/problem.py:683\u001b[0m, in \u001b[0;36mProblem.get_problem_data\u001b[0;34m(self, solver, gp, enforce_dpp, ignore_dpp, verbose, canon_backend, solver_opts)\u001b[0m\n\u001b[1;32m    680\u001b[0m     s\u001b[39m.\u001b[39mLOGGER\u001b[39m.\u001b[39minfo(\n\u001b[1;32m    681\u001b[0m              \u001b[39m'\u001b[39m\u001b[39mCompiling problem (target solver=\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m).\u001b[39m\u001b[39m'\u001b[39m, solver_name)\n\u001b[1;32m    682\u001b[0m     s\u001b[39m.\u001b[39mLOGGER\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mReduction chain: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m, reduction_chain_str)\n\u001b[0;32m--> 683\u001b[0m data, inverse_data \u001b[39m=\u001b[39m solving_chain\u001b[39m.\u001b[39;49mapply(\u001b[39mself\u001b[39;49m, verbose)\n\u001b[1;32m    684\u001b[0m safe_to_cache \u001b[39m=\u001b[39m (\n\u001b[1;32m    685\u001b[0m     \u001b[39misinstance\u001b[39m(data, \u001b[39mdict\u001b[39m)\n\u001b[1;32m    686\u001b[0m     \u001b[39mand\u001b[39;00m s\u001b[39m.\u001b[39mPARAM_PROB \u001b[39min\u001b[39;00m data\n\u001b[1;32m    687\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39many\u001b[39m(\u001b[39misinstance\u001b[39m(reduction, EvalParams)\n\u001b[1;32m    688\u001b[0m                 \u001b[39mfor\u001b[39;00m reduction \u001b[39min\u001b[39;00m solving_chain\u001b[39m.\u001b[39mreductions)\n\u001b[1;32m    689\u001b[0m )\n\u001b[1;32m    690\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compilation_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime() \u001b[39m-\u001b[39m start\n",
      "File \u001b[0;32m~/anaconda3/envs/QuantumC/lib/python3.8/site-packages/cvxpy/reductions/chain.py:76\u001b[0m, in \u001b[0;36mChain.apply\u001b[0;34m(self, problem, verbose)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[39mif\u001b[39;00m verbose:\n\u001b[1;32m     75\u001b[0m         s\u001b[39m.\u001b[39mLOGGER\u001b[39m.\u001b[39minfo(\u001b[39m'\u001b[39m\u001b[39mApplying reduction \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m, \u001b[39mtype\u001b[39m(r)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[0;32m---> 76\u001b[0m     problem, inv \u001b[39m=\u001b[39m r\u001b[39m.\u001b[39;49mapply(problem)\n\u001b[1;32m     77\u001b[0m     inverse_data\u001b[39m.\u001b[39mappend(inv)\n\u001b[1;32m     78\u001b[0m \u001b[39mreturn\u001b[39;00m problem, inverse_data\n",
      "File \u001b[0;32m~/anaconda3/envs/QuantumC/lib/python3.8/site-packages/cvxpy/reductions/complex2real/complex2real.py:69\u001b[0m, in \u001b[0;36mComplex2Real.apply\u001b[0;34m(self, problem)\u001b[0m\n\u001b[1;32m     65\u001b[0m constrs \u001b[39m=\u001b[39m []\n\u001b[1;32m     66\u001b[0m \u001b[39mfor\u001b[39;00m constraint \u001b[39min\u001b[39;00m problem\u001b[39m.\u001b[39mconstraints:\n\u001b[1;32m     67\u001b[0m     \u001b[39m# real2imag maps variable id to a potential new variable\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[39m# created for the imaginary part.\u001b[39;00m\n\u001b[0;32m---> 69\u001b[0m     real_constrs, imag_constrs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcanonicalize_tree(\n\u001b[1;32m     70\u001b[0m         constraint, inverse_data\u001b[39m.\u001b[39;49mreal2imag, leaf_map)\n\u001b[1;32m     71\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(real_constrs, \u001b[39mlist\u001b[39m):\n\u001b[1;32m     72\u001b[0m         constrs\u001b[39m.\u001b[39mextend(real_constrs)\n",
      "File \u001b[0;32m~/anaconda3/envs/QuantumC/lib/python3.8/site-packages/cvxpy/reductions/complex2real/complex2real.py:170\u001b[0m, in \u001b[0;36mComplex2Real.canonicalize_tree\u001b[0;34m(self, expr, real2imag, leaf_map)\u001b[0m\n\u001b[1;32m    168\u001b[0m imag_args \u001b[39m=\u001b[39m []\n\u001b[1;32m    169\u001b[0m \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m expr\u001b[39m.\u001b[39margs:\n\u001b[0;32m--> 170\u001b[0m     real_arg, imag_arg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcanonicalize_tree(arg, real2imag, leaf_map)\n\u001b[1;32m    171\u001b[0m     real_args\u001b[39m.\u001b[39mappend(real_arg)\n\u001b[1;32m    172\u001b[0m     imag_args\u001b[39m.\u001b[39mappend(imag_arg)\n",
      "File \u001b[0;32m~/anaconda3/envs/QuantumC/lib/python3.8/site-packages/cvxpy/reductions/complex2real/complex2real.py:170\u001b[0m, in \u001b[0;36mComplex2Real.canonicalize_tree\u001b[0;34m(self, expr, real2imag, leaf_map)\u001b[0m\n\u001b[1;32m    168\u001b[0m imag_args \u001b[39m=\u001b[39m []\n\u001b[1;32m    169\u001b[0m \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m expr\u001b[39m.\u001b[39margs:\n\u001b[0;32m--> 170\u001b[0m     real_arg, imag_arg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcanonicalize_tree(arg, real2imag, leaf_map)\n\u001b[1;32m    171\u001b[0m     real_args\u001b[39m.\u001b[39mappend(real_arg)\n\u001b[1;32m    172\u001b[0m     imag_args\u001b[39m.\u001b[39mappend(imag_arg)\n",
      "    \u001b[0;31m[... skipping similar frames: Complex2Real.canonicalize_tree at line 170 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/QuantumC/lib/python3.8/site-packages/cvxpy/reductions/complex2real/complex2real.py:170\u001b[0m, in \u001b[0;36mComplex2Real.canonicalize_tree\u001b[0;34m(self, expr, real2imag, leaf_map)\u001b[0m\n\u001b[1;32m    168\u001b[0m imag_args \u001b[39m=\u001b[39m []\n\u001b[1;32m    169\u001b[0m \u001b[39mfor\u001b[39;00m arg \u001b[39min\u001b[39;00m expr\u001b[39m.\u001b[39margs:\n\u001b[0;32m--> 170\u001b[0m     real_arg, imag_arg \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcanonicalize_tree(arg, real2imag, leaf_map)\n\u001b[1;32m    171\u001b[0m     real_args\u001b[39m.\u001b[39mappend(real_arg)\n\u001b[1;32m    172\u001b[0m     imag_args\u001b[39m.\u001b[39mappend(imag_arg)\n",
      "File \u001b[0;32m~/anaconda3/envs/QuantumC/lib/python3.8/site-packages/cvxpy/reductions/complex2real/complex2real.py:173\u001b[0m, in \u001b[0;36mComplex2Real.canonicalize_tree\u001b[0;34m(self, expr, real2imag, leaf_map)\u001b[0m\n\u001b[1;32m    171\u001b[0m         real_args\u001b[39m.\u001b[39mappend(real_arg)\n\u001b[1;32m    172\u001b[0m         imag_args\u001b[39m.\u001b[39mappend(imag_arg)\n\u001b[0;32m--> 173\u001b[0m     real_out, imag_out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcanonicalize_expr(expr, real_args,\n\u001b[1;32m    174\u001b[0m                                                 imag_args, real2imag,\n\u001b[1;32m    175\u001b[0m                                                 leaf_map)\n\u001b[1;32m    176\u001b[0m \u001b[39mreturn\u001b[39;00m real_out, imag_out\n",
      "File \u001b[0;32m~/anaconda3/envs/QuantumC/lib/python3.8/site-packages/cvxpy/reductions/complex2real/complex2real.py:183\u001b[0m, in \u001b[0;36mComplex2Real.canonicalize_expr\u001b[0;34m(self, expr, real_args, imag_args, real2imag, leaf_map)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(expr\u001b[39m.\u001b[39margs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m expr \u001b[39min\u001b[39;00m leaf_map:\n\u001b[1;32m    182\u001b[0m     \u001b[39mreturn\u001b[39;00m leaf_map[expr]\n\u001b[0;32m--> 183\u001b[0m result \u001b[39m=\u001b[39m elim_cplx_methods[\u001b[39mtype\u001b[39;49m(expr)](expr, real_args, imag_args, real2imag)\n\u001b[1;32m    184\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(expr\u001b[39m.\u001b[39margs) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    185\u001b[0m     leaf_map[expr] \u001b[39m=\u001b[39m result\n",
      "File \u001b[0;32m~/anaconda3/envs/QuantumC/lib/python3.8/site-packages/cvxpy/reductions/complex2real/canonicalizers/aff_canon.py:37\u001b[0m, in \u001b[0;36mseparable_canon\u001b[0;34m(expr, real_args, imag_args, real2imag)\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[39melif\u001b[39;00m imag_args[idx] \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     36\u001b[0m             imag_args[idx] \u001b[39m=\u001b[39m Constant(np\u001b[39m.\u001b[39mzeros(real_args[idx]\u001b[39m.\u001b[39mshape))\n\u001b[0;32m---> 37\u001b[0m     outputs \u001b[39m=\u001b[39m (expr\u001b[39m.\u001b[39mcopy(real_args), expr\u001b[39m.\u001b[39;49mcopy(imag_args))\n\u001b[1;32m     38\u001b[0m \u001b[39mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/anaconda3/envs/QuantumC/lib/python3.8/site-packages/cvxpy/atoms/affine/add_expr.py:102\u001b[0m, in \u001b[0;36mAddExpression.copy\u001b[0;34m(self, args, id_objects)\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[39m# Takes advantage of _arg_groups if present for efficiency.\u001b[39;00m\n\u001b[1;32m    101\u001b[0m copy \u001b[39m=\u001b[39m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__new__\u001b[39m(\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m))\n\u001b[0;32m--> 102\u001b[0m copy\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(args)\n\u001b[1;32m    103\u001b[0m \u001b[39mreturn\u001b[39;00m copy\n",
      "File \u001b[0;32m~/anaconda3/envs/QuantumC/lib/python3.8/site-packages/cvxpy/atoms/affine/add_expr.py:37\u001b[0m, in \u001b[0;36mAddExpression.__init__\u001b[0;34m(self, arg_groups)\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs \u001b[39m=\u001b[39m []\n\u001b[1;32m     36\u001b[0m \u001b[39mfor\u001b[39;00m group \u001b[39min\u001b[39;00m arg_groups:\n\u001b[0;32m---> 37\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexpand_args(group)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model_type = 'closed'\n",
    "model_type = 'open'\n",
    "\n",
    "N = 3 # Number of qubits of the entire system\n",
    "M = 2 # Number of qubits of subsystems\n",
    "G = 3 # Number of qubits of partial global system (C1)\n",
    "if model_type == 'open':\n",
    "    K = N-M+1 # Number of subsystems\n",
    "if model_type == 'closed':\n",
    "    K = N\n",
    "P = 4**M-1 # Number of Pauli basis for each subsystem\n",
    "\n",
    "PauliStrList = generate_PauliStrList(N)[1:]\n",
    "PauliStrList_part = generate_PauliStrList(M)[1:]\n",
    "PauliStrList_Gbody = generate_PauliStrList(G)[1:]\n",
    "\n",
    "H_local_list = ['XX','YY'] # Pauli string representation of the local Hamiltonian of subsystems\n",
    "H_global_list = Hamiltonian_global(H_local_list, N, M, K, model_type) # Pauli string representation of the Hamiltonian of the whole system\n",
    "H_local_matrix = np.array( Hamiltonian_matrix(H_local_list, model_type) ) # Matrix representation of the local Hamiltonian of subsystems\n",
    "H_global_matrix = np.array( Hamiltonian_matrix(H_global_list, model_type) ) # Matrix representation of the Hamiltonian of the whole system\n",
    "\n",
    "ground_state_energy, ground_state_dm = ground_state(H_global_matrix) \n",
    "q_state = DensityMatrix(ground_state_dm) \n",
    "lower_bound = lower_bound_with_SDP(H_local_matrix, N, M, G, K, P, PauliStrList_part, PauliStrList_Gbody)\n",
    "\n",
    "num_data_point = 4 # number of N_meas that we select to run\n",
    "N_meas_list = N_meas_list_func(100, 1000, num_data_point) # A list of number of measurement performed in all basis\n",
    "num_of_shot = 10 # Number of repeatation of the experiment\n",
    "\n",
    "higher_bound = 0.1 # Starting trial value for the bi-search method\n",
    "threshold = 0.001 # Accuracy of the minimum relaxation value \n",
    "data_min = get_SDP_dataset_min(num_of_shot=num_of_shot,\n",
    "                       N_meas_list=N_meas_list,\n",
    "                       higher_bound=higher_bound,\n",
    "                       threshold=threshold,\n",
    "                       N=N,\n",
    "                       M=M,\n",
    "                       G=G,\n",
    "                       K=K,\n",
    "                       P=P,\n",
    "                       model_type=model_type,\n",
    "                       PauliStrList_part=PauliStrList_part,\n",
    "                       PauliStrList_Gbody=PauliStrList_Gbody,\n",
    "                       H_local_matrix=H_local_matrix, \n",
    "                       H_global_list=H_global_list)\n",
    "data_max = get_SDP_dataset_max(num_of_shot=num_of_shot,\n",
    "                       N_meas_list=N_meas_list,\n",
    "                       higher_bound=higher_bound,\n",
    "                       threshold=threshold,\n",
    "                       N=N,\n",
    "                       M=M,\n",
    "                       G=G,\n",
    "                       K=K,\n",
    "                       P=P, \n",
    "                       model_type=model_type,\n",
    "                       PauliStrList_part=PauliStrList_part,\n",
    "                       PauliStrList_Gbody=PauliStrList_Gbody,\n",
    "                       H_local_matrix=H_local_matrix, \n",
    "                       H_global_list=H_global_list)\n",
    "\n",
    "E_mean_min, E_std_min = process_SDP_dataset(data_min, num_of_shot, num_data_point)\n",
    "E_mean_max, E_std_max = process_SDP_dataset(data_max, num_of_shot, num_data_point)\n",
    "\n",
    "name = 'data_N' + str(N) + '_threshold' + str(threshold)\n",
    "filename_min = '%s_min.npy' % name\n",
    "filename_max = '%s_max.npy' % name\n",
    "\n",
    "np.save(filename_min, data_min)\n",
    "np.save(filename_max, data_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=0, the index is: [0, 1, 2]\n",
      "For k=1, the index is: [1, 2, 3]\n",
      "For k=2, the index is: [2, 3, 0]\n",
      "For k=3, the index is: [3, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "K = 4\n",
    "M = 3\n",
    "\n",
    "for k in range(K):\n",
    "    index = [(k + i) % K for i in range(M)]\n",
    "    print(f\"For k={k}, the index is: {index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in range(3,5):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(np.array([0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(cp.Variable((K, P)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ep = cp.Variable((3,3))\n",
    "b = 3+cp.multiply(ep[0, 0], np.array(pauliToMatrix(PauliStrList_part[1])))\n",
    "type(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "constraints = [ep[0,0] >= -1, ep[0,0] <= 1]\n",
    "type(constraints)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('QuantumC')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb1c09c88080a82141bde80abfc5c4dcde1e462f373af1bd572dc93ad8fc5299"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
