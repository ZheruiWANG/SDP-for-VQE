{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "source": [
    "**Find the ground state energy of a certain Hamiltonian with SDP:**\n",
    "1. We can somehow prepare the groud state $\\rho_g$ of a Hamiltonian $H$\n",
    "2. We do quantum tomography on this prepared state $\\rho_g$ and get an approximation $\\hat{\\rho}$\n",
    "3. By using SDP, we get a physically valid quantum state $\\hat{\\rho}_{SDP}$ which minimizes $\\text{Tr}(\\rho H)$ for $\\rho \\in \\tilde{\\rho}$\n",
    "4. The ground state energy we find is then $\\text{Tr}(H\\hat{\\rho}_{SDP})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import math\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.stats import norm\n",
    "from qutip import *\n",
    "from qiskit import *\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.quantum_info import Statevector, DensityMatrix, Operator, Pauli, partial_trace, state_fidelity, random_density_matrix\n",
    "from qiskit.visualization import plot_histogram, plot_state_city, plot_bloch_multivector, plot_state_paulivec, plot_state_hinton, plot_state_qsphere\n",
    "from qiskit.tools.monitor import job_monitor\n",
    "import os\n",
    "#os.environ[\"OMP_NUM_THREADS\"] = \"10\"\n",
    "\n",
    "# Generate measurement dataset\n",
    "def meas(qubits_meas_basis, state, num_meas, N):\n",
    "    ''' Given a Pauli basis (0-Z, 1-X, 2-Y), do measurement and return its outcome\n",
    "    Args:\n",
    "        qubits_meas_basis: A list representing measuring basis, e.g.: [0,0,0] is 'ZZZ'\n",
    "        state: A quantum state from Qiskit\n",
    "        num_meas: number of measurements performed in this basis\n",
    "    Yeilds:\n",
    "        outcome: A list of strings, of which each element is an instance of measurement\n",
    "    E.g.:\n",
    "        INPUT: [0,0,0], state, N=3, num_meas=2\n",
    "        OUTPUT: [000, 000] (in order of qubit 012)\n",
    "    '''\n",
    "    outcome = []\n",
    "    circ_meas = QuantumCircuit(N)\n",
    "\n",
    "    if num_meas>0:\n",
    "        for i in range(N):\n",
    "            if qubits_meas_basis[i] == '1':\n",
    "                circ_meas.ry(-math.pi / 2, i)\n",
    "            elif qubits_meas_basis[i] == '2':\n",
    "                circ_meas.rx(math.pi / 2, i)\n",
    "\n",
    "        U_meas = Operator(circ_meas)\n",
    "        state_temp = state.evolve(U_meas)\n",
    "        for j in range(num_meas):\n",
    "            str_tmp = state_temp.measure()[0]\n",
    "            outcome.append(str_tmp[::-1])  # Take the reverse\n",
    "\n",
    "    # Note: in qiskit, qubit number counts from the left,\n",
    "    # e.g.: '00101' means we measure qubit0 a '1'.\n",
    "    return outcome\n",
    "def number_to_Pauli(pauli_num_str, N):\n",
    "    ''' Given a number string, return the corresponding Pauli string\n",
    "        0-Z, 1-X, 2-Y\n",
    "    E.g.:\n",
    "        INPUT: '01200' (in order of qubit 01234)\n",
    "        OUTPUT: 'ZZYXZ' (in order of qubit 01234)\n",
    "    '''\n",
    "    pauli_num_list = list(pauli_num_str)\n",
    "    pauli_basis_list = list(pauli_num_str)\n",
    "    for i in range(N):\n",
    "        if pauli_num_list[i] == '1':\n",
    "            pauli_basis_list[i] = 'X'\n",
    "        elif pauli_num_list[i] == '2':\n",
    "            pauli_basis_list[i] = 'Y'\n",
    "        else:\n",
    "            pauli_basis_list[i] = 'Z'\n",
    "    return ''.join(pauli_basis_list)\n",
    "def random_distribute(N_meas, N):\n",
    "    '''N_meas is the total number of measurements for all basis\n",
    "    '''\n",
    "    quotient = N_meas//3**N\n",
    "    remainder = N_meas%3**N\n",
    "    num_of_meas_list = quotient*np.ones(3**N)\n",
    "    \n",
    "    tmp = list(range(0,3**N))\n",
    "    lucky_dog = random.sample(tmp, int(remainder))\n",
    "\n",
    "    for i in range(remainder):\n",
    "        num_of_meas_list[lucky_dog[i]] = num_of_meas_list[lucky_dog[i]]+1\n",
    "\n",
    "    return num_of_meas_list\n",
    "def generate_meas_dataset(state, N_meas, N):\n",
    "    '''Generate measurement dataset for a N-qubit quantum state\n",
    "    Args:\n",
    "        state: A quantum state from Qiskit\n",
    "        N_meas: total number of measurements for all basis\n",
    "        N: number of qubits of the state\n",
    "    Yeilds:\n",
    "        Dict_meas_outcome\n",
    "    '''\n",
    "    Dict_meas_outcome = dict()\n",
    "    num_meas_list = random_distribute(N_meas, N) # A list of integers, of which each element represent the number of measurement for one basis\n",
    "    for i in range(3 ** N):\n",
    "        qubits_meas_basis = tenToAny(i, N, 3)\n",
    "        meas_outcome_string = meas(qubits_meas_basis, state, int(num_meas_list[i]), N)\n",
    "        Dict_meas_outcome[number_to_Pauli(''.join(qubits_meas_basis), N)] = meas_outcome_string\n",
    "    return Dict_meas_outcome\n",
    "def tenToAny(origin, N, n):\n",
    "    # 10进制转换为n进制list\n",
    "    list = []\n",
    "    while True:\n",
    "        s = origin // n\n",
    "        tmp = origin % n\n",
    "        list.append(tmp)\n",
    "        if s == 0:\n",
    "            break\n",
    "        origin = s\n",
    "    list.reverse()\n",
    "    list = [str(each) for each in list]\n",
    "    while len(list) < N:\n",
    "        list.insert(0, '0')\n",
    "    return list\n",
    "def generate_PauliStrList(N):\n",
    "    ''' Given the number of qubits N, return its corresponding Pauli vector.\n",
    "    E.g.:\n",
    "        INPUT: N=2\n",
    "        OUTPUT: ['II','IX',...'ZZ']\n",
    "    '''\n",
    "    Pauli_str_list = []\n",
    "    for i in range(4 ** N):\n",
    "        pauli_num_list = tenToAny(i, N, 4)\n",
    "        pauli_basis_list = pauli_num_list\n",
    "        for j in range(N):\n",
    "            if pauli_num_list[j] == '0':\n",
    "                pauli_basis_list[j] = 'I'\n",
    "            elif pauli_num_list[j] == '1':\n",
    "                pauli_basis_list[j] = 'X'\n",
    "            elif pauli_num_list[j] == '2':\n",
    "                pauli_basis_list[j] = 'Y'\n",
    "            else:\n",
    "                pauli_basis_list[j] = 'Z'\n",
    "        Pauli_str_list.append(''.join(pauli_basis_list))\n",
    "\n",
    "    return Pauli_str_list\n",
    "def generate_sub_PauliStrList(PauliStrList, index):\n",
    "    # Stupid version\n",
    "    ''' Given a index (list) of qubits, retrun the Pauli vectors of this sub system.\n",
    "    E.g.:\n",
    "        INPUT: PauliStrList=['III',...'ZZZ'], index=[0,2]\n",
    "        OUTPUT: ['III','IIX','IIY','IIZ','XII','XIX',...'ZIZ']\n",
    "    '''\n",
    "    output = list()\n",
    "    no_meas = list(set(list(range(N))) - set(index))\n",
    "    for i in PauliStrList:\n",
    "        trigger = bool(1)\n",
    "        for j in no_meas:\n",
    "            trigger = bool(trigger and i[int(j)] == 'I')\n",
    "        if trigger: output.append(i)\n",
    "\n",
    "    return output\n",
    "def generate_sub_PauliStrList(N, index_list):\n",
    "    # Less-complexity version\n",
    "    base_string = 'I' * N\n",
    "    output_strings = []\n",
    "\n",
    "    for combination in itertools.product('IXYZ', repeat=len(index_list)):\n",
    "        if all(c == 'I' for c in combination):\n",
    "            continue\n",
    "\n",
    "        temp_string = list(base_string)\n",
    "        for index, char in zip(index_list, combination):\n",
    "            temp_string[index] = char\n",
    "\n",
    "        output_strings.append(''.join(temp_string))\n",
    "\n",
    "    return output_strings\n",
    "def parity_check(meas_string):\n",
    "    ''' Given a measurement outcome binary string array,\n",
    "        return 0 if #1 in the string is even, otherwise return 1 for each element\n",
    "    E.g.:\n",
    "        INPUT: ['0001', '0101', '0000']\n",
    "        OUTPUT: [-1, 1, 1]\n",
    "    '''\n",
    "    num_of_meas = len(meas_string)\n",
    "    meas_parity = np.zeros(num_of_meas)\n",
    "    for i in range(num_of_meas):\n",
    "        temp = bin(int(meas_string[i], 2)).count(\"1\")\n",
    "        if temp % 2 == 0:\n",
    "            meas_parity[i] = 1\n",
    "        else:\n",
    "            meas_parity[i] = -1\n",
    "    return meas_parity\n",
    "def exp_var_calculator(measurement_dataset, pauli_basis_str):\n",
    "    ''' Given a Pauli basis (on partial qubits, e.g.: XIXZY, IIIXX, ZIIII, etc.) and dataset,\n",
    "        return its applicable measurement outcome expectation value and variance.\n",
    "    '''\n",
    "    #measurement_dataset = {key: value for key, value in measurement_dataset.items() if value} # For reducing the complexity\n",
    "    output = list([])\n",
    "    for key in measurement_dataset:\n",
    "        if pauli_basis_str.count('I') == sum(char1 != char2 for char1, char2 in zip(pauli_basis_str, key)):\n",
    "            output = measurement_dataset[key] + output\n",
    "\n",
    "    while pauli_basis_str.find('I') != -1:\n",
    "        index_I = pauli_basis_str.find('I')\n",
    "        pauli_basis_str = pauli_basis_str[:index_I] + pauli_basis_str[(index_I + 1):]\n",
    "        for j in range(len(output)):\n",
    "            words = output[j]\n",
    "            output[j] = words[:index_I] + words[(index_I + 1):]\n",
    "\n",
    "    meas_outcome = parity_check(output)\n",
    "    N_meas_sub = len(output)\n",
    "    \n",
    "    if N_meas_sub == 0:\n",
    "        expectation_value = 0\n",
    "        variance = 0\n",
    "    else: \n",
    "        expectation_value = np.average(meas_outcome)\n",
    "        variance = np.var(meas_outcome)\n",
    "\n",
    "    return expectation_value, variance\n",
    "def num_meas_sub_calculator(measurement_dataset, pauli_basis_str):\n",
    "    ''' Given a Pauli basis (on partial qubits, e.g.: XIXZY, IIIXX, ZIIII, etc.) and dataset,\n",
    "        return the number of measurements performed in this basis\n",
    "    '''\n",
    "    output = list([])\n",
    "    for key in measurement_dataset:\n",
    "        if pauli_basis_str.count('I') == sum(char1 != char2 for char1, char2 in zip(pauli_basis_str, key)):\n",
    "            output = measurement_dataset[key] + output\n",
    "\n",
    "    while pauli_basis_str.find('I') != -1:\n",
    "        index_I = pauli_basis_str.find('I')\n",
    "        pauli_basis_str = pauli_basis_str[:index_I] + pauli_basis_str[(index_I + 1):]\n",
    "        for j in range(len(output)):\n",
    "            words = output[j]\n",
    "            output[j] = words[:index_I] + words[(index_I + 1):]\n",
    "\n",
    "    return len(output)\n",
    "def pauliToMatrix(pauli_str):\n",
    "    '''Given a Pauli string basis (str),\n",
    "       output its corresponding matrix representation (Qobj data).\n",
    "    '''\n",
    "    pauli_basis_list = list()\n",
    "    for basis in pauli_str:\n",
    "        if basis == 'I':\n",
    "            pauli_basis_list.append(qeye(2))\n",
    "        elif basis == 'X':\n",
    "            pauli_basis_list.append(sigmax())\n",
    "        elif basis == 'Y':\n",
    "            pauli_basis_list.append(sigmay())\n",
    "        else:\n",
    "            pauli_basis_list.append(sigmaz())\n",
    "    return tensor(pauli_basis_list)\n",
    "def q_tomography_dm(qubit_index, measurement_dataset, N):\n",
    "    ''' Do quantum tomography for certain qubits according to the index,\n",
    "        output the constructed density matrix.\n",
    "    '''\n",
    "    density_matrix = 0\n",
    "    for basis in generate_sub_PauliStrList(N, qubit_index):\n",
    "        expectation, variance = exp_var_calculator(measurement_dataset, basis)\n",
    "        sub_basis = ''.join([basis[i] for i in qubit_index])\n",
    "        density_matrix += expectation * pauliToMatrix(sub_basis)\n",
    "    density_matrix += tensor([qeye(2)] * len(qubit_index))\n",
    "    return 1 / (2 ** len(qubit_index)) * density_matrix\n",
    "def q_tomography_vec(qubit_index, measurement_dataset):\n",
    "    ''' Do quantum tomography for certain qubits according to the index,\n",
    "        output a list of expectation value.\n",
    "    '''\n",
    "    bloch_vec = []\n",
    "    for basis in generate_sub_PauliStrList(N, qubit_index):\n",
    "        expectation, variance = exp_var_calculator(measurement_dataset, basis)\n",
    "        bloch_vec.append(expectation)\n",
    "    return bloch_vec\n",
    "def Wald_interval(qubit_index, confidence_level, measurement_dataset, N):\n",
    "    ''' Given a qubit index (e.g. [0,1,2], in order of 01234...),\n",
    "        return the corresponding Wald_interval for each expectation value\n",
    "    '''\n",
    "    error_rate = 1 - confidence_level\n",
    "    z = norm.ppf(1 - error_rate / 2)  # Quantile of the input confidence level for binomial distribution\n",
    "    mean_vec = np.array(q_tomography_vec(qubit_index, measurement_dataset))\n",
    "    p_vec = 0.5 * (1 + mean_vec)\n",
    "\n",
    "    basis_list = generate_sub_PauliStrList(N, qubit_index)\n",
    "    sigma = []\n",
    "    for i in range(len(basis_list)):\n",
    "        num_meas_sub = num_meas_sub_calculator(measurement_dataset, basis_list[i])\n",
    "        sigma.append(2 * z * ((p_vec[i] * (1 - p_vec[i]) / num_meas_sub) ** 0.5))\n",
    "\n",
    "    return sigma\n",
    "def Wald_interval_bisection(coef, qubit_index, confidence_level, measurement_dataset, N):\n",
    "    ''' Given a qubit index (in order of 01234...),\n",
    "        return the corresponding Wald_interval for each expectation value.\n",
    "        But here \"bisection\" means we add an additional coefficient,\n",
    "        so that we can use bisection method to find the solution of the SDP within a certain domain defined by a threshold\n",
    "    '''\n",
    "    error_rate = 1 - confidence_level\n",
    "    z = norm.ppf(1 - error_rate / 2)  # Quantile of the input confidence level for binomial distribution\n",
    "    mean_vec = np.array(q_tomography_vec(qubit_index, measurement_dataset))\n",
    "    p_vec = 0.5 * (1 + mean_vec)\n",
    "\n",
    "    basis_list = generate_sub_PauliStrList(N, qubit_index)\n",
    "    sigma = []\n",
    "    for i in range(len(basis_list)):\n",
    "        num_meas_sub = num_meas_sub_calculator(measurement_dataset, basis_list[i])\n",
    "        sigma.append(2 * coef * z * ((p_vec[i] * (1 - p_vec[i]) / num_meas_sub) ** 0.5))\n",
    "    sigma = np.nan_to_num(sigma, nan=1)\n",
    "    return sigma\n",
    "def Wilson_interval_bisection(coef, qubit_index, confidence_level, measurement_dataset, N):\n",
    "    ''' Given a qubit index (in order of 01234...),\n",
    "        return the corresponding Wilson_interval for each expectation value.\n",
    "        But here \"bisection\" means we add an additional coefficient,\n",
    "        so that we can use bisection method to find the solution of the SDP within a certain domain defined by a threshold\n",
    "    '''\n",
    "    error_rate = 1 - confidence_level\n",
    "    z = norm.ppf(1 - error_rate / 2)  # Quantile of the input confidence level for binomial distribution\n",
    "\n",
    "    mean_vec = np.array(q_tomography_vec(qubit_index, measurement_dataset))\n",
    "    p_vec = 0.5 * (1 + mean_vec)\n",
    "\n",
    "    basis_list = generate_sub_PauliStrList(N, qubit_index)\n",
    "    sigma = []\n",
    "    for i in range(len(basis_list)):\n",
    "        num_meas_sub = num_meas_sub_calculator(measurement_dataset, basis_list[i])\n",
    "        sigma.append(2*coef*z/(1+z*z/num_meas_sub)*math.sqrt((p_vec[i]*(1-p_vec[i]) + z*z/(4*num_meas_sub)) / num_meas_sub))\n",
    "    sigma = np.nan_to_num(sigma, nan=1)\n",
    "    return sigma\n",
    "def Bloch_vec(qiskit_state, qubit_index):\n",
    "    ''' Given a qiskit quantum state and the qubit index,\n",
    "        return the Bloch vector of the reduced state according to the index\n",
    "    '''\n",
    "    output = []\n",
    "    for basis in generate_sub_PauliStrList(N, qubit_index):\n",
    "        basis = basis[::-1]\n",
    "        output.append(qiskit_state.expectation_value(oper=Pauli(basis), qargs=None))\n",
    "    return output\n",
    "def qubit_swap(N, state_43210):\n",
    "    circSWAP = QuantumCircuit(N)\n",
    "    for i in range(int(N / 2)):\n",
    "        circSWAP.swap(i, N - 1 - i)\n",
    "    U_SWAP = Operator(circSWAP)\n",
    "    state_01234 = state_43210.evolve(U_SWAP)\n",
    "    return state_01234\n",
    "def generate_random_dm(purity, N):\n",
    "    '''Generate a random density matrix with a certain purity\n",
    "    '''\n",
    "    qiskit_state = DensityMatrix(random_statevector(2 ** N))\n",
    "    PauliStrList = generate_PauliStrList(N)[1:]\n",
    "\n",
    "    Bloch_vector = []\n",
    "    for basis in PauliStrList:\n",
    "        Bloch_vector.append(qiskit_state.expectation_value(oper=Pauli(basis), qargs=None))\n",
    "    Bloch_vector_noisy = math.sqrt(((2 ** N) * purity - 1) / (2 ** N - 1)) * np.array(Bloch_vector)\n",
    "\n",
    "    density_matrix = tensor([qeye(2)] * N)\n",
    "    for i in range(4 ** N - 1):\n",
    "        density_matrix += Bloch_vector_noisy[i] * pauliToMatrix(PauliStrList[i])\n",
    "    return 1 / (2 ** N) * np.array(density_matrix)\n",
    "\n",
    "# Hamiltonian and plot\n",
    "def Hamiltonian_matrix(H):\n",
    "    '''Given a list of Pauli string for each subsystem,\n",
    "       output a list of their matrix representation.\n",
    "    '''\n",
    "    Hamiltonian_matrix = 0\n",
    "    for i in range(len(H)):\n",
    "        Hamiltonian_matrix = Hamiltonian_matrix + (pauliToMatrix(H[i]))\n",
    "    return Hamiltonian_matrix\n",
    "def Hamiltonian_global(H_local_list, N, M, K):\n",
    "    '''Given the Hamiltonian of local subsystem (list of Pauli strings)\n",
    "       return the Hamiltonian of global system (list of Pauli strings)\n",
    "    '''\n",
    "    H_global = []\n",
    "    for i in range(K):\n",
    "        for h in H_local_list:\n",
    "            H_global.append(i * 'I' + h + (N - M - i) * 'I')\n",
    "    return H_global\n",
    "def ground_state(H_matrix):\n",
    "    '''Given a matrix representation of a Hamiltonian,\n",
    "       find the ground state energy, i.e. the minimum eigenvalue of the matrix,\n",
    "       and the ground state density matrix\n",
    "    '''\n",
    "    H_matrix = np.array(H_matrix)\n",
    "    eigenvalue, eigenvector = np.linalg.eigh(H_matrix)\n",
    "\n",
    "    tmp = np.argsort(eigenvalue)\n",
    "    ground_state_energy = eigenvalue[tmp[0]]\n",
    "    ground_state_vec = np.array(eigenvector[:, tmp[0]])\n",
    "\n",
    "    ground_state_dm = np.outer(ground_state_vec, np.conj(ground_state_vec))\n",
    "\n",
    "    return ground_state_energy, ground_state_dm\n",
    "def N_meas_list_func(start, end, num):\n",
    "    '''Generate a list of number of measurement for the loop\n",
    "    '''\n",
    "    a = pow(end / start, 1 / (num - 1))\n",
    "    N_meas_list = [start]\n",
    "    for i in range(num - 1):\n",
    "        N_meas_list.append(math.floor(a * N_meas_list[-1]))\n",
    "\n",
    "    return N_meas_list\n",
    "def gs_energy_estimate(measurement_dataset, confidence_level, H_global_list):\n",
    "    '''Given the Pauli decomposition of the Hamiltonian of interest and measurement dataset\n",
    "       return the expectaion value of the Hamiltonian (with confidence interval)\n",
    "    '''\n",
    "    E_min = 0\n",
    "    E_max = 0\n",
    "    error_rate = 1 - confidence_level\n",
    "    z = norm.ppf(1 - error_rate / 2)  # Quantile of the input confidence level for binomial distribution\n",
    "    \n",
    "    for pauli_basis_str in H_global_list:\n",
    "        exp, var = exp_var_calculator(measurement_dataset, pauli_basis_str)\n",
    "        num_meas_sub = num_meas_sub_calculator(measurement_dataset, pauli_basis_str)\n",
    "        p_value = 0.5 * (1 + exp)\n",
    "        sigma = z * ((p_value * (1 - p_value) / num_meas_sub) ** 0.5)\n",
    "        E_min = E_min + exp - 2*sigma\n",
    "        E_max = E_max + exp + 2*sigma\n",
    "\n",
    "    return E_min, E_max\n",
    "def gs_energy_estimate(measurement_dataset, confidence_level, H_global_list):\n",
    "    '''Given the Pauli decomposition of the Hamiltonian of interest and measurement dataset\n",
    "       return the expectaion value of the Hamiltonian (with confidence interval)\n",
    "       This version is more rigorous.\n",
    "    '''\n",
    "    E_sum = 0\n",
    "    var_sum = 0\n",
    "    error_rate = 1 - confidence_level\n",
    "    z = norm.ppf(1 - error_rate / 2)  # Quantile of the input confidence level for binomial distribution\n",
    "    \n",
    "    for pauli_basis_str in H_global_list:\n",
    "        exp, var = exp_var_calculator(measurement_dataset, pauli_basis_str)\n",
    "        num_meas_sub = num_meas_sub_calculator(measurement_dataset, pauli_basis_str)\n",
    "        E_sum = E_sum + exp\n",
    "        var_sum = var_sum + var/num_meas_sub\n",
    "\n",
    "    E_min = E_sum - 2.58*var_sum**0.5\n",
    "    E_max = E_sum + 2.58*var_sum**0.5\n",
    "\n",
    "    return E_min, E_max\n",
    "def lower_bound_with_SDP(H, N, M, K, P):\n",
    "    '''Solve the SDP minimization problem with constraints C0 and C0+C1\n",
    "    '''\n",
    "\n",
    "    K_3body = N-G+1 # Number of 3-body subsystems\n",
    "    P_3body = 4**G-1 # Number of Pauli basis for 3-body subsystems\n",
    "    ep = cp.Variable((K, P))\n",
    "    ep_C1 = cp.Variable((N-G+1, 4**G-1))\n",
    "\n",
    "    # Define SDP variables\n",
    "    dm_tilde = []\n",
    "    for k in range(K):\n",
    "        dm_tilde.append( np.array(tensor([qeye(2)] * M)) / 2 **M )\n",
    "    for k in range(K):\n",
    "        for p in range(P):\n",
    "            dm_tilde[k] = dm_tilde[k] + cp.multiply(ep[k, p], np.array(pauliToMatrix(PauliStrList_part[p])))\n",
    "    dm_tilde_C1 = []\n",
    "    for k in range(K_3body):\n",
    "        dm_tilde_C1.append( np.array(tensor([qeye(2)] * G)) / 2 ** G )\n",
    "    for k in range(K_3body): \n",
    "        for p in range(P_3body):\n",
    "            dm_tilde_C1[k] = dm_tilde_C1[k] + cp.multiply(ep_C1[k, p], np.array(pauliToMatrix(PauliStrList_Gbody[p])))\n",
    "\n",
    "            \n",
    "\n",
    "    constraints_C0 = []\n",
    "    for i in range(K):  # non-negative eigenvalues\n",
    "        constraints_C0 += [dm_tilde[i] >> 1e-8]\n",
    "    for i in range(K - 1):  # physically compatitble\n",
    "        constraints_C0 += [cp.partial_trace(dm_tilde[i], dims=[2] * M, axis=0) ==\n",
    "                        cp.partial_trace(dm_tilde[i + 1], dims=[2] * M, axis=M - 1)]\n",
    "\n",
    "    constraints_C1 = []\n",
    "    for i in range(K_3body): \n",
    "        constraints_C1 += [dm_tilde_C1[i] >> 1e-8]  # non-negative eigenvalues\n",
    "\n",
    "    for i in range(K_3body):\n",
    "        constraints_C1 += [cp.partial_trace(dm_tilde_C1[i], dims=[4,2], axis=1) == dm_tilde[i]]\n",
    "        constraints_C1 += [cp.partial_trace(dm_tilde_C1[i], dims=[2,4], axis=0) == dm_tilde[i+1]]\n",
    "\n",
    "\n",
    "    # Solve SDP with conditions C1+C0\n",
    "    H_exp01 = 0\n",
    "    for i in range(K):\n",
    "        H_exp01 = H_exp01 + H @ dm_tilde[i]\n",
    "    prob_C01 = cp.Problem(\n",
    "        cp.Minimize(\n",
    "            cp.real(\n",
    "                cp.trace(\n",
    "                    H_exp01\n",
    "                )\n",
    "            )\n",
    "        ), constraints_C0 + constraints_C1\n",
    "    )\n",
    "    energy_C01 = prob_C01.solve(solver=cp.SCS, verbose=False)\n",
    "\n",
    "    return energy_C01\n",
    "\n",
    "# SDP problem\n",
    "def SDP_variables_C0(ep, measurement_dataset, N, M, K, P):\n",
    "    '''Define SDP variables'''\n",
    "    dm = []\n",
    "    for k in range(K):  # K: number of subsystems\n",
    "        index = list(range(k, k + M, 1))  # [k, k+1, ...]\n",
    "        dm.append(np.array(q_tomography_dm(index, measurement_dataset, N)))\n",
    "    dm_hat = dm\n",
    "    dm_tilde = dm\n",
    "    for k in range(K):\n",
    "        for p in range(P):\n",
    "            dm_tilde[k] = dm_tilde[k] + cp.multiply(ep[k, p], np.array(pauliToMatrix(PauliStrList_part[p])))\n",
    "    return dm_tilde, dm_hat\n",
    "def constraints_C0(ep, coef, dm_tilde, measurement_dataset, N, M, K, P):\n",
    "    '''Define the constraints of the SDP for bisection method:\n",
    "       1. non-negative eigenvalues\n",
    "       2. physically compatitble\n",
    "    '''\n",
    "    constraints = []\n",
    "    for i in range(K):  # non-negative eigenvalues\n",
    "        constraints += [dm_tilde[i] >> 1e-8]\n",
    "    for i in range(K - 1):  # physically compatitble\n",
    "        constraints += [cp.partial_trace(dm_tilde[i], dims=[2] * M, axis=0) ==\n",
    "                        cp.partial_trace(dm_tilde[i + 1], dims=[2] * M, axis=M - 1)]\n",
    "\n",
    "    sigma = np.zeros((K, P))\n",
    "    for i in range(K):\n",
    "        index = list(range(i, i + M, 1))  # [i, i+1, ...]\n",
    "        sigma[i] = Wilson_interval_bisection(coef, index, 0.95, measurement_dataset, N)\n",
    "    constraints += [ep >= -sigma, ep <= sigma]\n",
    "\n",
    "    return constraints\n",
    "def constraints_interval(ep, coef, dm_tilde, measurement_dataset, N, M, K, P):\n",
    "    '''Define the constraints of the SDP for bisection method:\n",
    "       1. non-negative eigenvalues\n",
    "    '''\n",
    "    constraints = []\n",
    "    sigma = np.zeros((K, P))\n",
    "    for i in range(K):\n",
    "        index = list(range(i, i + M, 1))  # [i, i+1, ...]\n",
    "        sigma[i] = Wilson_interval_bisection(coef, index, 0.95, measurement_dataset, N)\n",
    "    constraints += [ep >= -sigma, ep <= sigma]\n",
    "\n",
    "    return constraints\n",
    "def SDP_variables_verify(ep_verify, measurement_dataset, N):\n",
    "    '''Define the varibles of global verification problem\n",
    "    '''\n",
    "    dm_tilde_full = np.array(tensor([qeye(2)] * N)) / 2 ** N\n",
    "    for i in range(4 ** N - 1):\n",
    "        dm_tilde_full = dm_tilde_full + cp.multiply(ep_verify[i], np.array(pauliToMatrix(PauliStrList[i])))\n",
    "    return dm_tilde_full\n",
    "def constraints_verify(ep_verify, coef, dm_tilde, dm_tilde_full, measurement_dataset, N, M, K):\n",
    "    '''Define the constraints of global verification problem:\n",
    "       1. non-negative eigenvalues\n",
    "       2. there exists a global state whose reduced states are the corresponding subsystems' states\n",
    "    '''\n",
    "    constraints_verify = []\n",
    "    constraints_verify += [dm_tilde_full >> 1e-8]  # non-negative eigenvalues\n",
    "\n",
    "    # global verification\n",
    "    constraints_verify += [cp.partial_trace(dm_tilde_full, dims=[2 ** M, 2 ** (N - M)], axis=1) == dm_tilde[0]]\n",
    "    constraints_verify += [cp.partial_trace(dm_tilde_full, dims=[2 ** (N - M), 2 ** M], axis=0) == dm_tilde[-1]]\n",
    "    # constraints_verify += [cp.partial_trace(cp.partial_trace(dm_tilde_full, dims=[2,4,2], axis=0), dims=[4,2], axis=1) == dm_tilde[1]]\n",
    "\n",
    "    if K >= 3:\n",
    "        for i in range(K - 2):\n",
    "            constraints_verify += [cp.partial_trace(\n",
    "                cp.partial_trace(dm_tilde_full, dims=[2 ** (i + 1), 2 ** M, 2 ** (N - M - i - 1)], axis=2),\n",
    "                dims=[2 ** (i + 1), 2 ** M], axis=0) == dm_tilde[i + 1]]\n",
    "\n",
    "    constraints_verify += [ep_verify >= -1, ep_verify <= 1]\n",
    "\n",
    "    return constraints_verify\n",
    "def SDP_variables_C1(ep_C1, measurement_dataset, N, G):\n",
    "    '''Define SDP variables for C1\n",
    "    '''\n",
    "    K_3body = N-G+1 # Number of 3-body subsystems\n",
    "    P_3body = 4**G-1 # Number of Pauli basis for 3-body subsystems\n",
    "    \n",
    "    dm_tilde_C1 = []\n",
    "    for k in range(K_3body):\n",
    "        dm_tilde_C1.append( np.array(tensor([qeye(2)] * G)) / 2 ** G )\n",
    "\n",
    "    for k in range(K_3body): \n",
    "        for p in range(P_3body):\n",
    "            dm_tilde_C1[k] = dm_tilde_C1[k] + cp.multiply(ep_C1[k, p], np.array(pauliToMatrix(PauliStrList_Gbody[p])))\n",
    "    \n",
    "    return dm_tilde_C1\n",
    "def constraints_C1(ep_C1, coef, dm_tilde, dm_tilde_C1, measurement_dataset, N, M, G):\n",
    "    '''Define the constraints of 3-body SDP problem (C1):\n",
    "       1. non-negative eigenvalues\n",
    "       2. there exists a 3-body global state whose reduced states are the corresponding subsystems' states\n",
    "    '''\n",
    "    K_3body = N-G+1 # Number of 3-body subsystems\n",
    "    P_3body = 4**G-1 # Number of Pauli basis for 3-body subsystems\n",
    "\n",
    "    constraints_C1 = []\n",
    "    for i in range(K_3body): \n",
    "        constraints_C1 += [dm_tilde_C1[i] >> 1e-8]  # non-negative eigenvalues\n",
    "\n",
    "    for i in range(K_3body):\n",
    "        constraints_C1 += [cp.partial_trace(dm_tilde_C1[i], dims=[4,2], axis=1) == dm_tilde[i]]\n",
    "        constraints_C1 += [cp.partial_trace(dm_tilde_C1[i], dims=[2,4], axis=0) == dm_tilde[i+1]]\n",
    "\n",
    "    return constraints_C1\n",
    "def SDP_variables_C2(ep_C2, measurement_dataset, N, G):\n",
    "    '''Define SDP variables for C2:\n",
    "    '''\n",
    "    K_3body = N-G+1 # Number of 3-body subsystems\n",
    "    P_3body = 4**G-1 # Number of Pauli basis for 3-body subsystems\n",
    "\n",
    "    dm = []\n",
    "    for k in range(K_3body):  # K: number of subsystems\n",
    "        index = list(range(k, k+G, 1))  # [k, k+1, ...]\n",
    "        dm.append(np.array(q_tomography_dm(index, measurement_dataset, N)))\n",
    "    dm_hat_C2 = dm\n",
    "    dm_tilde_C2 = dm\n",
    "    for k in range(K_3body):\n",
    "        for p in range(P_3body):\n",
    "            dm_tilde_C2[k] = dm_tilde_C2[k] + cp.multiply(ep_C2[k, p], np.array(pauliToMatrix(PauliStrList_Gbody[p])))\n",
    "\n",
    "    return dm_tilde_C2\n",
    "def constraints_C2(ep_C2, coef, dm_tilde, dm_tilde_C2, measurement_dataset, N, M, G):\n",
    "    '''Define the constraints of the SDP for bisection method:\n",
    "       1. there exists a 3-body global state whose reduced states are the corresponding subsystems' states\n",
    "       2. in the confidence interval\n",
    "    '''\n",
    "    K_3body = N-G+1 # Number of 3-body subsystems\n",
    "    P_3body = 4**G-1 # Number of Pauli basis for 3-body subsystems\n",
    "\n",
    "    constraints_C2 = []\n",
    "    for i in range(K_3body):\n",
    "        constraints_C2 += [cp.partial_trace(dm_tilde_C2[i], dims=[4,2], axis=1) == dm_tilde[i]]\n",
    "        constraints_C2 += [cp.partial_trace(dm_tilde_C2[i], dims=[2,4], axis=0) == dm_tilde[i+1]]\n",
    "\n",
    "    sigma = np.zeros((K_3body, P_3body))\n",
    "    for i in range(K_3body):\n",
    "        index = list(range(i, i+G, 1))  # [i, i+1, ...]\n",
    "        sigma[i] = Wilson_interval_bisection(coef, index, 0.95, measurement_dataset, N)\n",
    "    constraints_C2 += [ep_C2 >= -sigma, ep_C2 <= sigma]\n",
    "\n",
    "    return constraints_C2\n",
    "def SDP_solver_min(coef, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P):\n",
    "    '''Solve the SDP minimization problem with constraints C0 and C0+C1\n",
    "    '''\n",
    "    \n",
    "    dm_tilde_copy0 = dm_tilde\n",
    "    dm_tilde_copy1 = dm_tilde\n",
    "\n",
    "    # Solve SDP with conditions C0\n",
    "    constraints = constraints_C0(ep, coef, dm_tilde_copy0, measurement_dataset, N, M, K, P)\n",
    "    H_exp = 0\n",
    "    for i in range(K):\n",
    "        H_exp = H_exp + H @ dm_tilde_copy0[i]\n",
    "    prob_C0 = cp.Problem(\n",
    "        cp.Minimize(\n",
    "            cp.real(\n",
    "                cp.trace(\n",
    "                    H_exp\n",
    "                )\n",
    "            )\n",
    "        ), constraints\n",
    "    )\n",
    "    energy_C0 = prob_C0.solve(solver=cp.SCS, verbose=False)\n",
    "\n",
    "\n",
    "    # Solve SDP with conditions C1+C0\n",
    "    constraints0 = constraints_C0(ep, coef, dm_tilde_copy1, measurement_dataset, N, M, K, P)\n",
    "    constraints1 = constraints_C1(ep_C1, coef, dm_tilde_copy1, dm_tilde_C1, measurement_dataset, N, M, G)\n",
    "    H_exp01 = 0\n",
    "    for i in range(K):\n",
    "        H_exp01 = H_exp01 + H @ dm_tilde_copy1[i]\n",
    "    prob_C01 = cp.Problem(\n",
    "        cp.Minimize(\n",
    "            cp.real(\n",
    "                cp.trace(\n",
    "                    H_exp01\n",
    "                )\n",
    "            )\n",
    "        ), constraints0 + constraints1\n",
    "    )\n",
    "    energy_C01 = prob_C01.solve(solver=cp.SCS, verbose=False)\n",
    "\n",
    "    return energy_C0, energy_C01\n",
    "def SDP_solver_max(coef, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P):\n",
    "    '''Solve the SDP maximization problem with constraints C0 and C0+C1\n",
    "    '''\n",
    "\n",
    "    dm_tilde_copy0 = dm_tilde\n",
    "    dm_tilde_copy1 = dm_tilde\n",
    "\n",
    "    # Solve SDP with conditions C0\n",
    "    constraints = constraints_C0(ep, coef, dm_tilde_copy0, measurement_dataset, N, M, K, P)\n",
    "    H_exp = 0\n",
    "    for i in range(K):\n",
    "        H_exp = H_exp + H @ dm_tilde_copy0[i]\n",
    "    prob_C0 = cp.Problem(\n",
    "        cp.Maximize(\n",
    "            cp.real(\n",
    "                cp.trace(\n",
    "                    H_exp\n",
    "                )\n",
    "            )\n",
    "        ), constraints\n",
    "    )\n",
    "    energy_C0 = prob_C0.solve(solver=cp.SCS, verbose=False)\n",
    "\n",
    "\n",
    "    # Solve SDP with conditions C1+C0\n",
    "    constraints0 = constraints_C0(ep, coef, dm_tilde_copy1, measurement_dataset, N, M, K, P)\n",
    "    constraints1 = constraints_C1(ep_C1, coef, dm_tilde_copy1, dm_tilde_C1, measurement_dataset, N, M, G)\n",
    "    H_exp01 = 0\n",
    "    for i in range(K):\n",
    "        H_exp01 = H_exp01 + H @ dm_tilde_copy1[i]\n",
    "    prob_C01 = cp.Problem(\n",
    "        cp.Maximize(\n",
    "            cp.real(\n",
    "                cp.trace(\n",
    "                    H_exp01\n",
    "                )\n",
    "            )\n",
    "        ), constraints0 + constraints1\n",
    "    )\n",
    "    energy_C01 = prob_C01.solve(solver=cp.SCS, verbose=False)\n",
    "\n",
    "    return energy_C0, energy_C01\n",
    "def biSection_search_min(higher_bound, threshold, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P):\n",
    "    '''Use bi-search method to find the minimum value of the relaxation such that there exists at least one solution in the search space,\n",
    "       with an accuracy of 'threshold'\n",
    "    '''\n",
    "\n",
    "    low = 0\n",
    "    high = higher_bound\n",
    "    max_iter = 6\n",
    "   \n",
    "    energy_C0, energy_C01 = SDP_solver_min(high, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P)\n",
    "    coef = high\n",
    "    \n",
    "    # If no solution exists within the initial higher bounds, increase the higher bound.\n",
    "    while (math.isinf(energy_C0) or math.isinf(energy_C01)) and max_iter > 0:\n",
    "        low = high\n",
    "        high = 2*high\n",
    "        max_iter = max_iter-1\n",
    "        energy_C0, energy_C01 = SDP_solver_min(high, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P)\n",
    "\n",
    "    # If still no solution after expanding the bounds, return an error message.\n",
    "    if max_iter == 0:\n",
    "        return \"No solution found within the search bounds and maximum iterations.\"\n",
    "\n",
    "    # Perform the binary search within the updated bounds.\n",
    "    while abs(high - low) > threshold or (math.isinf(energy_C0) or math.isinf(energy_C01)):\n",
    "        coef = low + abs(high - low) / 2\n",
    "        energy_C0, energy_C01 = SDP_solver_min(coef, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P)\n",
    "        if (math.isinf(energy_C0) or math.isinf(energy_C01)):\n",
    "            low = coef\n",
    "        else:\n",
    "            high = coef\n",
    "\n",
    "    return energy_C0, energy_C01, coef\n",
    "def biSection_search_max(higher_bound, threshold, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P):\n",
    "    '''Use bi-search method to find the minimum value of the relaxation such that there exists at least one solution in the search space,\n",
    "       with an accuracy of 'threshold'\n",
    "    '''\n",
    "\n",
    "    low = 0\n",
    "    high = higher_bound\n",
    "    max_iter = 6\n",
    "\n",
    "    energy_C0, energy_C01 = SDP_solver_max(high, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P)\n",
    "    coef = high\n",
    "    \n",
    "    # If no solution exists within the initial higher bounds, increase the higher bound.\n",
    "    while (math.isinf(energy_C0) or math.isinf(energy_C01)) and max_iter > 0:\n",
    "        low = high\n",
    "        high = 2*high\n",
    "        max_iter = max_iter-1\n",
    "        energy_C0, energy_C01 = SDP_solver_max(high, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P)\n",
    "\n",
    "    # If still no solution after expanding the bounds, return an error message.\n",
    "    if max_iter == 0:\n",
    "        return \"No solution found within the search bounds and maximum iterations.\"\n",
    "\n",
    "    # Perform the binary search within the updated bounds.\n",
    "    while abs(high - low) > threshold or (math.isinf(energy_C0) or math.isinf(energy_C01)):\n",
    "        coef = low + abs(high - low) / 2\n",
    "        energy_C0, energy_C01 = SDP_solver_max(coef, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P)\n",
    "        if (math.isinf(energy_C0) or math.isinf(energy_C01)):\n",
    "            low = coef\n",
    "        else:\n",
    "            high = coef\n",
    "\n",
    "    return energy_C0, energy_C01, coef\n",
    "def biSection_gs(coef_gs, threshold, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P):\n",
    "    '''Use bi-search method to find the approximation of ground state energy\n",
    "    '''\n",
    "\n",
    "    low = 0\n",
    "    max_iter = 6\n",
    "    high = coef_gs\n",
    "   \n",
    "    energy_C0, energy_C01 = SDP_solver_min(high, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P)\n",
    "    coef = high\n",
    "    \n",
    "    # If no solution exists within the initial higher bounds, increase the higher bound.\n",
    "    while (math.isinf(energy_C0) or math.isinf(energy_C01)) and max_iter > 0:\n",
    "        low = high\n",
    "        high = 2*high\n",
    "        max_iter = max_iter-1\n",
    "        energy_C0, energy_C01 = SDP_solver_min(high, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, K, P)\n",
    "    energy_C0_gs = energy_C0 # Store the SDP solutions when the value of relaxation equals the higher bound (to approch the ground energy)\n",
    "    energy_C01_gs = energy_C01 # Store the SDP solutions when the value of relaxation equals the higher bound (to approch the ground energy)\n",
    "\n",
    "    # If still no solution after expanding the bounds, return an error message.\n",
    "    if max_iter == 0:\n",
    "        return \"No solution found within the search bounds and maximum iterations.\"\n",
    "\n",
    "    return energy_C0_gs, energy_C01_gs, coef\n",
    "\n",
    "# Main functions\n",
    "def jordi(N_meas_list, higher_bound, higher_bound_gs, threshold, N, M, K, P):\n",
    "    '''Solve the SDP minimization and maximization problem with the two different constraints for a list of number of measurement\n",
    "    '''\n",
    "\n",
    "    E_min = []\n",
    "    E_min_C0 = []\n",
    "    E_min_C01 = []\n",
    "    E_min_C0_gs = []\n",
    "    E_min_C01_gs = []\n",
    "    E_max = []\n",
    "    E_max_C0 = []\n",
    "    E_max_C01 = []\n",
    "\n",
    "    coef_min = []\n",
    "    coef_max = []\n",
    "    coef_min_gs = []\n",
    "\n",
    "    for N_meas in N_meas_list:\n",
    "        measurement_dataset = generate_meas_dataset(q_state, N_meas, N)\n",
    "        measurement_dataset = {key: value for key, value in measurement_dataset.items() if value} # For reducing the complexity\n",
    "        N_meas_sub = N_meas * (3 ** (N - M))\n",
    "\n",
    "        ep = cp.Variable((K, P))\n",
    "        ep_C1 = cp.Variable((N-G+1, 4**G-1))\n",
    "        dm_tilde, dm_hat = SDP_variables_C0(ep, measurement_dataset, N, M, K, P)\n",
    "        dm_tilde_C1 = SDP_variables_C1(ep_C1, measurement_dataset, N, G)\n",
    "\n",
    "        # Energy with SDP - minimum\n",
    "        E_min_C0_value, E_min_C01_value, coef_min_value = biSection_search_min(higher_bound, threshold, \n",
    "                                                                               ep, ep_C1, dm_tilde, dm_tilde_C1, \n",
    "                                                                               H_local, measurement_dataset, \n",
    "                                                                               N, M, K, P\n",
    "                                                                               )\n",
    "        E_min_C0.append(E_min_C0_value)\n",
    "        E_min_C01.append(E_min_C01_value)\n",
    "        coef_min.append(coef_min_value)\n",
    "\n",
    "        # Energy with SDP - maximum\n",
    "        E_max_C0_value, E_max_C01_value, coef_max_value = biSection_search_max(higher_bound, threshold, \n",
    "                                                                               ep, ep_C1, dm_tilde, dm_tilde_C1, \n",
    "                                                                               H_local, measurement_dataset, \n",
    "                                                                               N, M, K, P\n",
    "                                                                               )\n",
    "        E_max_C0.append(E_max_C0_value)\n",
    "        E_max_C01.append(E_max_C01_value)\n",
    "        coef_max.append(coef_max_value)\n",
    "\n",
    "        # Energy with SDP - ground energy estimate\n",
    "        for coef_gs in higher_bound_gs:\n",
    "            E_min_C0_gs_value, E_min_C01_gs_value, coef_gs = biSection_gs(coef_gs, threshold, \n",
    "                                                                          ep, ep_C1, dm_tilde, dm_tilde_C1, \n",
    "                                                                          H_local, measurement_dataset, \n",
    "                                                                          N, M, K, P\n",
    "                                                                          )\n",
    "            E_min_C0_gs.append(E_min_C0_gs_value)\n",
    "            E_min_C01_gs.append(E_min_C01_gs_value)\n",
    "            coef_min_gs.append(coef_gs)\n",
    "\n",
    "        # Average energy calculated from measurements\n",
    "        E_min_and_max = gs_energy_estimate(measurement_dataset, 0.99, H_global_list)\n",
    "        E_min.append(E_min_and_max[0])\n",
    "        E_max.append(E_min_and_max[1])\n",
    "\n",
    "        print(\"Case N_meas =\", N_meas, \"finished\")\n",
    "\n",
    "    return E_min, E_min_C0, E_min_C01, E_min_C0_gs, E_min_C01_gs, E_max, E_max_C0, E_max_C01, coef_min, coef_max, coef_min_gs\n",
    "def get_SDP_dataset(num_of_shot, N_meas_list, higher_bound, higher_bound_gs, threshold, N, M, K, P):\n",
    "    '''Get the dataset of the solution of the SDP problems\n",
    "    '''\n",
    "\n",
    "    data = {}\n",
    "    data['E_min'] = []\n",
    "    data['E_min_C0'] = []\n",
    "    data['E_min_C01'] = []\n",
    "    data['E_min_C0_gs'] = []\n",
    "    data['E_min_C01_gs'] = []\n",
    "\n",
    "    data['E_max'] = []\n",
    "    data['E_max_C0'] = []\n",
    "    data['E_max_C01'] = []\n",
    "    \n",
    "    coef_data = {}\n",
    "    coef_data['coef_min'] = []\n",
    "    coef_data['coef_max'] = []\n",
    "    coef_data['coef_min_gs'] = []\n",
    "\n",
    "    for i in range(num_of_shot):\n",
    "        E_min, E_min_C0, E_min_C01, E_min_C0_gs, E_min_C01_gs, E_max, E_max_C0, E_max_C01, coef_min, coef_max, coef_min_gs = jordi(\n",
    "            N_meas_list, higher_bound, higher_bound_gs, threshold, N, M, K, P)\n",
    "        data['E_min'].append(E_min)\n",
    "        data['E_min_C0'].append(E_min_C0)\n",
    "        data['E_min_C01'].append(E_min_C01)\n",
    "        data['E_min_C0_gs'].append(E_min_C0_gs)\n",
    "        data['E_min_C01_gs'].append(E_min_C01_gs)\n",
    "\n",
    "        data['E_max'].append(E_max)\n",
    "        data['E_max_C0'].append(E_max_C0)\n",
    "        data['E_max_C01'].append(E_max_C01)\n",
    "\n",
    "        coef_data['coef_min'].append(coef_min)\n",
    "        coef_data['coef_max'].append(coef_max)\n",
    "        coef_data['coef_min_gs'].append(coef_min_gs)\n",
    "    return data, coef_data\n",
    "def process_SDP_dataset(data, num_of_shot, num_data_point, higher_bound_gs):\n",
    "    '''Given the dataset of SDP problem results,\n",
    "       return the mean value and standard deviation\n",
    "    '''\n",
    "    E_mean = {}\n",
    "    E_std = {}\n",
    "\n",
    "    sp_keys = ['E_min_C0_gs', 'E_min_C01_gs'] \n",
    "    for key in data:\n",
    "        tmp = np.array(data[key])\n",
    "        E_mean[key] = np.mean(tmp, axis=0)\n",
    "        E_std[key] = np.std(tmp, axis=0) / num_of_shot ** 0.5\n",
    "\n",
    "    for key in sp_keys:\n",
    "        result_mean = E_mean[key]\n",
    "        result_std = E_std[key]\n",
    "        for i in range(len(higher_bound_gs)):\n",
    "            coef = higher_bound_gs[i]\n",
    "            result_splits_mean = result_mean[i*num_data_point:(i+1)*num_data_point]\n",
    "            result_splits_std = result_std[i*num_data_point:(i+1)*num_data_point]\n",
    "            E_mean[key + str(coef)] = result_splits_mean\n",
    "            E_std[key + str(coef)] = result_splits_std\n",
    "\n",
    "    return E_mean, E_std\n",
    "\n",
    "# Moniter the time complexity with fixed G as N increases\n",
    "import time\n",
    "def time_cost_min_C01(H, measurement_dataset, N, M, K, P):\n",
    "    '''Solve the SDP using bi-section method\n",
    "    '''\n",
    "    ep = cp.Variable((K, P))\n",
    "    ep_C1 = cp.Variable((N-G+1, 4**G-1))\n",
    "    ep_C2 = cp.Variable((N-G+1, 4**G-1))\n",
    "    coef = 1\n",
    "\n",
    "    # Solve SDP with conditions C1+C0\n",
    "    dm_tilde01, dm_hat01 = SDP_variables_C0(ep, measurement_dataset, N, M, K, P)\n",
    "    dm_tilde_C1 = SDP_variables_C1(ep_C1, measurement_dataset, N, G)\n",
    "    constraints0 = constraints_C0(ep, coef, dm_tilde01, measurement_dataset, N, M, K, P)\n",
    "    constraints1 = constraints_C1(ep_C1, coef, dm_tilde01, dm_tilde_C1, measurement_dataset, N, M, G)\n",
    "    \n",
    "    H_exp01 = 0\n",
    "    for i in range(K):\n",
    "        H_exp01 = H_exp01 + H @ dm_tilde01[i]\n",
    "    prob_C1 = cp.Problem(\n",
    "        cp.Minimize(\n",
    "            cp.real(\n",
    "                cp.trace(\n",
    "                    H_exp01\n",
    "                )\n",
    "            )\n",
    "        ), constraints0 + constraints1\n",
    "    )\n",
    "    energy_C1 = prob_C1.solve(solver=cp.SCS, verbose=False)\n",
    "\n",
    "    return energy_C1, coef\n",
    "def time_cost_max_C01(H, measurement_dataset, N, M, K, P):\n",
    "    '''Solve the SDP using bi-section method\n",
    "    '''\n",
    "    ep = cp.Variable((K, P))\n",
    "    ep_C1 = cp.Variable((N-G+1, 4**G-1))\n",
    "    ep_C2 = cp.Variable((N-G+1, 4**G-1))\n",
    "    coef = 1\n",
    "\n",
    "    # Solve SDP with conditions C1+C0\n",
    "    dm_tilde01, dm_hat01 = SDP_variables_C0(ep, measurement_dataset, N, M, K, P)\n",
    "    dm_tilde_C1 = SDP_variables_C1(ep_C1, measurement_dataset, N, G)\n",
    "    constraints0 = constraints_C0(ep, coef, dm_tilde01, measurement_dataset, N, M, K, P)\n",
    "    constraints1 = constraints_C1(ep_C1, coef, dm_tilde01, dm_tilde_C1, measurement_dataset, N, M, G)\n",
    "    \n",
    "    H_exp01 = 0\n",
    "    for i in range(K):\n",
    "        H_exp01 = H_exp01 + H @ dm_tilde01[i]\n",
    "    prob_C1 = cp.Problem(\n",
    "        cp.Maximize(\n",
    "            cp.real(\n",
    "                cp.trace(\n",
    "                    H_exp01\n",
    "                )\n",
    "            )\n",
    "        ), constraints0 + constraints1\n",
    "    )\n",
    "    energy_C1 = prob_C1.solve(solver=cp.SCS, verbose=False)\n",
    "\n",
    "    return energy_C1, coef\n",
    "def time_cost_min_C0(H, measurement_dataset, N, M, K, P):\n",
    "    '''Solve the SDP using bi-section method\n",
    "    '''\n",
    "    ep = cp.Variable((K, P))\n",
    "    coef = 1\n",
    "\n",
    "    # Solve SDP with conditions C0\n",
    "    dm_tilde0, dm_hat0 = SDP_variables_C0(ep, measurement_dataset, N, M, K, P)\n",
    "    constraints0 = constraints_C0(ep, coef, dm_tilde0, measurement_dataset, N, M, K, P)\n",
    "    \n",
    "    H_exp0 = 0\n",
    "    for i in range(K):\n",
    "        H_exp0 = H_exp0 + H @ dm_tilde0[i]\n",
    "    prob_C0 = cp.Problem(\n",
    "        cp.Minimize(\n",
    "            cp.real(\n",
    "                cp.trace(\n",
    "                    H_exp0\n",
    "                )\n",
    "            )\n",
    "        ), constraints0\n",
    "    )\n",
    "    energy_C0 = prob_C0.solve(solver=cp.SCS, verbose=False)\n",
    "\n",
    "    return energy_C0, coef\n",
    "def time_cost_max_C0(H, measurement_dataset, N, M, K, P):\n",
    "    '''Solve the SDP using bi-section method\n",
    "    '''\n",
    "    ep = cp.Variable((K, P))\n",
    "    coef = 1\n",
    "\n",
    "    # Solve SDP with conditions C0\n",
    "    dm_tilde0, dm_hat0 = SDP_variables_C0(ep, measurement_dataset, N, M, K, P)\n",
    "    constraints0 = constraints_C0(ep, coef, dm_tilde0, measurement_dataset, N, M, K, P)\n",
    "    \n",
    "    H_exp0 = 0\n",
    "    for i in range(K):\n",
    "        H_exp0 = H_exp0 + H @ dm_tilde0[i]\n",
    "    prob_C0 = cp.Problem(\n",
    "        cp.Maximize(\n",
    "            cp.real(\n",
    "                cp.trace(\n",
    "                    H_exp0\n",
    "                )\n",
    "            )\n",
    "        ), constraints0\n",
    "    )\n",
    "    energy_C0 = prob_C0.solve(solver=cp.SCS, verbose=False)\n",
    "\n",
    "    return energy_C0, coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 4 # Number of qubits of the entire system\n",
    "M = 2 # Number of qubits of subsystems\n",
    "G = 3 # Number of qubits of partial global system (C1)\n",
    "K = N-M+1 # Number of subsystems\n",
    "P = 4**M-1 # Number of Pauli basis for each subsystem\n",
    "\n",
    "PauliStrList = generate_PauliStrList(N)[1:]\n",
    "PauliStrList_part = generate_PauliStrList(M)[1:]\n",
    "PauliStrList_Gbody = generate_PauliStrList(G)[1:]\n",
    "\n",
    "H_local_list = ['XX','YY'] # Pauli string representation of the local Hamiltonian of subsystems\n",
    "H_global_list = Hamiltonian_global(H_local_list, N, M, K) # Pauli string representation of the Hamiltonian of the whole system\n",
    "H_local = np.array( Hamiltonian_matrix(H_local_list) ) # Matrix representation of the local Hamiltonian of subsystems\n",
    "H_global = np.array( Hamiltonian_matrix(H_global_list) ) # Matrix representation of the Hamiltonian of the whole system\n",
    "\n",
    "ground_state_energy, ground_state_dm = ground_state(H_global) \n",
    "q_state = DensityMatrix(ground_state_dm) \n",
    "lower_bound = lower_bound_with_SDP(H_local, N, M, K, P)\n",
    "\n",
    "num_data_point = 15 # number of N_meas that we select to run\n",
    "N_meas_list = N_meas_list_func(100, 100000, num_data_point) # A list of number of measurement performed in all basis\n",
    "num_of_shot = 100 # Number of repeatation of the experiment\n",
    "\n",
    "higher_bound = 0.2 # Starting trial value for the bi-search method\n",
    "higher_bound_gs = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8] # Trial value for lower bounding the ground state energy\n",
    "threshold = 0.01 # Accuracy of the minimum relaxation value \n",
    "data, coef_data = get_SDP_dataset(num_of_shot=num_of_shot,\n",
    "                       N_meas_list=N_meas_list,\n",
    "                       higher_bound=higher_bound,\n",
    "                       higher_bound_gs=higher_bound_gs,\n",
    "                       threshold=threshold,\n",
    "                       N=N,\n",
    "                       M=M,\n",
    "                       K=K,\n",
    "                       P=P)\n",
    "\n",
    "E_mean, E_std = process_SDP_dataset(data, num_of_shot, num_data_point, higher_bound_gs)\n",
    "name = 'data_N' + str(N) + '_threshold' + str(threshold)\n",
    "filename = '%s.npy' % name\n",
    "np.save(filename, data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('QuantumC')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb1c09c88080a82141bde80abfc5c4dcde1e462f373af1bd572dc93ad8fc5299"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
