{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": ""
    }
   },
   "source": [
    "**Example of minimiation of ground energy of Hamiltonians**\n",
    "1. Cooling method\n",
    "2. Cooling method with SDP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wangzherui/anaconda3/envs/QuantumC/lib/python3.8/site-packages/qutip/__init__.py:66: UserWarning: The new version of Cython, (>= 3.0.0) is not supported.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import time\n",
    "import random\n",
    "import itertools\n",
    "import numpy as np\n",
    "import cvxpy as cp\n",
    "import math\n",
    "import scipy\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from scipy.stats import norm\n",
    "from qutip import *\n",
    "from qiskit import *\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.quantum_info import Statevector, DensityMatrix, Operator, Pauli, partial_trace, state_fidelity, random_density_matrix, random_statevector\n",
    "from qiskit.visualization import plot_histogram, plot_state_city, plot_bloch_multivector, plot_state_paulivec, plot_state_hinton, plot_state_qsphere\n",
    "from qiskit.tools.monitor import job_monitor\n",
    "\n",
    "from SDPforVQE import *\n",
    "from SDPforVQE import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pauli_product(single_pauli_str1, single_pauli_str2):\n",
    "    '''Compute the product of Pauli operators in an analytical way\n",
    "    Example 1:\n",
    "        INPUT: 'XI', 'IY' \n",
    "        OUTPUT: [1, 'XY'] (Because XI times IY is XY)\n",
    "    Example 2:\n",
    "        INPUT: 'X', 'Y' \n",
    "        OUTPUT: [1j, 'Z'] (Because X times Y is iZ)\n",
    "    '''\n",
    "\n",
    "    if single_pauli_str1 == 'I':\n",
    "        return [1, single_pauli_str2]\n",
    "    if single_pauli_str2 == 'I':\n",
    "        return [1, single_pauli_str1]\n",
    "\n",
    "    if single_pauli_str1 == 'X':\n",
    "        if single_pauli_str2 == 'X':\n",
    "            return [1, 'I']\n",
    "        elif single_pauli_str2 == 'Y':\n",
    "            return [1j, 'Z']\n",
    "        elif single_pauli_str2 == 'Z':\n",
    "            return [-1j, 'Y']\n",
    "        \n",
    "    if single_pauli_str1 == 'Y':\n",
    "        if single_pauli_str2 == 'X':\n",
    "            return [-1j, 'Z']\n",
    "        elif single_pauli_str2 == 'Y':\n",
    "            return [1, 'I']\n",
    "        elif single_pauli_str2 == 'Z':\n",
    "            return [1j, 'X']\n",
    "        \n",
    "    if single_pauli_str1 == 'Z':\n",
    "        if single_pauli_str2 == 'X':\n",
    "            return [1j, 'Y']\n",
    "        elif single_pauli_str2 == 'Y':\n",
    "            return [-1j, 'X']\n",
    "        elif single_pauli_str2 == 'Z':\n",
    "            return [1, 'I']\n",
    "\n",
    "def pauli_commutator(pauli_str1, pauli_str2):\n",
    "    '''Compute the commutator of two Pauli operators in an analytical way\n",
    "    Example 1:\n",
    "        INPUT: 'XI', 'IY' \n",
    "        OUTPUT: 0 (Because [XI,IY]=0)\n",
    "    Example 2:\n",
    "        INPUT: 'X', 'Y' \n",
    "        OUTPUT: [2j, Z] (Because [X,Y]=2iZ)\n",
    "    '''\n",
    "    \n",
    "    commutator = pauliToMatrix(pauli_str1)*pauliToMatrix(pauli_str2) - pauliToMatrix(pauli_str2)*pauliToMatrix(pauli_str1)\n",
    "    \n",
    "    if np.all(np.array(commutator) == 0):\n",
    "        return 0 \n",
    "    else:\n",
    "        commutator_str = ''\n",
    "        coef = 2\n",
    "        for i in range(len(pauli_str1)):\n",
    "            result = pauli_product(pauli_str1[i], pauli_str2[i])\n",
    "            commutator_str = commutator_str + result[1]\n",
    "            coef = coef*result[0]\n",
    "    \n",
    "        return coef, commutator_str\n",
    "\n",
    "def qiskit_statevec_map(statevec_qiskit, N):\n",
    "    '''Qiskit orders qubits in a endian way, \n",
    "       this function is used to convert a state vector that written in endian ordering to a normal ordering\n",
    "    '''\n",
    "    statevec_qiskit = np.array(statevec_qiskit)\n",
    "    statevec_normal = np.zeros_like(statevec_qiskit, dtype=complex)\n",
    "    \n",
    "    for i in range(2**N):\n",
    "        binary_index = format(i, f'0{N}b')  # Convert the index to an N-bit binary string\n",
    "        reversed_index = int(binary_index[::-1], 2)  # Reverse the binary string and convert it back to an integer\n",
    "        \n",
    "        statevec_normal[reversed_index] = statevec_qiskit[i]\n",
    "\n",
    "    return Statevector(statevec_normal)\n",
    "\n",
    "def available_h_set(N, M, K, model_type):\n",
    "    '''Get all the accessible operations according to the layout of the Hamiltonian of insterest'''\n",
    "\n",
    "    h_set = set({})\n",
    "\n",
    "    if model_type == 'open':\n",
    "        for i in range(N):\n",
    "            h_set.add('I'*i + 'X' + 'I'*(N-i-1))\n",
    "            h_set.add('I'*i + 'Y' + 'I'*(N-i-1))\n",
    "            h_set.add('I'*i + 'Z' + 'I'*(N-i-1))\n",
    "        PauliStrList_part = generate_PauliStrList(M)[1:]\n",
    "        for k in range(K):\n",
    "            for basis in PauliStrList_part:\n",
    "                h_set.add('I'*k + basis + 'I'*(N-k-M))\n",
    "\n",
    "    if model_type == 'closed':\n",
    "        for i in range(N):\n",
    "            h_set.add('I'*i + 'X' + 'I'*(N-i-1))\n",
    "            h_set.add('I'*i + 'Y' + 'I'*(N-i-1))\n",
    "            h_set.add('I'*i + 'Z' + 'I'*(N-i-1))\n",
    "        PauliStrList_part = generate_PauliStrList(M)[1:]\n",
    "        for k in range(N-M+1):\n",
    "            for basis in PauliStrList_part:\n",
    "                h_set.add('I'*(k) + basis + 'I'*(N-k-M))\n",
    "        for basis in PauliStrList_part:\n",
    "            h_set.add(basis[0] + 'I'*(N-M) + basis[1])\n",
    "            \n",
    "    return h_set\n",
    "\n",
    "def get_reduced_pauli_strings(pauli_str):\n",
    "    '''Given a Pauli string, eliminate all \"I\", and thus leaves the reduced Pauli string\n",
    "    Example:\n",
    "        INPUT: 'XIZIIY' \n",
    "        OUTPUT: 'XZY'\n",
    "    '''\n",
    "    non_trivial_indices = []\n",
    "    for i, char in enumerate(pauli_str): # Iterate through the characters in the Pauli string\n",
    "        if char in ['X', 'Y', 'Z']: # Check if the character represents a non-trivial Pauli operator\n",
    "            non_trivial_indices.append(i) # Append the index to the list of non-trivial indices\n",
    "\n",
    "    return non_trivial_indices\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_relevant_indices(h_set, H_global_list):\n",
    "    '''Get the set of qubit indices of all the relevant reduced density matrices, \n",
    "       which are used to calculate A=<hHh-H> and B=i<hH-Hh>\n",
    "    Args:\n",
    "       h_set: Set of accessible Pauli operators in the lab\n",
    "       H_global_list: A list Pauli strings which describes the global Hamiltonian\n",
    "    '''\n",
    "    set_of_indices = set({})\n",
    "\n",
    "    for h in h_set:\n",
    "        for H in H_global_list:\n",
    "            tmp = pauli_commutator(h, H)\n",
    "            if tmp != 0:\n",
    "                relevant_index = get_reduced_pauli_strings(tmp[1])\n",
    "                set_of_indices.add(tuple(relevant_index))\n",
    "                \n",
    "    return set_of_indices\n",
    "\n",
    "def get_rdm_dict(dm_Mbody, meas_dataset, \n",
    "                 h_set, H_global_list, N, M, K,\n",
    "                 model_type):\n",
    "    '''Get the dictionary for all relevant reduced density matrices required to calculate A=<hHh-H> and B=i<hH-Hh> \n",
    "    Args:\n",
    "       dm_Mbody: A list of M-body density matrices, which can be obtained by SDP or just tomography\n",
    "       meas_dataset: measurement dataset\n",
    "       h_set: Set of accessible Pauli operators in the lab\n",
    "       H_global_list: A list Pauli strings which describes the global Hamiltonian\n",
    "    '''\n",
    "    set_of_indices = get_all_relevant_indices(h_set, H_global_list)\n",
    "    \n",
    "    # Make a dictionary for all the relevant reduced density matrices\n",
    "    dm_dict = {}\n",
    "    for index in set_of_indices:\n",
    "        dm_dict[tuple(index)] = np.array(q_tomography_dm(list(index), meas_dataset, N))\n",
    "    \n",
    "    # Replace the reduced density matrices that are associated with local Hamiltonians with dm_Mbody \n",
    "    # dm_Mbody can be obtained by SDP or just tomography\n",
    "    if model_type=='open':\n",
    "        for k in range(K):  # K: number of subsystem\n",
    "            index = list(range(k, k + M, 1))  # [k, k+1, ...]\n",
    "            dm_dict[tuple(index)] = dm_Mbody[index[0]]\n",
    "    if model_type=='closed':\n",
    "        for k in range(K):  # K: number of subsystems\n",
    "            index = [(k + i) % K for i in range(M)]  # [k, k+1, ...]\n",
    "            dm_dict[tuple(index)] = dm_Mbody[index[0]]\n",
    "        \n",
    "    return dm_dict\n",
    "\n",
    "def evolved_rdm(layer_operators, rdm_index, rdm):\n",
    "    '''Given layer operator and a reduced density matrix (and its index),\n",
    "       compute the evolved reduced density matrix\n",
    "    Args: \n",
    "       layer_operators: A layer of unitary operators\n",
    "       rdm: density matrix to be evovled\n",
    "       rdm_index: the qubit indices of the rdm\n",
    "    '''\n",
    "    register = list(range(len(rdm_index)))\n",
    "    \n",
    "    for operator_index in layer_operators: # Loop over every unitary operator in this layer\n",
    "\n",
    "        overlap_index = list(set(tuple(rdm_index)) & set(operator_index))\n",
    "        extra_I_index = list(set(tuple(rdm_index)) - set(operator_index))\n",
    "\n",
    "        if len(overlap_index) > 0:\n",
    "            h_best, B, t_opt, decrease = layer_operators[operator_index] # Fetch the operator associated with operator_index\n",
    "            reduced_h = ''.join(h_best[i] for i in rdm_index) # Get the reduced Pauli strings (e.g.: 'XYIII' to 'XY')\n",
    "            \n",
    "            # Get the reduced operator \n",
    "            if (B < 0 and t_opt < 0):\n",
    "                reduced_U = Operator( scipy.linalg.expm( -1j * (t_opt+math.pi/2) * np.array(pauliToMatrix(reduced_h)) ) )\n",
    "            elif (B <= 0 and t_opt >= 0):\n",
    "                reduced_U = Operator( scipy.linalg.expm( -1j * t_opt * np.array(pauliToMatrix(reduced_h)) ) )\n",
    "            elif (B >= 0 and t_opt <= 0):\n",
    "                reduced_U = Operator( scipy.linalg.expm( 1j * (-t_opt) * np.array(pauliToMatrix(reduced_h)) ) )\n",
    "            elif (B > 0 and t_opt > 0):\n",
    "                reduced_U = Operator( scipy.linalg.expm( 1j * (-t_opt+math.pi/2) * np.array(pauliToMatrix(reduced_h)) ) )\n",
    "            \n",
    "            # Evolve\n",
    "            rdm = np.array( DensityMatrix(np.array(rdm)).evolve(reduced_U, register) )\n",
    " \n",
    "    return rdm\n",
    "    \n",
    "def get_current_rdm(layer_operators, dm_dict):\n",
    "    '''Given the layer operators and measurement dataset,\n",
    "       comupte all the M-body reduced density matrices and single-qubit density matrices\n",
    "    Args: \n",
    "       layer_operators: A layer of unitary operators\n",
    "       dm_dict: The dictionary that stores all relevant reduced density matrices required to calculate A=<hHh-H> and B=i<hH-Hh> \n",
    "    '''\n",
    "    dm_dict_new = {}\n",
    "    \n",
    "    for rdm_index in dm_dict: # Loop through every rdm in dm_dict\n",
    "        rdm = dm_dict[rdm_index]\n",
    "        dm_dict_new[tuple(rdm_index)] = evolved_rdm(layer_operators, rdm_index, rdm) # Get the evolved reduced density matrix\n",
    "        \n",
    "    return dm_dict_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_h_best(dm_dict, h_set, H_global_list, N, M, K):\n",
    "    '''Given the accessible set operations and the reduced density matrices,\n",
    "       find the 'cooling' operation which leads to the maximal decrease of energy expection\n",
    "    Args: \n",
    "       dm_dict: The dictionary that stores all relevant reduced density matrices required to calculate A=<hHh-H> and B=i<hH-Hh> \n",
    "       h_set: Set of accessible Pauli operators in the lab\n",
    "       H_global_list: A list Pauli strings which describes the global Hamiltonian\n",
    "    '''\n",
    "    \n",
    "    h_cool = [] # Set of h such that i<[h,H]> is smaller than 0 and the corresponding optimal time t_opt\n",
    "    \n",
    "    for h in h_set: # Loop through every Pauli operator in the accessible set h_set\n",
    "        \n",
    "        # Compute commutator [h,H]\n",
    "        commutator_1st_list = [] # [h,H]\n",
    "        for H in H_global_list:\n",
    "            tmp = pauli_commutator(h, H)\n",
    "            if tmp != 0:\n",
    "                commutator_1st_list.append(tmp)\n",
    "\n",
    "        # Get B = i<[h,H]>\n",
    "        B_tmp = 0\n",
    "        for commutator in commutator_1st_list:\n",
    "            relevant_index = get_reduced_pauli_strings(commutator[1])\n",
    "            rho = dm_dict[tuple(relevant_index)] # reduced density matrices\n",
    "            commutator_sub = commutator[1].replace('I', '')\n",
    "            exp = np.trace(np.matmul(np.array(pauliToMatrix(commutator_sub)), np.array(rho)))\n",
    "            B_tmp += exp*commutator[0]\n",
    "        B = B_tmp*1j\n",
    "        \n",
    "        # Compute commutator [h,[h,H]]\n",
    "        commutator_2nd_list = [] # [h,[h,H]]\n",
    "        for h_H in commutator_1st_list:\n",
    "            coef_1st = h_H[0]\n",
    "            if pauli_commutator(h, h_H[1]) != 0:\n",
    "                coef_2nd, commutator_2nd = pauli_commutator(h, h_H[1])\n",
    "                commutator_2nd_list.append( (coef_1st*coef_2nd, commutator_2nd) )\n",
    "                \n",
    "        # Get A = -1/2*<[h,[h,H]]>\n",
    "        A_tmp = 0\n",
    "        for commutator in commutator_2nd_list:\n",
    "            relevant_index = get_reduced_pauli_strings(commutator[1])\n",
    "            rho = dm_dict[tuple(relevant_index)] # reduced density matrices\n",
    "            # if np.shape(rho) == ():   \n",
    "            #     print(relevant_index)\n",
    "            commutator_sub = commutator[1].replace('I', '')\n",
    "            exp = np.trace(np.matmul(np.array(pauliToMatrix(commutator_sub)), np.array(rho)))\n",
    "            A_tmp += exp*commutator[0]\n",
    "        A = -1/2*A_tmp\n",
    "\n",
    "        #if A.real != 0 and B.real != 0:\n",
    "        if A.real != 0:\n",
    "            t_opt = 1/2*math.atan(-B.real/A.real) # The optimal time to evolve with\n",
    "            decrease = 0.5*(A.real-math.sqrt(A.real**2+B.real**2)) # The decrease\n",
    "            h_cool.append( (h, B.real, t_opt, decrease) ) # (Pauli string of h, B, t_opt, decrease)\n",
    "\n",
    "        # Select the operator h which leads to the most decrease\n",
    "        if len(h_cool)>0:\n",
    "            h_best, B, t_opt, decrease = max(h_cool, key=lambda x: abs(x[3]))\n",
    "        else:\n",
    "            h_best, B, t_opt, decrease = 'I'*N, 0, 0, 0\n",
    "  \n",
    "    return h_best, B, t_opt, decrease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_compatible_paulis(N, qubit_index):\n",
    "    '''Find the set of Pauli operators that support qubits associated with the input qubit_index\n",
    "    Args: \n",
    "       N: number of qubits of the whole system\n",
    "       qubit_index: indices of qubits\n",
    "    Example:\n",
    "       INPUT: N=3, qubit_index=[2]\n",
    "       OUTPUT: {IIX, IIY, IIZ}\n",
    "    '''\n",
    "    \n",
    "    h_set = generate_PauliStrList(len(qubit_index))[1:]\n",
    "    identity_string = 'I'*N\n",
    "    \n",
    "    new_h_set = []\n",
    "\n",
    "    for pauli_string in h_set:\n",
    "        new_string_list = list(identity_string)\n",
    "\n",
    "        for i in qubit_index:\n",
    "            new_string_list[i] = pauli_string[qubit_index.index(i)]\n",
    "\n",
    "        new_h_set.append(''.join(new_string_list))\n",
    "\n",
    "    return new_h_set\n",
    "\n",
    "def find_incompatible_paulis(pauli_set, given_pauli):\n",
    "    '''Find the set of Pauli operators that support qubits NOT associated with the input qubit_index\n",
    "    Args: \n",
    "       pauli_set: set of pauli operator string\n",
    "       given_pauli: a pauli string\n",
    "    Example:\n",
    "       INPUT: pauli_set = {XXI, YYY, ZZI, ZYY}, given_pauli={IIX}\n",
    "       OUTPUT: {XXI, ZZI}\n",
    "    '''\n",
    "    # Find indices of non-'I' characters in the given Pauli string\n",
    "    non_I_indices = [i for i, char in enumerate(given_pauli) if char != 'I']\n",
    "\n",
    "    # Find Pauli strings in the set with 'I' at these indices\n",
    "    incompatible_paulis = set()\n",
    "    for pauli in pauli_set:\n",
    "        if all(pauli[i] == 'I' for i in non_I_indices):\n",
    "            incompatible_paulis.add(pauli)\n",
    "\n",
    "    return incompatible_paulis\n",
    "\n",
    "def find_layer_operator(dm_Mbody, meas_dataset, input_state, N_meas,\n",
    "                        h_set, H_global_list, N, M, K,\n",
    "                        num_of_sweep,\n",
    "                        model_type):\n",
    "    '''Find a layer operator of algorithmic cooling\n",
    "    Args:\n",
    "       dm_dict: The dictionary that stores all relevant reduced density matrices required to calculate A=<hHh-H> and B=i<hH-Hh> \n",
    "       h_set: Set of accessible Pauli operators in the lab\n",
    "       H_global_list: A list Pauli strings which describes the global Hamiltonian\n",
    "    '''\n",
    "    \n",
    "    layer_operators_list = [] # A list of operators that forms the layer\n",
    "                              # Each element of this list refers to one 'sub-layer' of this layer operator\n",
    "                              # For example, we have only one 'sub-layer' in this list if num_of_sweep=0, and two if num_of_sweep=1\n",
    "    layer_operators = {} # Initialize the first sweep\n",
    "\n",
    "    dm_dict = get_rdm_dict(dm_Mbody, meas_dataset, h_set, H_global_list, N, M, K, model_type)\n",
    "    while len(h_set) != 0:\n",
    "        # Get the operator which gives the most decrease\n",
    "        h_best, B, t_opt, decrease = find_h_best(dm_dict, h_set, H_global_list, N, M, K)\n",
    "        counter = 0\n",
    "        while h_best == N*'I':\n",
    "            counter = counter+1\n",
    "            meas_dataset_new = generate_meas_dataset(input_state, N_meas, N) \n",
    "            \n",
    "            dm = []\n",
    "            if model_type=='open':\n",
    "                for k in range(K):  # K: number of subsystems\n",
    "                    index = list(range(k, k + M, 1))  # [k, k+1, ...]\n",
    "                    dm.append(np.array(q_tomography_dm(index, meas_dataset_new, N)))\n",
    "                dm_hat = dm.copy()\n",
    "            if model_type=='closed':\n",
    "                for k in range(K):  # K: number of subsystems\n",
    "                    index = [(k + i) % K for i in range(M)]  # [k, k+1, ...]\n",
    "                    dm.append(np.array(q_tomography_dm(index, meas_dataset_new, N)))\n",
    "                dm_hat = dm.copy()\n",
    "\n",
    "            dm_dict = get_rdm_dict(dm_hat, meas_dataset_new, h_set, H_global_list, N, M, K, model_type)\n",
    "            h_best, B, t_opt, decrease = find_h_best(dm_dict, h_set, H_global_list, N, M, K)\n",
    "\n",
    "        layer_operators[ tuple([i for i, char in enumerate(h_best) if char != 'I']) ] = tuple((h_best, B, t_opt, decrease))\n",
    "        \n",
    "        # Evolve the reduced density matrices with this newly-getted operator\n",
    "        new_operator = {} # Get the unitary operator we get\n",
    "        new_operator[ tuple([i for i, char in enumerate(h_best) if char != 'I']) ] = tuple((h_best, B, t_opt, decrease))\n",
    "        dm_dict = get_current_rdm(new_operator, dm_dict)\n",
    "        \n",
    "        # Updated the accessible set of operators\n",
    "        h_set = find_incompatible_paulis(h_set, h_best)\n",
    "    \n",
    "    layer_operators_list.append(layer_operators)\n",
    "    \n",
    "    # Get the layout of this layer operator\n",
    "    layout = list(layer_operators.keys())\n",
    "    \n",
    "    # Do the sweep\n",
    "    for i in range(num_of_sweep):\n",
    "\n",
    "        sweep_operators = {}\n",
    "\n",
    "        for qubit_index in layout:\n",
    "\n",
    "            h_set = find_compatible_paulis(N, list(qubit_index))\n",
    "\n",
    "            h_best, B, t_opt, decrease = find_h_best(dm_dict, h_set, H_global_list, N, M, K)\n",
    "            sweep_operators[ tuple([i for i, char in enumerate(h_best) if char != 'I']) ] = tuple((h_best, B, t_opt, decrease))\n",
    "            \n",
    "            new_operator = {}\n",
    "            new_operator[ tuple([i for i, char in enumerate(h_best) if char != 'I']) ] = tuple((h_best, B, t_opt, decrease))\n",
    "            dm_dict = get_current_rdm(new_operator, dm_dict)\n",
    "\n",
    "        layer_operators_list.append(sweep_operators)\n",
    "\n",
    "\n",
    "    return layer_operators_list\n",
    "\n",
    "def find_layer_operator_HF(dm_dict, h_set, H_global_list, N, M, K,\n",
    "                        num_of_sweep):\n",
    "    '''Find a layer operator of algorithmic cooling\n",
    "    Args:\n",
    "       dm_dict: The dictionary that stores all relevant reduced density matrices required to calculate A=<hHh-H> and B=i<hH-Hh> \n",
    "       h_set: Set of accessible Pauli operators in the lab\n",
    "       H_global_list: A list Pauli strings which describes the global Hamiltonian\n",
    "    '''\n",
    "    \n",
    "    layer_operators_list = [] # A list of operators that forms the layer\n",
    "                              # Each element of this list refers to one 'sub-layer' of this layer operator\n",
    "                              # For example, we have only one 'sub-layer' in this list if num_of_sweep=0, and two if num_of_sweep=1\n",
    "    layer_operators = {} # Initialize the first sweep\n",
    "    while len(h_set) != 0:\n",
    "        # Get the operator which gives the most decrease\n",
    "        h_best, B, t_opt, decrease = find_h_best(dm_dict, h_set, H_global_list, N, M, K)\n",
    "        layer_operators[ tuple([i for i, char in enumerate(h_best) if char != 'I']) ] = tuple((h_best, B, t_opt, decrease))\n",
    "        \n",
    "        # Evolve the reduced density matrices with this newly-getted operator\n",
    "        new_operator = {} # Get the unitary operator we get\n",
    "        new_operator[ tuple([i for i, char in enumerate(h_best) if char != 'I']) ] = tuple((h_best, B, t_opt, decrease))\n",
    "        dm_dict = get_current_rdm(new_operator, dm_dict)\n",
    "        \n",
    "        # Updated the accessible set of operators\n",
    "        h_set = find_incompatible_paulis(h_set, h_best)\n",
    "    \n",
    "    layer_operators_list.append(layer_operators)\n",
    "    \n",
    "    # Get the layout of this layer operator\n",
    "    layout = list(layer_operators.keys())\n",
    "    \n",
    "    # Do the sweep\n",
    "    for i in range(num_of_sweep):\n",
    "\n",
    "        sweep_operators = {}\n",
    "\n",
    "        for qubit_index in layout:\n",
    "\n",
    "            h_set = find_compatible_paulis(N, list(qubit_index))\n",
    "\n",
    "            h_best, B, t_opt, decrease = find_h_best(dm_dict, h_set, H_global_list, N, M, K)\n",
    "            sweep_operators[ tuple([i for i, char in enumerate(h_best) if char != 'I']) ] = tuple((h_best, B, t_opt, decrease))\n",
    "            \n",
    "            new_operator = {}\n",
    "            new_operator[ tuple([i for i, char in enumerate(h_best) if char != 'I']) ] = tuple((h_best, B, t_opt, decrease))\n",
    "            dm_dict = get_current_rdm(new_operator, dm_dict)\n",
    "\n",
    "        layer_operators_list.append(sweep_operators)\n",
    "\n",
    "\n",
    "    return layer_operators_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dm(N, qiskit_state, qubit_index):\n",
    "    '''Given a multi-qubit state and index, \n",
    "       get the density matrix of the reduced state associated with the index\n",
    "    Args:\n",
    "       N: number of qubits of the whole system\n",
    "       qiskit_state: a quantum state with qiskit structure\n",
    "       qubit_index: indices of qubits of interest\n",
    "    '''\n",
    "\n",
    "    basis_list = generate_sub_PauliStrList(N, qubit_index)\n",
    "    \n",
    "    # First get the Bloch vector\n",
    "    Bloch_vec = []\n",
    "    for basis in basis_list:\n",
    "        basis = basis[::-1] # Qiskit use endian, so we take the reverse here\n",
    "        Bloch_vec.append(qiskit_state.expectation_value(oper=Pauli(basis), qargs=None))\n",
    "    \n",
    "    # Now compute the reduced density matrix\n",
    "    dm = 0\n",
    "    for i in range(4**len(qubit_index)-1):\n",
    "        basis = basis_list[i]\n",
    "        sub_basis = ''.join([basis[i] for i in qubit_index])\n",
    "        dm += Bloch_vec[i] * pauliToMatrix(sub_basis)\n",
    "    dm += tensor([qeye(2)] * len(qubit_index))\n",
    "\n",
    "    return 1 / (2 ** len(qubit_index)) * dm\n",
    "\n",
    "def get_HF_state(H_global_list, H_global_matrix, N, M, K, model_type):\n",
    "    '''Get the product state with the lowest <H>\n",
    "    Args:\n",
    "       H_global_list: A list Pauli strings which describes the global Hamiltonian\n",
    "       H_global_matrix: matrix representation of the global Hamiltonian in computational basis\n",
    "    '''\n",
    "\n",
    "    # Initialize state to a random tensor product state\n",
    "    input_state = np.array(DensityMatrix(random_statevector(2))) # Make the first qubit a random pure state\n",
    "    for i in range(N-1):\n",
    "        statevec = random_statevector(2)\n",
    "        dm = DensityMatrix(statevec)\n",
    "        input_state = np.kron(input_state, np.array(dm))\n",
    "    input_state = DensityMatrix(input_state) # This is an N-qubit random tensor product state\n",
    "\n",
    "    h_set = available_h_set(N, M=1, K=N, model_type='open')\n",
    "    set_of_indices = get_all_relevant_indices(h_set, H_global_list)\n",
    "\n",
    "    exp_H_value = np.real(np.trace( np.matmul(input_state, H_global_matrix) ))\n",
    "    exp_H_value_list = [exp_H_value]\n",
    "    diff = 10\n",
    "    \n",
    "    qc = QuantumCircuit(N)\n",
    "\n",
    "    while abs(diff) > 1e-3:\n",
    "\n",
    "        exp_H_value_old = exp_H_value\n",
    "        \n",
    "        # Make a dictionary for all the relevant reduced density matrices\n",
    "        dm_dict = {}\n",
    "        for qubit_index in set_of_indices:\n",
    "            dm_dict[tuple(qubit_index)] = np.array( get_dm(N, input_state, qubit_index) )\n",
    "            \n",
    "        # Find the layer operators that gives a decrease to <H>   \n",
    "        layer_operators_list = find_layer_operator_HF(dm_dict, h_set, H_global_list, N, M, K, num_of_sweep=0)\n",
    "    \n",
    "        # Evolve the state with the obtained layer operators\n",
    "        for i in range(len(layer_operators_list)):\n",
    "            layer_operators = layer_operators_list[i]\n",
    "\n",
    "            for qubit_index in layer_operators:\n",
    "                register = list(qubit_index)\n",
    "                h_best, B, t_opt, decrease = layer_operators[qubit_index]\n",
    "                h_best_reduced = ''.join(char for char in h_best if char != 'I')\n",
    "            \n",
    "                if (B < 0 and t_opt < 0):\n",
    "                    U = Operator( scipy.linalg.expm( -1j * (t_opt+math.pi/2) * np.array(pauliToMatrix(h_best_reduced)) ) )\n",
    "                elif (B <= 0 and t_opt >= 0):\n",
    "                    U = Operator( scipy.linalg.expm( -1j * t_opt * np.array(pauliToMatrix(h_best_reduced)) ) )\n",
    "                elif (B >= 0 and t_opt <= 0):\n",
    "                    U = Operator( scipy.linalg.expm( 1j * (-t_opt) * np.array(pauliToMatrix(h_best_reduced)) ) )\n",
    "                elif (B > 0 and t_opt > 0):\n",
    "                    U = Operator( scipy.linalg.expm( 1j * (-t_opt+math.pi/2) * np.array(pauliToMatrix(h_best_reduced)) ) )\n",
    "                    \n",
    "                input_state = input_state.evolve(U, register[::-1])\n",
    "                qc.append(U, register[::-1])\n",
    "        qc.barrier()\n",
    "\n",
    "        exp_H_value = np.real(np.trace( np.matmul(input_state, H_global_matrix) ))\n",
    "        exp_H_value_list.append(exp_H_value)\n",
    "        diff = exp_H_value - exp_H_value_old\n",
    "\n",
    "    qc.draw('mpl')\n",
    "\n",
    "    return DensityMatrix(input_state), exp_H_value_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SDP_solver_min_C01(coef:float, \n",
    "                   ep:cp.expressions.variable.Variable, ep_C1:cp.expressions.variable.Variable, \n",
    "                   dm_tilde:cp.atoms.affine.add_expr.AddExpression, dm_tilde_C1:cp.atoms.affine.add_expr.AddExpression, \n",
    "                   H:np.ndarray, \n",
    "                   measurement_dataset:Dict[str,List[str]], \n",
    "                   N:int, M:int, G:int, K:int, P:int,\n",
    "                   model_type:str) -> (float,float,float):\n",
    "    '''Solve the SDP minimization problem with constraints C0 and C0+C1\n",
    "    '''\n",
    "    \n",
    "    dm_tilde_copy01 = dm_tilde\n",
    "\n",
    "    # Solve SDP with conditions C1+C0\n",
    "    constraints_0 = constraints_C0(ep, coef, dm_tilde_copy01, measurement_dataset, N, M, K, P, model_type)\n",
    "    constraints_1 = constraints_C1(ep_C1, coef, dm_tilde_copy01, dm_tilde_C1, measurement_dataset, N, M, G, K, model_type)\n",
    "    H_exp01 = 0\n",
    "    for i in range(K):\n",
    "        H_exp01 = H_exp01 + H @ dm_tilde_copy01[i]\n",
    "    prob_C01 = cp.Problem(\n",
    "        cp.Minimize(\n",
    "            cp.real(\n",
    "                cp.trace(\n",
    "                    H_exp01\n",
    "                )\n",
    "            )\n",
    "        ), constraints_0 + constraints_1\n",
    "    )\n",
    "    energy_C01 = prob_C01.solve(solver=cp.SCS, verbose=False)\n",
    "    if prob_C01.status != cp.OPTIMAL:\n",
    "        energy_C01 = float('inf') \n",
    "  \n",
    "    dm_SDP = []\n",
    "    for i in range(K):\n",
    "        dm_SDP.append(dm_tilde_copy01[i].value)\n",
    "\n",
    "\n",
    "    return energy_C01, dm_SDP\n",
    "\n",
    "def biSection_search_min_C01(higher_bound:float, threshold:float, \n",
    "                         ep:cp.expressions.variable.Variable, ep_C1:cp.expressions.variable.Variable, \n",
    "                         dm_tilde:cp.atoms.affine.add_expr.AddExpression, dm_tilde_C1:cp.atoms.affine.add_expr.AddExpression, \n",
    "                         H:np.ndarray, \n",
    "                         measurement_dataset:Dict[str,List[str]], \n",
    "                         N:int, M:int, G:int, K:int, P:int,\n",
    "                         model_type:str) -> (float, float, float, float):\n",
    "    '''Use bi-search method to find the minimum value of the relaxation such that there exists at least one solution in the search space,\n",
    "       with an accuracy of 'threshold'\n",
    "    '''\n",
    "\n",
    "    low = 0\n",
    "    high = higher_bound\n",
    "    max_iter = 10\n",
    "   \n",
    "    energy_C01, dm_SDP = SDP_solver_min_C01(high, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, G, K, P, model_type)\n",
    "    coef = high\n",
    "    \n",
    "    \n",
    "    # If no solution exists within the initial higher bounds, increase the higher bound.\n",
    "    while (math.isinf(energy_C01)) and max_iter > 0:\n",
    "        low = high\n",
    "        high = 2*high\n",
    "        max_iter = max_iter-1\n",
    "        energy_C01, dm_SDP = SDP_solver_min_C01(high, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, G, K, P, model_type)\n",
    "\n",
    "    # If still no solution after expanding the bounds, return an error message.\n",
    "    if max_iter == 0:\n",
    "        return \"No solution found within the search bounds and maximum iterations.\"\n",
    "    \n",
    "    # Perform the binary search within the updated bounds.\n",
    "    while abs(high - low) >= threshold:\n",
    "        coef = low + abs(high - low) / 2\n",
    "        energy_C01_result, dm_SDP = SDP_solver_min_C01(coef, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, G, K, P, model_type)\n",
    "        if (math.isinf(energy_C01_result)):\n",
    "            low = coef\n",
    "        else:\n",
    "            high = coef\n",
    "            energy_C01 = energy_C01_result\n",
    "\n",
    "    return energy_C01, dm_SDP, coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def algorithmic_cooling(input_state, N_opt, N_meas,\n",
    "                        N, M, G, K, P, \n",
    "                        PauliStrList_part, PauliStrList_Gbody, h_set,\n",
    "                        H_global_list, H_local_matrix,\n",
    "                        higher_bound, threshold,\n",
    "                        model_type,\n",
    "                        SDP_tag, num_of_sweep):\n",
    "    '''Do the algorithmic cooling\n",
    "    '''\n",
    "    # Get the energy of the initial input state\n",
    "    E = 0\n",
    "    for pauli_basis in H_global_list:\n",
    "        E = E + input_state.expectation_value(oper=Pauli(pauli_basis), qargs=None)\n",
    "\n",
    "    # Define lists for saving the results\n",
    "    expH_dm_iter = [E]\n",
    "    expH_dm_SDPvalue_iter = [E]\n",
    "\n",
    "    # Start the optimization\n",
    "    for i in tqdm(range(N_opt)):\n",
    "        # Meas\n",
    "        meas_dataset = generate_meas_dataset(input_state, N_meas, N)\n",
    "\n",
    "        # Get the density matrix by tomography and SDP, respectively. \n",
    "        # Also get the minimized energy by SDP.\n",
    "        ep = cp.Variable((K, P)) # SDP variables\n",
    "        if model_type=='open':\n",
    "            K_3body = N-G+1 # Number of 3-body subsystems\n",
    "        if model_type=='closed':\n",
    "            K_3body = K # Number of 3-body subsystems\n",
    "        ep_C1 = cp.Variable((K_3body, 4**G-1)) # SDP variables for global verification\n",
    "        dm_tilde, dm_hat = SDP_variables_C0(ep, meas_dataset, \n",
    "                                            N, M, K, P, \n",
    "                                            PauliStrList_part, model_type)\n",
    "        \n",
    "        # Solve the SDP problem\n",
    "        if SDP_tag:\n",
    "            dm_tilde_C1 = SDP_variables_C1(ep_C1, meas_dataset, \n",
    "                                    N, G, K, \n",
    "                                    PauliStrList_Gbody, model_type)\n",
    "            # Energy with SDP - minimum\n",
    "            E_min_C01_value, dm_SDP, coef_min_value = biSection_search_min_C01(higher_bound, threshold, \n",
    "                                                                                    ep, ep_C1, dm_tilde, dm_tilde_C1, \n",
    "                                                                                    H_local_matrix, meas_dataset, \n",
    "                                                                                    N, M, G, K, P,\n",
    "                                                                                    model_type\n",
    "                                                                                    ) # dm_SDP is the density matrices by SDP\n",
    "     \n",
    "            expH_dm_SDPvalue_iter.append(E_min_C01_value) # Save the solved SDP min. value\n",
    "            layer_operators_list = find_layer_operator(dm_SDP, meas_dataset, input_state, N_meas,\n",
    "                                                       h_set, H_global_list, N, M, K,\n",
    "                                                       num_of_sweep,\n",
    "                                                       model_type)\n",
    "            \n",
    "        else:\n",
    "            layer_operators_list = find_layer_operator(dm_hat, meas_dataset, input_state, N_meas,\n",
    "                                                       h_set, H_global_list, N, M, K,\n",
    "                                                       num_of_sweep,\n",
    "                                                       model_type)\n",
    "\n",
    "        # Get the expectation value <H>\n",
    "        exp_H_new = 0\n",
    "        for H in H_global_list:\n",
    "            exp, var = exp_var_calculator(meas_dataset, H)\n",
    "            exp_H_new += exp\n",
    "        expH_dm_iter.append(exp_H_new) # Save the expectation value <H>\n",
    "\n",
    "        # Evolve the state with the calculated layer operator \n",
    "        for i in range(len(layer_operators_list)): # The length of layer_operators_list corresponds to how many sweeps we do in each iteration \n",
    "                \n",
    "            layer_operators = layer_operators_list[i]\n",
    "\n",
    "            for qubit_index in layer_operators:\n",
    "                register = list(qubit_index)\n",
    "                h_best, B, t_opt, decrease = layer_operators[qubit_index]\n",
    "                h_best_reduced = ''.join(char for char in h_best if char != 'I')\n",
    "            \n",
    "                if (B < 0 and t_opt < 0):\n",
    "                    U = Operator( scipy.linalg.expm( -1j * (t_opt+math.pi/2) * np.array(pauliToMatrix(h_best_reduced)) ) )\n",
    "                elif (B <= 0 and t_opt >= 0):\n",
    "                    U = Operator( scipy.linalg.expm( -1j * t_opt * np.array(pauliToMatrix(h_best_reduced)) ) )\n",
    "                elif (B >= 0 and t_opt <= 0):\n",
    "                    U = Operator( scipy.linalg.expm( 1j * (-t_opt) * np.array(pauliToMatrix(h_best_reduced)) ) )\n",
    "                elif (B > 0 and t_opt > 0):\n",
    "                    U = Operator( scipy.linalg.expm( 1j * (-t_opt+math.pi/2) * np.array(pauliToMatrix(h_best_reduced)) ) )\n",
    "                    \n",
    "                input_state = input_state.evolve(U, register[::-1])\n",
    "    \n",
    "    return expH_dm_iter, expH_dm_SDPvalue_iter\n",
    "\n",
    "def get_figure(avg_expH, std_expH, \n",
    "               avg_expH_enhanced, std_expH_enhanced, \n",
    "               avg_expH_enhanced_SDPvalue, std_expH_enhanced_SDPvalue, \n",
    "               ground_state_energy,\n",
    "               initial_guess, N, N_opt, N_meas):\n",
    "    '''Draw and plot the figure\n",
    "    '''\n",
    "    \n",
    "    plt.figure()\n",
    "    iteration_list = list(range(N_opt+1))\n",
    "    \n",
    "    # Plot the theoretical ground state energy\n",
    "    plt.axhline(y = ground_state_energy, color='r', linestyle='-', linewidth=1.25, label='GS energy')\n",
    "\n",
    "    # Plot the case without SDP\n",
    "    plt.plot(iteration_list, avg_expH, linewidth=0.75, marker='s', markersize=2.5, label='Tomography')\n",
    "    plt.fill_between(iteration_list, \n",
    "                    avg_expH-std_expH, avg_expH+std_expH, \n",
    "                    alpha=0.3)\n",
    "\n",
    "    # Plot the case with SDP\n",
    "    plt.plot(iteration_list, avg_expH_enhanced, linewidth=0.75, marker='s', markersize=2.5, label='SDP-Enhanced')\n",
    "    plt.plot(iteration_list, avg_expH_enhanced_SDPvalue, linewidth=0.75, marker='o', markersize=2.5, label='SDP-Enhanced-min.')\n",
    "    plt.fill_between(iteration_list, \n",
    "                    avg_expH_enhanced-std_expH_enhanced, avg_expH_enhanced+std_expH_enhanced, \n",
    "                    alpha=0.3)\n",
    "    plt.fill_between(iteration_list, \n",
    "                    avg_expH_enhanced_SDPvalue-std_expH_enhanced_SDPvalue, avg_expH_enhanced_SDPvalue+std_expH_enhanced_SDPvalue, \n",
    "                    alpha=0.3)\n",
    "\n",
    "\n",
    "    titlename = 'Initial:' + initial_guess + ', $N=$' + str(N) + ', $N_{meas}=$' + str(int(N_meas))\n",
    "    plt.title(titlename)\n",
    "    plt.xlabel('Number of iterations')\n",
    "    plt.ylabel('Energy expectation')\n",
    "    plt.legend()\n",
    "\n",
    "    figurename = 'N' + str(N) + '_Meas' + str(int(N_meas)) + '_'+ initial_guess +  '.pdf'\n",
    "    plt.savefig(figurename)\n",
    "\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(initial_guess, N_opt, N_meas, num_of_shots,\n",
    "         N, M, G, H_local_list, model_type):\n",
    "    \n",
    "    # Get the useful parameters and constants for this function\n",
    "    if model_type == 'open':\n",
    "        K = N-M+1 # Number of subsystems\n",
    "    if model_type == 'closed':\n",
    "        K = N\n",
    "    P = 4**M-1 # Number of Pauli basis for each subsystem\n",
    "    PauliStrList_part = generate_PauliStrList(M)[1:]\n",
    "    PauliStrList_Gbody = generate_PauliStrList(G)[1:]\n",
    "    h_set = available_h_set(N, M, K, model_type)\n",
    "    H_global_list = Hamiltonian_global(H_local_list, N, M, K, model_type) # Pauli string representation of the Hamiltonian of the whole system\n",
    "    H_local_matrix = np.array( Hamiltonian_matrix(H_local_list, model_type) ) # Matrix representation of the local Hamiltonian of subsystems\n",
    "    H_global_matrix = np.array( Hamiltonian_matrix(H_global_list, model_type) ) # Matrix representation of the Hamiltonian of the whole system\n",
    "    higher_bound = 1 # Starting trial value for the bi-search method\n",
    "    threshold = 1 # Accuracy of the minimum relaxation value \n",
    "    ground_state_energy, ground_state_dm = ground_state(H_global_matrix) \n",
    "\n",
    "    # Initial state\n",
    "    if initial_guess == 'HF':\n",
    "        input_state, exp_H_value_list = get_HF_state(H_global_list, H_global_matrix, N, M, K, model_type) # The HF state (the product state with the lowest <H>)\n",
    "    if initial_guess == '00':\n",
    "        tmp = np.zeros(2**N)\n",
    "        tmp[0] = 1\n",
    "        input_state = DensityMatrix( qiskit_statevec_map( Statevector(tmp), N ) ) # |000> state\n",
    "    if initial_guess == '++':\n",
    "        tmp = np.zeros(2**N)\n",
    "        tmp[0] = 1\n",
    "        input_state = DensityMatrix( qiskit_statevec_map( Statevector(tmp), N ) ) # |000> state\n",
    "        Hadamard = Operator(np.array(1/2**0.5*(qutip.sigmax()+qutip.sigmaz()))) \n",
    "        for i in range(N):\n",
    "            input_state = input_state.evolve(Hadamard, [i])\n",
    "    \n",
    "    # Define lists for saving the results\n",
    "    expH_matrix = []\n",
    "    expH_enhanced_matrix = []\n",
    "    expH_enhanced_SDPvalue_matrix = []\n",
    "\n",
    "    # Do the algorithmic cooling for many times\n",
    "    for i in tqdm(range(num_of_shots)):\n",
    "        # Without SDP\n",
    "        expH, expH_SDPvalue = algorithmic_cooling(input_state, N_opt, N_meas,\n",
    "                                                  N, M, G, K, P, \n",
    "                                                  PauliStrList_part, PauliStrList_Gbody, h_set,\n",
    "                                                  H_global_list, H_local_matrix,\n",
    "                                                  higher_bound, threshold,\n",
    "                                                  model_type,\n",
    "                                                  SDP_tag=False, num_of_sweep=0)\n",
    "        expH_matrix.append(expH)\n",
    "        # With SDP\n",
    "        expH_enhanced, expH_enhanced_SDPvalue = algorithmic_cooling(input_state, N_opt, N_meas,\n",
    "                                                                    N, M, G, K, P, \n",
    "                                                                    PauliStrList_part, PauliStrList_Gbody, h_set,\n",
    "                                                                    H_global_list, H_local_matrix,\n",
    "                                                                    higher_bound, threshold,\n",
    "                                                                    model_type,\n",
    "                                                                    SDP_tag=True, num_of_sweep=0)\n",
    "        expH_enhanced_matrix.append(expH_enhanced)\n",
    "        expH_enhanced_SDPvalue_matrix.append(expH_enhanced_SDPvalue)\n",
    "\n",
    "    # Calculate the avg and std of cases WITHOUT SDP\n",
    "    avg_expH= np.mean(np.array(expH_matrix), axis=0)\n",
    "    std_expH = np.std(np.array(expH_matrix), axis=0)/(num_of_shots**0.5)\n",
    "\n",
    "    # Calculate the avg and std of cases WITH SDP\n",
    "    avg_expH_enhanced= np.mean(np.array(expH_enhanced_matrix), axis=0)\n",
    "    std_expH_enhanced= np.std(np.array(expH_enhanced_matrix), axis=0)/(num_of_shots**0.5)\n",
    "    avg_expH_enhanced_SDPvalue = np.mean(np.array(expH_enhanced_SDPvalue_matrix), axis=0)\n",
    "    std_expH_enhanced_SDPvalue = np.std(np.array(expH_enhanced_SDPvalue_matrix), axis=0)/(num_of_shots**0.5)\n",
    "    \n",
    "    # Draw and save the figure\n",
    "    get_figure(avg_expH, std_expH, \n",
    "               avg_expH_enhanced, std_expH_enhanced, \n",
    "               avg_expH_enhanced_SDPvalue, std_expH_enhanced_SDPvalue, \n",
    "               ground_state_energy,\n",
    "               initial_guess, N, N_opt, N_meas)\n",
    "\n",
    "    return avg_expH, std_expH, avg_expH_enhanced, std_expH_enhanced, avg_expH_enhanced_SDPvalue, std_expH_enhanced_SDPvalue, ground_state_energy\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:15<00:00,  1.54s/it]\n"
     ]
    }
   ],
   "source": [
    "H_local_list = ['XX','YY'] # Pauli string representation of the local Hamiltonian of subsystems\n",
    "model_type = 'closed'\n",
    "M = 2 # Number of qubits of subsystems\n",
    "G = 3 # Number of qubits of partial global system (C1)\n",
    "\n",
    "N_opt = 10 # Number of iterations of cooling\n",
    "num_of_shots = 2 # Number of experiments we do \n",
    "\n",
    "data = []\n",
    "for N in [3,4]: # Number of qubits of the entire system\n",
    "    for N_meas in [1000]: # Number of measurements in all basis each loop\n",
    "        for initial_guess in ['++']:\n",
    "            avg_expH, std_expH, avg_expH_enhanced, std_expH_enhanced, avg_expH_enhanced_SDPvalue, std_expH_enhanced_SDPvalue, ground_state_energy = main(initial_guess, N_opt, N_meas, num_of_shots, \n",
    "                                                                                                                                                N, M, G, H_local_list, model_type)\n",
    "            for i in list(range(N_opt+1)):\n",
    "                # Save data to Panda DataFrame\n",
    "                df = {\n",
    "                    'N_opt': i,\n",
    "                    'avg_expH': avg_expH[i],\n",
    "                    'std_expH': std_expH[i],\n",
    "                    'avg_expH_enhanced': avg_expH_enhanced[i],\n",
    "                    'std_expH_enhanced': std_expH_enhanced[i],\n",
    "                    'avg_expH_enhanced_SDPvalue': avg_expH_enhanced_SDPvalue[i],\n",
    "                    'std_expH_enhanced_SDPvalue': std_expH_enhanced_SDPvalue[i],\n",
    "                    'N': N,\n",
    "                    'N_meas': N_meas,\n",
    "                    'Initial_state': initial_guess\n",
    "                }\n",
    "                data.append(df)\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv('experiment_data.csv', index=False) # Save the DataFrame to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[0.18794313+0.00000000e+00j, 0.20198074-6.82570108e-07j,\n",
      "        0.21382982-2.17106281e-06j, 0.15773236-3.05372944e-07j],\n",
      "       [0.20198074+6.82570108e-07j, 0.31205733+0.00000000e+00j,\n",
      "        0.30325992-7.50173527e-07j, 0.21382981-2.17095596e-06j],\n",
      "       [0.21382982+2.17106281e-06j, 0.30325992+7.50173527e-07j,\n",
      "        0.31205692+0.00000000e+00j, 0.20198063-6.81892336e-07j],\n",
      "       [0.15773236+3.05372944e-07j, 0.21382981+2.17095596e-06j,\n",
      "        0.20198063+6.81892336e-07j, 0.18794262+0.00000000e+00j]]), array([[0.16329053+0.00000000e+00j, 0.2098239 -1.06841417e-06j,\n",
      "        0.20198066-6.80832054e-07j, 0.14377464+1.98633060e-07j],\n",
      "       [0.2098239 +1.06841417e-06j, 0.33670951+0.00000000e+00j,\n",
      "        0.33337223-2.81094680e-07j, 0.20198072-6.83630390e-07j],\n",
      "       [0.20198066+6.80832054e-07j, 0.33337223+2.81094680e-07j,\n",
      "        0.33670967+0.00000000e+00j, 0.20982394-1.07031835e-06j],\n",
      "       [0.14377464-1.98633060e-07j, 0.20198072+6.83630390e-07j,\n",
      "        0.20982394+1.07031835e-06j, 0.16329028+0.00000000e+00j]]), array([[0.16725558+0.00000000e+00j, 0.21382936+5.02406460e-04j,\n",
      "        0.20982343+5.03508043e-04j, 0.1363967 +8.54378520e-06j],\n",
      "       [0.21382936-5.02406460e-04j, 0.33274463+0.00000000e+00j,\n",
      "        0.33222442-4.31212681e-07j, 0.20982441-5.05646776e-04j],\n",
      "       [0.20982343-5.03508043e-04j, 0.33222442+4.31212681e-07j,\n",
      "        0.33274489+0.00000000e+00j, 0.21383027-5.06748478e-04j],\n",
      "       [0.1363967 -8.54378520e-06j, 0.20982441+5.05646776e-04j,\n",
      "        0.21383027+5.06748478e-04j, 0.16725491+0.00000000e+00j]])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [01:50<16:31, 110.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failure:interrupted\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "SolverError",
     "evalue": "Solver 'SCS' failed. Try another solver, or solve with verbose=True for more information.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSolverError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 66>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     88\u001b[0m high \u001b[38;5;241m=\u001b[39m higher_bound\n\u001b[1;32m     89\u001b[0m max_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m---> 91\u001b[0m energy_C01, dm_SDP \u001b[38;5;241m=\u001b[39m \u001b[43mSDP_solver_min_C01\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhigh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mep_C1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdm_tilde\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdm_tilde_C1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mH_local_matrix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmeas_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mM\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_type\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28mprint\u001b[39m(dm_SDP)\n\u001b[1;32m     94\u001b[0m layer_operators_list \u001b[38;5;241m=\u001b[39m find_layer_operator(dm_SDP, meas_dataset, input_state, N_meas,\n\u001b[1;32m     95\u001b[0m                                                    h_set, H_global_list, N, M, K,\n\u001b[1;32m     96\u001b[0m                                                    num_of_sweep,\n\u001b[1;32m     97\u001b[0m                                                    model_type)\n",
      "Input \u001b[0;32mIn [7]\u001b[0m, in \u001b[0;36mSDP_solver_min_C01\u001b[0;34m(coef, ep, ep_C1, dm_tilde, dm_tilde_C1, H, measurement_dataset, N, M, G, K, P, model_type)\u001b[0m\n\u001b[1;32m     18\u001b[0m     H_exp01 \u001b[38;5;241m=\u001b[39m H_exp01 \u001b[38;5;241m+\u001b[39m H \u001b[38;5;241m@\u001b[39m dm_tilde_copy01[i]\n\u001b[1;32m     19\u001b[0m prob_C01 \u001b[38;5;241m=\u001b[39m cp\u001b[38;5;241m.\u001b[39mProblem(\n\u001b[1;32m     20\u001b[0m     cp\u001b[38;5;241m.\u001b[39mMinimize(\n\u001b[1;32m     21\u001b[0m         cp\u001b[38;5;241m.\u001b[39mreal(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m     ), constraints_0 \u001b[38;5;241m+\u001b[39m constraints_1\n\u001b[1;32m     27\u001b[0m )\n\u001b[0;32m---> 28\u001b[0m energy_C01 \u001b[38;5;241m=\u001b[39m \u001b[43mprob_C01\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSCS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m prob_C01\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m!=\u001b[39m cp\u001b[38;5;241m.\u001b[39mOPTIMAL:\n\u001b[1;32m     30\u001b[0m     energy_C01 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minf\u001b[39m\u001b[38;5;124m'\u001b[39m) \n",
      "File \u001b[0;32m~/anaconda3/envs/QuantumC/lib/python3.8/site-packages/cvxpy/problems/problem.py:495\u001b[0m, in \u001b[0;36mProblem.solve\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    494\u001b[0m     solve_func \u001b[38;5;241m=\u001b[39m Problem\u001b[38;5;241m.\u001b[39m_solve\n\u001b[0;32m--> 495\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msolve_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/QuantumC/lib/python3.8/site-packages/cvxpy/problems/problem.py:1070\u001b[0m, in \u001b[0;36mProblem._solve\u001b[0;34m(self, solver, warm_start, verbose, gp, qcp, requires_grad, enforce_dpp, ignore_dpp, canon_backend, **kwargs)\u001b[0m\n\u001b[1;32m   1068\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   1069\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_solve_time \u001b[38;5;241m=\u001b[39m end \u001b[38;5;241m-\u001b[39m start\n\u001b[0;32m-> 1070\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munpack_results\u001b[49m\u001b[43m(\u001b[49m\u001b[43msolution\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msolving_chain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minverse_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verbose:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28mprint\u001b[39m(_FOOTER)\n",
      "File \u001b[0;32m~/anaconda3/envs/QuantumC/lib/python3.8/site-packages/cvxpy/problems/problem.py:1395\u001b[0m, in \u001b[0;36mProblem.unpack_results\u001b[0;34m(self, solution, chain, inverse_data)\u001b[0m\n\u001b[1;32m   1393\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(INF_OR_UNB_MESSAGE)\n\u001b[1;32m   1394\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m solution\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;129;01min\u001b[39;00m s\u001b[38;5;241m.\u001b[39mERROR:\n\u001b[0;32m-> 1395\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error\u001b[38;5;241m.\u001b[39mSolverError(\n\u001b[1;32m   1396\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSolver \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m failed. \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m chain\u001b[38;5;241m.\u001b[39msolver\u001b[38;5;241m.\u001b[39mname() \u001b[38;5;241m+\u001b[39m\n\u001b[1;32m   1397\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTry another solver, or solve with verbose=True for more \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1398\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minformation.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1400\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munpack(solution)\n\u001b[1;32m   1401\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_solver_stats \u001b[38;5;241m=\u001b[39m SolverStats(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_solution\u001b[38;5;241m.\u001b[39mattr,\n\u001b[1;32m   1402\u001b[0m                                  chain\u001b[38;5;241m.\u001b[39msolver\u001b[38;5;241m.\u001b[39mname())\n",
      "\u001b[0;31mSolverError\u001b[0m: Solver 'SCS' failed. Try another solver, or solve with verbose=True for more information."
     ]
    }
   ],
   "source": [
    "N = 3\n",
    "M = 2 # Number of qubits of subsystems\n",
    "G = 3 # Number of qubits of partial global system (C1)\n",
    "num_of_sweep = 0\n",
    "\n",
    "H_local_list = ['XX','YY'] # Pauli string representation of the local Hamiltonian of subsystems\n",
    "model_type = 'closed'\n",
    "# Get the useful parameters and constants for this function\n",
    "if model_type == 'open':\n",
    "    K = N-M+1 # Number of subsystems\n",
    "if model_type == 'closed':\n",
    "    K = N\n",
    "\n",
    "N_opt = 10 # Number of iterations of cooling\n",
    "num_of_shots = 1 # Number of experiments we do \n",
    "N_meas = 5000 # Number of measurements in all basis each loop\n",
    "initial_guess = '++'\n",
    "\n",
    "\n",
    "P = 4**M-1 # Number of Pauli basis for each subsystem\n",
    "PauliStrList_part = generate_PauliStrList(M)[1:]\n",
    "PauliStrList_Gbody = generate_PauliStrList(G)[1:]\n",
    "h_set = available_h_set(N, M, K, model_type)\n",
    "H_global_list = Hamiltonian_global(H_local_list, N, M, K, model_type) # Pauli string representation of the Hamiltonian of the whole system\n",
    "H_local_matrix = np.array( Hamiltonian_matrix(H_local_list, model_type) ) # Matrix representation of the local Hamiltonian of subsystems\n",
    "H_global_matrix = np.array( Hamiltonian_matrix(H_global_list, model_type) ) # Matrix representation of the Hamiltonian of the whole system\n",
    "higher_bound = 1 # Starting trial value for the bi-search method\n",
    "threshold = 1 # Accuracy of the minimum relaxation value \n",
    "ground_state_energy, ground_state_dm = ground_state(H_global_matrix) \n",
    "\n",
    "# Initial state\n",
    "if initial_guess == 'HF':\n",
    "    input_state, exp_H_value_list = get_HF_state(H_global_list, H_global_matrix, N, M, K, model_type) # The HF state (the product state with the lowest <H>)\n",
    "if initial_guess == '00':\n",
    "    tmp = np.zeros(2**N)\n",
    "    tmp[0] = 1\n",
    "    input_state = DensityMatrix( qiskit_statevec_map( Statevector(tmp), N ) ) # |000> state\n",
    "if initial_guess == '++':\n",
    "    tmp = np.zeros(2**N)\n",
    "    tmp[0] = 1\n",
    "    input_state = DensityMatrix( qiskit_statevec_map( Statevector(tmp), N ) ) # |000> state\n",
    "    Hadamard = Operator(np.array(1/2**0.5*(qutip.sigmax()+qutip.sigmaz()))) \n",
    "    for i in range(N):\n",
    "        input_state = input_state.evolve(Hadamard, [i])\n",
    "\n",
    "# expH_enhanced, expH_enhanced_SDPvalue = algorithmic_cooling(input_state, N_opt, N_meas,\n",
    "#                                                             N, M, G, K, P, \n",
    "#                                                             PauliStrList_part, PauliStrList_Gbody, h_set,\n",
    "#                                                             H_global_list, H_local_matrix,\n",
    "#                                                             higher_bound, threshold,\n",
    "#                                                             model_type,\n",
    "#                                                             SDP_tag=True, num_of_sweep=0)\n",
    "\n",
    "\n",
    "\n",
    "# Get the energy of the initial input state\n",
    "E = 0\n",
    "for pauli_basis in H_global_list:\n",
    "    E = E + input_state.expectation_value(oper=Pauli(pauli_basis), qargs=None)\n",
    "\n",
    "# Define lists for saving the results\n",
    "expH_dm_iter = [E]\n",
    "expH_dm_SDPvalue_iter = [E]\n",
    "\n",
    "# Start the optimization\n",
    "for i in tqdm(range(N_opt)):\n",
    "    # Meas\n",
    "    meas_dataset = generate_meas_dataset(input_state, N_meas, N)\n",
    "\n",
    "    # Get the density matrix by tomography and SDP, respectively. \n",
    "    # Also get the minimized energy by SDP.\n",
    "    ep = cp.Variable((K, P)) # SDP variables\n",
    "    if model_type=='open':\n",
    "        K_3body = N-G+1 # Number of 3-body subsystems\n",
    "    if model_type=='closed':\n",
    "        K_3body = K # Number of 3-body subsystems\n",
    "    ep_C1 = cp.Variable((K_3body, 4**G-1)) # SDP variables for global verification\n",
    "    dm_tilde, dm_hat = SDP_variables_C0(ep, meas_dataset, \n",
    "                                        N, M, K, P, \n",
    "                                        PauliStrList_part, model_type)\n",
    "    \n",
    "    # Solve the SDP problem\n",
    "    dm_tilde_C1 = SDP_variables_C1(ep_C1, meas_dataset, \n",
    "                                N, G, K, \n",
    "                                PauliStrList_Gbody, model_type)\n",
    "    \n",
    "    low = 0\n",
    "    high = higher_bound\n",
    "    max_iter = 10\n",
    "   \n",
    "    energy_C01, dm_SDP = SDP_solver_min_C01(high, ep, ep_C1, dm_tilde, dm_tilde_C1, H_local_matrix, meas_dataset, N, M, G, K, P, model_type)\n",
    "    print(dm_SDP)\n",
    "\n",
    "    layer_operators_list = find_layer_operator(dm_SDP, meas_dataset, input_state, N_meas,\n",
    "                                                       h_set, H_global_list, N, M, K,\n",
    "                                                       num_of_sweep,\n",
    "                                                       model_type)\n",
    "    \n",
    "    # Get the expectation value <H>\n",
    "    exp_H_new = 0\n",
    "    for H in H_global_list:\n",
    "        exp, var = exp_var_calculator(meas_dataset, H)\n",
    "        exp_H_new += exp\n",
    "    expH_dm_iter.append(exp_H_new) # Save the expectation value <H>\n",
    "\n",
    "    # Evolve the state with the calculated layer operator \n",
    "    for i in range(len(layer_operators_list)): # The length of layer_operators_list corresponds to how many sweeps we do in each iteration \n",
    "            \n",
    "        layer_operators = layer_operators_list[i]\n",
    "\n",
    "        for qubit_index in layer_operators:\n",
    "            register = list(qubit_index)\n",
    "            h_best, B, t_opt, decrease = layer_operators[qubit_index]\n",
    "            h_best_reduced = ''.join(char for char in h_best if char != 'I')\n",
    "        \n",
    "            if (B < 0 and t_opt < 0):\n",
    "                U = Operator( scipy.linalg.expm( -1j * (t_opt+math.pi/2) * np.array(pauliToMatrix(h_best_reduced)) ) )\n",
    "            elif (B <= 0 and t_opt >= 0):\n",
    "                U = Operator( scipy.linalg.expm( -1j * t_opt * np.array(pauliToMatrix(h_best_reduced)) ) )\n",
    "            elif (B >= 0 and t_opt <= 0):\n",
    "                U = Operator( scipy.linalg.expm( 1j * (-t_opt) * np.array(pauliToMatrix(h_best_reduced)) ) )\n",
    "            elif (B > 0 and t_opt > 0):\n",
    "                U = Operator( scipy.linalg.expm( 1j * (-t_opt+math.pi/2) * np.array(pauliToMatrix(h_best_reduced)) ) )\n",
    "                \n",
    "            input_state = input_state.evolve(U, register[::-1])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n",
      "[1, 2]\n",
      "[2, 3]\n",
      "[3, 4]\n",
      "[4, 0]\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "N = 5\n",
    "M = 2 # Number of qubits of subsystems\n",
    "G = 3 # Number of qubits of partial global system (C1)\n",
    "num_of_sweep = 0\n",
    "\n",
    "H_local_list = ['XX','YY'] # Pauli string representation of the local Hamiltonian of subsystems\n",
    "model_type = 'closed'\n",
    "# Get the useful parameters and constants for this function\n",
    "if model_type == 'open':\n",
    "    K = N-M+1 # Number of subsystems\n",
    "if model_type == 'closed':\n",
    "    K = N\n",
    "\n",
    "N_opt = 10 # Number of iterations of cooling\n",
    "num_of_shots = 1 # Number of experiments we do \n",
    "N_meas = 5000 # Number of measurements in all basis each loop\n",
    "initial_guess = '++'\n",
    "\n",
    "\n",
    "P = 4**M-1 # Number of Pauli basis for each subsystem\n",
    "PauliStrList_part = generate_PauliStrList(M)[1:]\n",
    "PauliStrList_Gbody = generate_PauliStrList(G)[1:]\n",
    "h_set = available_h_set(N, M, K, model_type)\n",
    "H_global_list = Hamiltonian_global(H_local_list, N, M, K, model_type) # Pauli string representation of the Hamiltonian of the whole system\n",
    "H_local_matrix = np.array( Hamiltonian_matrix(H_local_list, model_type) ) # Matrix representation of the local Hamiltonian of subsystems\n",
    "H_global_matrix = np.array( Hamiltonian_matrix(H_global_list, model_type) ) # Matrix representation of the Hamiltonian of the whole system\n",
    "higher_bound = 1 # Starting trial value for the bi-search method\n",
    "threshold = 1 # Accuracy of the minimum relaxation value \n",
    "ground_state_energy, ground_state_dm = ground_state(H_global_matrix) \n",
    "\n",
    "if model_type=='closed':\n",
    "    for k in range(K):  # K: number of subsystems\n",
    "        index = [(k + i) % K for i in range(M)]  # [k, k+1, ...]\n",
    "        print(index)\n",
    "\n",
    "if model_type=='closed':\n",
    "    for i in range(K - 1):  # physically compatitble\n",
    "        print(i)\n",
    "    #     constraints += [cp.partial_trace(dm_tilde[i], dims=[2] * M, axis=0) ==\n",
    "    #                     cp.partial_trace(dm_tilde[i+1], dims=[2] * M, axis=M - 1)]\n",
    "        \n",
    "    #     print()\n",
    "    # # Add the physically compatitble constraints between the head and tail local systems (only works for M=2)\n",
    "    print(K-1)\n",
    "    # constraints += [cp.partial_trace(dm_tilde[K-2], dims=[2] * M, axis=0) ==\n",
    "    #                     cp.partial_trace(dm_tilde[K-1], dims=[2] * M, axis=0)]\n",
    "    # constraints += [cp.partial_trace(dm_tilde[K-1], dims=[2] * M, axis=M-1) ==\n",
    "    #                     cp.partial_trace(dm_tilde[0], dims=[2] * M, axis=M-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n",
      "[1, 2, 3]\n",
      "[2, 3, 4]\n",
      "[3, 4, 0]\n",
      "[4, 0, 1]\n",
      "0\n",
      "1\n",
      "2\n",
      "K-2 is 3\n",
      "K-1 is 4\n"
     ]
    }
   ],
   "source": [
    "if model_type=='closed':\n",
    "    for k in range(K):  # K: number of subsystems\n",
    "        index = [(k + i) % K for i in range(G)]  # [k, k+1, ...]\n",
    "        print(index)\n",
    "\n",
    "# for k in range(K):\n",
    "#     print(k)\n",
    "\n",
    "if model_type=='closed':\n",
    "    for i in range(N-G+1):\n",
    "        print(i)\n",
    "    #     constraints_C1 += [cp.partial_trace(dm_tilde_C1[i], dims=[4,2], axis=1) == dm_tilde[i]]\n",
    "    #     constraints_C1 += [cp.partial_trace(dm_tilde_C1[i], dims=[2,4], axis=0) == dm_tilde[i+1]]\n",
    "    # if K>=4: # Add the globally compatitble constraints between the head and tail local systems (only works for M=2)\n",
    "    print('K-2 is', K-2 )\n",
    "    print('K-1 is', K-1)\n",
    "    #     constraints_C1 += [cp.partial_trace(dm_tilde_C1[K-2], dims=[2,4], axis=0) == dm_tilde[K-1]]\n",
    "    #     constraints_C1 += [cp.partial_trace(dm_tilde_C1[K-2], dims=[4,2], axis=1) == dm_tilde[K-2]]\n",
    "    #     constraints_C1 += [cp.partial_trace(dm_tilde_C1[K-1], dims=[2,2,2], axis=0) == dm_tilde[0]]\n",
    "    #     constraints_C1 += [cp.partial_trace(dm_tilde_C1[K-1], dims=[2,2,2], axis=G-1) == dm_tilde[K-1]]\n",
    "    #     # (only works for M=2, G=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YX\n"
     ]
    }
   ],
   "source": [
    "qubit_index = [4, 0]\n",
    "N = 5\n",
    "for basis in ['XIIIY']:\n",
    "    sub_basis = ''.join([basis[i] for i in qubit_index])\n",
    "    print(sub_basis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 ('QuantumC')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb1c09c88080a82141bde80abfc5c4dcde1e462f373af1bd572dc93ad8fc5299"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
